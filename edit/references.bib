
@article{tukey_exploratory_1977,
	title = {Exploratory {Data} {Analysis}},
	volume = {231},
	url = {http://xa.yimg.com/kq/groups/16412409/1159714453/name/ExploratoryDataAnalysis.pdf},
	urldate = {2012-12-18},
	journal = {Reading, MA},
	author = {Tukey, J. W.},
	year = {1977},
	file = {Tukey - 1977 - Exploratory data analysis.pdf:/Users/rca2t1/Dropbox/Zotero/storage/4NTMMC3I/Tukey - 1977 - Exploratory data analysis.pdf:application/pdf},
}

@misc{jacobs_skills_2008,
	title = {Skills, {Role} \& {Career} {Structure} of {Data} {Scientists} \& {Curators}: {Assessment} of {Current} {Practice} \& {Future} {Needs}},
	copyright = {Copyright Jisc unless explicitly acknowledged otherwise.},
	shorttitle = {Skills, {Role} \& {Career} {Structure} of {Data} {Scientists} \& {Curators}},
	url = {http://www.jisc.ac.uk/whatwedo/programmes/digitalrepositories2007/dataskillscareers.aspx},
	abstract = {A project to examine and make recommendations on the role and career development of data scientists, the associated supply of specialist data curation skills to the research community, including an assessment of the value and potential of extending data handling, curation and preservation skills within undergraduate and postgraduate curricula.},
	language = {en-GB},
	urldate = {2012-12-18},
	author = {Jacobs, Neil},
	year = {2008},
	keywords = {Data \& Text Mining, Data Services \& Collections, Digital Repositories, Network \& Infrastructure, Research \& Innovation, Staff Developmen},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TF8DGJTP/dataskillscareers.html:text/html},
}

@misc{press_very_2012,
	title = {A {Very} {Short} {History} of {Big} {Data}},
	url = {http://whatsthebigdata.com/2012/06/06/a-very-short-history-of-big-data/},
	abstract = {In addition to researching A Very Short History of Data Science, I have also been looking at the history of how data became big. Here I focus on the history of attempts to quantify the growth rate ...},
	urldate = {2012-12-18},
	journal = {What's The Big Data?},
	author = {Press, Gil},
	month = jun,
	year = {2012},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/XVHUXDB6/a-very-short-history-of-big-data.html:text/html},
}

@book{wiener_cybernetics:_1948,
	address = {Paris, France},
	title = {Cybernetics: {Or} {Control} and {Communication} in the {Animal} and the {Machine}},
	publisher = {Librairie Hermann \& Cie},
	author = {Wiener, Norbert},
	year = {1948},
}

@article{rappaport_ritual_1971,
	series = {New {Series}},
	title = {Ritual, {Sanctity}, and {Cybernetics}},
	volume = {73},
	issn = {00027294},
	url = {http://www.jstor.org/stable/671812},
	abstract = {The role of the sacred in human communication and in the regulation of social and ecological systems is approached through ritual. After a brief review of salient features of Maring ethnography, formal characteristics of rituals making them suitable for communication and regulation functions are examined. From this discussion a concept of sanctity relating it to a problem inherent in symbolic communication is derived. The non-discussive basis of sanctity is then considered and the role of the sacred in the cybernetics of social and ecological systems is then discussed. Next it is suggested that the relationship between sanctity and authority changes with technological development. Finally, some tentative suggestions concerning the origins of the sacred are advanced.},
	number = {1},
	urldate = {2009-10-21},
	journal = {American Anthropologist},
	author = {Rappaport, Roy A.},
	year = {1971},
	note = {ArticleType: primary\_article / Full publication date: Feb., 1971 / Copyright © 1971 American Anthropological Association},
	pages = {59--76},
	file = {Rappaport - 1971 - Ritual, Sanctity, and Cybernetics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/QMN9KFW7/Rappaport - 1971 - Ritual, Sanctity, and Cybernetics.pdf:application/pdf},
}

@article{kusnetzky_what_2010,
	title = {What is "{Big} {Data}?"},
	url = {http://www.zdnet.com/blog/virtualization/what-is-big-data/1708},
	urldate = {2010-11-04},
	journal = {ZDNet},
	author = {Kusnetzky, Dan},
	month = feb,
	year = {2010},
	annote = {"Big Data" is a catch phrase that has been bubbling up from the high performance computing niche of the IT market. Increasingly suppliers of processing virtualization and storage virtualization software have begun to flog "Big Data" in their presentations. What, exactly, does this phrase mean?},
	file = {What is "Big Data?" | ZDNet:/Users/rca2t1/Dropbox/Zotero/storage/G5NTEDFQ/1708.html:text/html},
}

@article{kline_cybernetics_nodate,
	title = {Cybernetics , {Management} {Science} , and {Technology} {Policy}},
	author = {Kline, Ronald R},
	file = {Attachment:/Users/rca2t1/Dropbox/Zotero/storage/798ZGNT9/Cybernetics , Management Science , and Technology Policy_Unknown.pdf:application/pdf},
}

@article{hayles_boundary_2007,
	title = {Boundary {Disputes} : {Homeostasis} , {Reflexivity} , and the {Foundations} of {Cybernetics}},
	volume = {3},
	number = {1994},
	journal = {Constellations},
	author = {Hayles, N Katherine},
	year = {2007},
	pages = {1--16},
	file = {Attachment:/Users/rca2t1/Dropbox/Zotero/storage/RXNW8BJB/Boundary Disputes Homeostasis , Reflexivity , and the Foundations of Cybernetics_Constellations.pdf:application/pdf},
}

@article{kay_cybernetics_1997,
	title = {Cybernetics, {Information}, {Life}: {The} {Emergence} of {Scriptural} {Representations} of {Heredity}},
	volume = {5},
	issn = {1080-6520},
	shorttitle = {Cybernetics, {Information}, {Life}},
	url = {http://muse.jhu.edu/journals/configurations/v005/5.1kay.html},
	number = {1},
	urldate = {2011-08-18},
	journal = {Configurations},
	author = {Kay, Lily E.},
	year = {1997},
	note = {{\textless}p{\textgreater}Volume 5, Number 1, Winter 1997{\textless}/p{\textgreater}},
	pages = {23--91},
	file = {Project MUSE Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/76DUVAPQ/5.1kay.html:text/html},
}

@book{wiener_human_1950,
	address = {Boston,},
	title = {The human use of human beings; cybernetics and society.},
	publisher = {Houghton Mifflin,},
	author = {Wiener, Norbert},
	year = {1950},
}

@article{lorenza_understanding_2011,
	title = {Understanding as an embodied, situated and sequential achievement in interaction},
	volume = {43},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/S0378216610002754},
	doi = {10.1016/j.pragma.2010.08.019},
	abstract = {This paper aims at outlining the sequential, situated and embodied dimensions of understanding in interaction. This perspective on understanding, originating in Ryle and Wittgenstein, further developed by ethnomethodology and conversation analysis, focuses on the orderly unfolding of sequences of actions in time. It also focuses on understanding as a collective achievement, publicly displayed and interactively oriented to within the production and the monitoring of action. Its accountability is built through a plurality of displays, claiming and demonstrating understanding, thanks to the mobilization of linguistic and embodied resources at specific sequential positions. The paper discusses evidences of understanding as they are publicly displayed by the participants in interaction: It both offers a discussion of the ethnomethodological and conversation analytic literature, and an analysis an empirical case, focusing on the interplay of embodied and sequential features in the production and monitoring of understanding.},
	number = {2},
	urldate = {2012-02-20},
	journal = {Journal of Pragmatics},
	author = {Lorenza, Mondada},
	year = {2011},
	note = {January 2011},
	keywords = {Social interaction, Accountability, Conversation analysis, Embodiment, Ethnomethodology, Multimodality, Sequentiality, Time, Understanding},
	pages = {542--552},
	file = {Lorenza - 2011 - Understanding as an embodied, situated and sequent.pdf:/Users/rca2t1/Dropbox/Zotero/storage/MX4Q7NGI/Lorenza - 2011 - Understanding as an embodied, situated and sequent.pdf:application/pdf;ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3TGTVSUE/Lorenza - 2011 - Understanding as an embodied, situated and sequent.html:text/html},
}

@inproceedings{freeman_neurobiological_1997,
	title = {A neurobiological interpretation of semiotics: {Meaning} vs. representation},
	volume = {2},
	shorttitle = {A neurobiological interpretation of semiotics},
	booktitle = {Systems, {Man}, and {Cybernetics}, 1997.'{Computational} {Cybernetics} and {Simulation}'., 1997 {IEEE} {International} {Conference} on},
	author = {Freeman, W.J.},
	year = {1997},
	pages = {1481--1486},
	file = {Freeman - 1997 - A neurobiological interpretation of semiotics Mea.pdf:/Users/rca2t1/Dropbox/Zotero/storage/XV5ZC6SU/Freeman - 1997 - A neurobiological interpretation of semiotics Mea.pdf:application/pdf;Google Scholar Linked Page:/Users/rca2t1/Dropbox/Zotero/storage/NINJTGTN/abs_all.html:text/html},
}

@book{mindell_war_2000,
	title = {War, technology, and experience aboard the {USS} {Monitor}},
	isbn = {978-0-8018-6250-2},
	abstract = {In a familiar story, the USS Monitor battled the CSS Virginia (the armored and refitted USS Merrimack) at Hampton Roads in March of 1862. In War, Technology, and Experience aboard the USS Monitor, David A. Mindell adds a new perspective to the story as he explores how mariners -- fighting "blindly" below the waterline -- lived and coped with the metal monster they called the "iron coffin." Mindell shows how the iron warship emerged as an idea and became practicable, how building it drew upon and forced changes in contemporary manufacturing technology, and how the vessel captured the nineteenth-century American popular and literary imaginations.Combining technical, personal, administrative, and literary analysis, Mindell examines the experience of the men aboard the Monitor and their reactions to the thrills and dangers that accompanied the new machine. The invention surrounded men with iron and threatened their heroism, their self-image as warriors, even their lives. Mindell also examines responses to this strange new warship by Nathaniel Hawthorne and Herman Melville, who prophetically saw in the Civil War a portent of the mechanized warfare of the future. The story of the Monitor shows how technology changes not only the tools but also the very experience of combat, generating effects that are still felt today in the era of "smart bombs" and pushbutton wars."We find new significance in the otherwise well-known history of the Monitor. It is no longer the story of the heroic inventor and his impenetrable weapon thrusting themselves upon a doubtful and conservative bureaucracy... It is no longer the story of a heroic battle and the machine's epic loss soon after. Rather it is a story of people experiencing new machinery, attempting to make sense of its thrills, constrictions, and politics, and sensing its power and impotence -- both in glory and frustration." -- from War, Technology, and Experience aboard the USS Monitor},
	language = {en},
	publisher = {JHU Press},
	author = {Mindell, David A.},
	year = {2000},
	keywords = {history, Civil War},
}

@article{norman_cognition_1993,
	title = {Cognition in the {Head} and in the {World}: {An} {Introduction} to the {Special} {Issue} on {Situated} {Action}},
	volume = {17},
	copyright = {1993 Lawrence Erlbaum Associates, Inc.},
	issn = {1551-6709},
	shorttitle = {Cognition in the {Head} and in the {World}},
	url = {http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1701_1/abstract},
	doi = {10.1207/s15516709cog1701_1},
	language = {en},
	number = {1},
	urldate = {2012-03-09},
	journal = {Cognitive Science},
	author = {Norman, Donald A},
	year = {1993},
	pages = {1--6},
	file = {Norman - 1993 - Cognition in the Head and in the World An Introdu.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ZXE4HDMI/Norman - 1993 - Cognition in the Head and in the World An Introdu.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/XC5WQV8M/Norman - 1993 - Cognition in the Head and in the World An Introdu.html:text/html},
}

@article{vera_situated_1993,
	title = {Situated {Action}: {A} {Symbolic} {Interpretation}},
	volume = {17},
	shorttitle = {Situated {Action}},
	number = {1},
	journal = {Cognitive science},
	author = {Vera, A.H. and Simon, H.A.},
	year = {1993},
	keywords = {situated action},
	pages = {7--48},
	file = {Vera and Simon - 1993 - Situated Action A Symbolic Interpretation.pdf:/Users/rca2t1/Dropbox/Zotero/storage/XBVJAAWC/Vera and Simon - 1993 - Situated Action A Symbolic Interpretation.pdf:application/pdf},
}

@article{suchman_making_1995,
	title = {Making work visible},
	volume = {38},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/223248.223263},
	doi = {10.1145/223248.223263},
	number = {9},
	urldate = {2012-04-03},
	journal = {Commun. ACM},
	author = {Suchman, Lucy},
	month = sep,
	year = {1995},
	pages = {56--ff.},
	file = {Suchman - 1995 - Making work visible.pdf:/Users/rca2t1/Dropbox/Zotero/storage/EWWM34BV/Suchman - 1995 - Making work visible.pdf:application/pdf},
}

@book{suchman_plans_1987,
	edition = {2},
	title = {Plans and {Situated} {Actions}: {The} {Problem} of {Human}-{Machine} {Communication}},
	isbn = {0-521-33739-9},
	shorttitle = {Plans and {Situated} {Actions}},
	publisher = {Cambridge University Press},
	author = {Suchman, Lucy A.},
	year = {1987},
	keywords = {artificial intelligence, situated action},
}

@book{wiener_human_1967,
	title = {The human use of human beings: {Cybernetics} and society},
	shorttitle = {The human use of human beings},
	publisher = {Avon Books},
	author = {Wiener, Norbert},
	year = {1967},
}

@article{wiener_speech_1950,
	title = {Speech, {Language}, and {Learning}},
	volume = {22},
	url = {http://link.aip.org/link/?JAS/22/696/1},
	doi = {10.1121/1.1906672},
	number = {6},
	urldate = {2013-04-08},
	journal = {The Journal of the Acoustical Society of America},
	author = {Wiener, Norbert},
	year = {1950},
	keywords = {Cybernetics},
	pages = {696--697},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TKUR8K3A/p696_s1.html:text/html;Wiener - 1950 - Speech, Language, and Learning.pdf:/Users/rca2t1/Dropbox/Zotero/storage/D797ZGUI/Wiener - 1950 - Speech, Language, and Learning.pdf:application/pdf},
}

@article{wiener_sound_1949,
	title = {Sound {Communication} with the {Deaf}},
	volume = {16},
	copyright = {Copyright © 1949 Philosophy of Science Association},
	issn = {0031-8248},
	url = {http://www.jstor.org/stable/185520},
	doi = {10.2307/185520},
	number = {3},
	urldate = {2013-04-08},
	journal = {Philosophy of Science},
	author = {Wiener, Norbert},
	month = jul,
	year = {1949},
	note = {ArticleType: research-article / Full publication date: Jul., 1949 / Copyright © 1949 Philosophy of Science Association},
	keywords = {Cybernetics},
	pages = {260--262},
	file = {Wiener - 1949 - Sound Communication with the Deaf.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2Q6Q5K8W/Wiener - 1949 - Sound Communication with the Deaf.pdf:application/pdf},
}

@article{wiener_problems_1951,
	title = {Problems of sensory prosthesis},
	volume = {57},
	issn = {0002-9904, 1936-881X},
	url = {http://www.ams.org/bull/1951-57-01/S0002-9904-1951-09433-1/},
	doi = {10.1090/S0002-9904-1951-09433-1},
	abstract = {al Information DOI: http://dx.doi.org/10.1090/S0002-9904-1951-09433-1 PII: S 0002-9904(1951)09433-1},
	number = {1},
	urldate = {2013-04-08},
	journal = {Bulletin of the American Mathematical Society},
	author = {Wiener, Norbert},
	year = {1951},
	keywords = {Cybernetics},
	pages = {27--35},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/KFKZHCWX/S0002-9904-1951-09433-1.html:text/html;Wiener - 1951 - Problems of sensory prosthesis.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RQT3P4FB/Wiener - 1951 - Problems of sensory prosthesis.pdf:application/pdf},
}

@article{wiener_time_1948,
	title = {Time, {Communication}, and the {Nervous} {System}},
	volume = {50},
	issn = {1749-6632},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1948.tb39853.x/abstract},
	doi = {10.1111/j.1749-6632.1948.tb39853.x},
	language = {en},
	number = {4},
	urldate = {2013-04-08},
	journal = {Annals of the New York Academy of Sciences},
	author = {Wiener, Norbert},
	year = {1948},
	keywords = {Cybernetics},
	pages = {197--220},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/8FZ3HGGU/abstract.html:text/html;Wiener - 1948 - Time, Communication, and the Nervous System.pdf:/Users/rca2t1/Dropbox/Zotero/storage/Z5AQSPQF/Wiener - 1948 - Time, Communication, and the Nervous System.pdf:application/pdf},
}

@article{wiener_what_1956,
	title = {What is information theory},
	volume = {48},
	url = {http://www.cetuc.puc-rio.br/~weiler/RECOMENDED_papers/Wiener1956_TIT48.pdf},
	urldate = {2013-04-08},
	journal = {IRE Transactions on Information Theory},
	author = {Wiener, Norbert},
	year = {1956},
	keywords = {information, information theory},
	file = {Wiener - 1956 - What is information theory.pdf:/Users/rca2t1/Dropbox/Zotero/storage/PAH4JUNB/Wiener - 1956 - What is information theory.pdf:application/pdf},
}

@book{mindell_between_2002,
	title = {Between {Human} and {Machine}: {Feedback}, {Control}, and {Computing} {Before} {Cybernetics}},
	isbn = {978-0-8018-6895-5},
	shorttitle = {Between {Human} and {Machine}},
	abstract = {Today, we associate the relationship between feedback, control, and computing with Norbert Wiener's 1948 formulation of cybernetics. But the theoretical and practical foundations for cybernetics, control engineering, and digital computing were laid earlier, between the two world wars. In Between Human and Machine: Feedback, Control, and Computing before Cybernetics, David A. Mindell shows how the modern sciences of systems emerged from disparate engineering cultures and their convergence during World War II. Mindell examines four different arenas of control systems research in the United States between the world wars: naval fire control, the Sperry Gyroscope Company, the Bell Telephone Laboratories, and Vannevar Bush's laboratory at MIT. Each of these institutional sites had unique technical problems, organizational imperatives, and working environments, and each fostered a distinct engineering culture. Each also developed technologies to represent the world in a machine.At the beginning of World War II, President Roosevelt established the National Defense Research Committee, one division of which was devoted to control systems. Mindell shows how the NDRC brought together representatives from the four pre-war engineering cultures, and how its projects synthesized conceptions of control, communications, and computing. By the time Wiener articulated his vision, these ideas were already suffusing through engineering. They would profoundly influence the digital world. As a new way to conceptualize the history of computing, this book will be of great interest to historians of science, technology, and culture, as well as computer scientists and theorists. Between Human and Machine: Feedback, Control, and Computing before Cybernetics},
	language = {en},
	publisher = {JHU Press},
	author = {Mindell, David A.},
	month = aug,
	year = {2002},
	keywords = {Computers / History, Technology \& Engineering / History, Computers / Data Processing, Science / History, Technology \& Engineering / Automation, Technology \& Engineering / Engineering (General), Technology \& Engineering / Mechanical},
	file = {Mindell - 2002 - Between Human and Machine Feedback, Control, and .pdf:/Users/rca2t1/Dropbox/Zotero/storage/R2ASLW3G/Mindell - 2002 - Between Human and Machine Feedback, Control, and .pdf:application/pdf},
}

@misc{mindell_cybernetics:_2004,
	title = {Cybernetics: {Knowledge} {Domains} in {Engineering} {Systems}},
	abstract = {Today, we associate the relationship between feedback, control, and computing with Norbert Wiener's 1948 formulation of cybernetics. But the theoretical and practical foundations for cybernetics, control engineering, and digital computing were laid earlier, between the two world wars. In Between Human and Machine: Feedback, Control, and Computing before Cybernetics, David A. Mindell shows how the modern sciences of systems emerged from disparate engineering cultures and their convergence during World War II. Mindell examines four different arenas of control systems research in the United States between the world wars: naval fire control, the Sperry Gyroscope Company, the Bell Telephone Laboratories, and Vannevar Bush's laboratory at MIT. Each of these institutional sites had unique technical problems, organizational imperatives, and working environments, and each fostered a distinct engineering culture. Each also developed technologies to represent the world in a machine.At the beginning of World War II, President Roosevelt established the National Defense Research Committee, one division of which was devoted to control systems. Mindell shows how the NDRC brought together representatives from the four pre-war engineering cultures, and how its projects synthesized conceptions of control, communications, and computing. By the time Wiener articulated his vision, these ideas were already suffusing through engineering. They would profoundly influence the digital world. As a new way to conceptualize the history of computing, this book will be of great interest to historians of science, technology, and culture, as well as computer scientists and theorists. Between Human and Machine: Feedback, Control, and Computing before Cybernetics},
	language = {en},
	publisher = {JHU Press},
	author = {Mindell, David A.},
	year = {2004},
	keywords = {Cybernetics},
	file = {mindell-2000-cybernetics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/H8FDDTUG/mindell-2000-cybernetics.pdf:application/pdf},
}

@misc{manovich_course_nodate,
	title = {Course {Schedule}: {Big} {Data}, {Visualization}, and {Digital} {Humanities}. {Spring} 2013, {GC} {CUNY}.},
	url = {https://docs.google.com/document/d/1Mf6qlFNqwLLvVPlWAOy0eK3HfbgLlJgIJSyEImM4uSg/preview?sle=true#},
	urldate = {2013-02-24},
	author = {Manovich, Lev},
	file = {course schedule\: Big Data, Visualization, and Digital Humanities.Spring 2013. GC CUNY - Google Drive:/Users/rca2t1/Dropbox/Zotero/storage/JD8H9JNX/preview.html:text/html},
}

@article{forsythe_knowledge_1989,
	title = {Knowledge acquisition for expert systems: some pitfalls and suggestions},
	volume = {19},
	issn = {0018-9472},
	shorttitle = {Knowledge acquisition for expert systems},
	doi = {10.1109/21.31050},
	abstract = {The interdisciplinary anthropological study of knowledge elicitation (ASKE) project is introduced. The choice of anthropological methodology for the project is discussed, and the relevance of anthropology to knowledge engineering in general is pointed out. Examples are given of pitfalls observed in the knowledge elicitation process, including problems related to both interviewing technique and conceptual approach. Some preliminary conclusions are drawn based on work to date},
	number = {3},
	journal = {IEEE Transactions on Systems, Man and Cybernetics},
	author = {Forsythe, D.E. and Buchanan, Bruce G.},
	year = {1989},
	keywords = {Laboratories, Computer science, Humans, Intelligent systems, anthropological study of knowledge elicitation, Artificial intelligence, ASKE project, expert systems, Intelligent structures, knowledge acquisition, Knowledge based systems, knowledge engineering},
	pages = {435--442},
	file = {IEEE Xplore Abstract Record:/Users/rca2t1/Dropbox/Zotero/storage/IAIZBZE9/abs_all.html:text/html;IEEE Xplore Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/H2RBW5XK/Forsythe and Buchanan - 1989 - Knowledge acquisition for expert systems some pit.pdf:application/pdf},
}

@article{mindell_ocean_2003,
	title = {An {Ocean} in {Common}: {American} {Naval} {Officers}, {Scientists}, and the {Ocean} {Environment} (review)},
	volume = {44},
	issn = {1097-3729},
	shorttitle = {An {Ocean} in {Common}},
	url = {http://muse.jhu.edu/journals/technology_and_culture/v044/44.2mindell.html},
	doi = {10.1353/tech.2003.0082},
	number = {2},
	urldate = {2013-08-05},
	journal = {Technology and Culture},
	author = {Mindell, David A.},
	year = {2003},
	note = {{\textless}p{\textgreater}Volume 44, Number 2, April 2003{\textless}/p{\textgreater}},
	pages = {437--439},
	file = {Mindell - 2003 - An Ocean in Common American Naval Officers, Scien.pdf:/Users/rca2t1/Dropbox/Zotero/storage/6GU737PD/Mindell - 2003 - An Ocean in Common American Naval Officers, Scien.pdf:application/pdf;Project MUSE Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/7R8SU9BE/44.2mindell.html:text/html},
}

@article{mindell_opening_2000,
	title = {Opening {Black}'s {Box}: {Rethinking} {Feedback}'s {Myth} of {Origin}},
	volume = {41},
	issn = {1097-3729},
	shorttitle = {Opening {Black}'s {Box}},
	url = {http://muse.jhu.edu/journals/technology_and_culture/v041/41.3mindell.html},
	abstract = {In lieu of an abstract, here is a brief excerpt of the content:
        
Technology and Culture 41.3 (2000) 405-434
Figures
The specific triumph of the technical imagination
rested on the ability to dissociate lifting power from the arm and
create a crane: to dissociate work from the action of men and
animals and create the water-mill: to dissociate light from the
combustion of wood and oil and create the electric
lamp.
--Lewis Mumford
The engineer who embarks on the design of a feedback
amplifier must be a creature of mixed emotions.
--Hendrik Bode
Like any modern episteme worthy of the name, the theory of
feedback has a myth of origin. On a sunny August morning in 1927,
Harold Black, a twenty-nine-year-old systems engineer, rode the
Lackawanna ferry to work at the Bell Telephone Laboratories. Many
Bell engineers lived in New Jersey, and on the early morning ferry
rides across the Hudson to the Manhattan laboratories they
frequently gathered on the forward deck. This morning Black stood
alone, staring at the Statue of Liberty, and had an epiphany: "I
suddenly realized that if I fed the amplifier output back to the
input, in reverse phase, and kept the device from oscillating
(singing, as we called it then), I would have exactly what I
wanted: a means of canceling out the distortion in the output." As
it happened, the New York Times that day contained a blank
page, and Black sketched his idea, "a simple canonical diagram of a
negative feedback amplifier plus the equations for the
amplification with feedback." He rushed into work, asked a
technician to wire up a prototype, and gave birth to a foundational
circuit of modern electronics. This story has become enshrined as
one of the central "flashes of insight" in electrical engineering
in this century, periodically retold as an inspiration for
engineers. A common textbook on control engineering reprints the
story of Black's vision verbatim in the first chapter.
At Bell Laboratories from 1927 to 1940, the legend goes, Black,
Harry Nyquist, and Hendrik Bode laid the foundations of feedback
control that engineers then applied to all types of closed-loop
systems, from servomechanisms to thermostats, fire control systems
to automatic computers. More than other contemporary narratives of
control systems such as automatic pilots or servomechanisms, this
story of feedback earned a place in engineering legend and college
textbooks. It produced design methods and graphical techniques that
carry their author's names (the Bode plot, the Nyquist diagram) and
earned telephone engineering a claim to priority in feedback
history. Feedback theory, moreover, formed the basis of
cybernetics, systems theory, and a host of other post-World War II
information sciences, so Black's invention is hailed as a
foundation of the information age.
Feedback is indeed a fundamental concept in twentieth-century
technology, and the Bell Labs feedback theorists did lay critical
foundations for it. But the origin myth effaces its sources. It
skips over the inventors themselves and the ways in which their
backgrounds and prior experience influenced their work. It reveals
little about the concrete problems these men worked on when they
produced their solutions. The story also removes feedback theory
from its engineering culture, that of the telephone network between
the world wars. Black's version also does not account for the
relationship of his feedback amplifiers to prior traditions of
governors and self-regulating machinery.
Thus a reexamination of the sources is in order, retelling
Black's legend not as a heroic tale but as the story of an engineer
solving the technical problems of a particular place and time and
trying to convince others to support his solutions. As it turns
out, Black did not understand as much about feedback as he later
recalled. To make his idea credible, he needed Nyquist's
reformulation of the problem of stability and Bode's analysis
outlining the tight constraints that a feedback amplifier had to
meet. He also needed the Bell System. Negative-feedback amplifiers
emerged from efforts to extend the telephone network across the
continent, to increase the network's carrying capacity, and to make
it work predictably in the face of changes in season, weather, and
landscape -- from the context, that is, of building a large
technical...},
	number = {3},
	urldate = {2013-08-05},
	journal = {Technology and Culture},
	author = {Mindell, David A.},
	year = {2000},
	note = {{\textless}p{\textgreater}Volume 41, Number 3, July 2000{\textless}/p{\textgreater}},
	pages = {405--434},
	file = {Mindell - 2000 - Opening Black's Box Rethinking Feedback's Myth of.pdf:/Users/rca2t1/Dropbox/Zotero/storage/CNKJFKXH/Mindell - 2000 - Opening Black's Box Rethinking Feedback's Myth of.pdf:application/pdf;Project MUSE Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/P5J2PGWG/41.3mindell.html:text/html},
}

@book{yovits_self-organizing_1960,
	title = {Self-{Organizing} {Systems}},
	url = {http://archive.org/details/SelfOrganizingSystems},
	urldate = {2013-07-30},
	author = {Yovits, Marshall C. and Cameron, Scott},
	year = {1960},
	keywords = {Cameron, Scott, Eds},
}

@article{suchman_artificial_1993,
	title = {Artificial {Intelligence} as {Craftwork}},
	url = {http://books.google.com/books?id=iR_YTUIHoMgC&lpg=PA144&ots=fvkYHQIfo4&dq=lucy%20suchman&lr&pg=PA144#v=onepage&q&f=false},
	journal = {Understanding practice: Perspectives on activity and context},
	author = {Suchman, Lucy A. and Trigg, Randall},
	year = {1993},
	keywords = {artificial intelligence},
	pages = {144--178},
}

@article{suchman_categories_1994,
	title = {Do {Categories} {Have} {Politics}?},
	volume = {2},
	issn = {0925-9724},
	url = {http://www.springerlink.com/content/q37372236m358448/abstract/},
	doi = {10.1007/BF00749015},
	abstract = {Drawing on writings within the CSCW community and on recent social theory, this paper proposes that the adoption of speech act theory as a foundation for system design carries with it an agenda of discipline and control over organization members' actions. I begin with a brief review of the language/action perspective introduced by Winograd, Flores and their colleagues, focusing in particular on the categorization of speakers' intent. I then turn to some observations on the politics of categorization and, with that framework as back-ground, consider the attempt, throughthe coordinator, to implement a technological system for intention-accounting within organizations. Finally, I suggest the implications of the analysis presented in the paper for the politics of CSCW systems design.},
	number = {3},
	urldate = {2012-04-03},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Suchman, Lucy},
	year = {1994},
	keywords = {Computer science, Categorization},
	pages = {177--190},
	file = {Suchman - 1994 - Do Categories Have Politics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RDDN2T7S/Suchman - 1994 - Do Categories Have Politics.pdf:application/pdf;Suchman_categories_1994.pdf:/Users/ontoligent/Desktop/Suchman_categories_1994.pdf:application/pdf},
}

@article{suchman_office_1983,
	title = {Office {Procedure} as {Practical} {Action}: {Models} of {Work} and {System} {Design}},
	volume = {1},
	issn = {1046-8188},
	shorttitle = {Office procedure as practical action},
	url = {http://doi.acm.org/10.1145/357442.357445},
	doi = {10.1145/357442.357445},
	number = {4},
	urldate = {2012-04-03},
	journal = {ACM Trans. Inf. Syst.},
	author = {Suchman, Lucy A.},
	month = oct,
	year = {1983},
	pages = {320--328},
	file = {Suchman - 1983 - Office procedure as practical action models of wo.pdf:/Users/rca2t1/Dropbox/Zotero/storage/85J6PZR3/Suchman - 1983 - Office procedure as practical action models of wo.pdf:application/pdf},
}

@article{suchman_affiliative_2005,
	title = {Affiliative {Objects}},
	volume = {12},
	issn = {1350-5084, 1461-7323},
	url = {http://org.sagepub.com/content/12/3/379},
	doi = {10.1177/1350508405051276},
	abstract = {Through the case of a particular organization devoted to technological research and development, this paper investigates how values of the ‘new’ operate in what Appadurai (1986) has characterized as the social life of objects. Drawing on previous scholarship in anthropology and science and technology studies, I adopt the trope of the ‘affiliative object’ to describe the relational dynamics of association (and disassociation) that characterize the identification of objects and persons. This perspective emphasizes the multiplicity of objects within the unfolding and uncertain trajectories of organizational life, as both problem and resource for organization members. The paper examines how ‘object-centered sociality’ (Knorr-Cetina, 1997) is enacted as a strategic, but also contingent, resource in the alignment of professional identities and organizational positionings.},
	language = {en},
	number = {3},
	urldate = {2013-12-11},
	journal = {Organization},
	author = {Suchman, Lucy},
	month = may,
	year = {2005},
	keywords = {materiality, identity, invention, multiplicity, object-centered sociality},
	pages = {379--399},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/R38D7JIP/379.html:text/html;Suchman - 2005 - Affiliative Objects.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HFAS4E74/Suchman - 2005 - Affiliative Objects.pdf:application/pdf},
}

@article{pollock_forget_nodate,
	chapter = {News},
	title = {Forget {Big} {Data}, {Small} {Data} {Is} the {Real} {Revolution}},
	issn = {0261-3077},
	url = {http://www.guardian.co.uk/news/datablog/2013/apr/25/forget-big-data-small-data-revolution},
	abstract = {Rufus Pollock, Founder and Co-Director of the Open Knowledge Foundation, discusses why current hype around big data misses the point, and why the real revolution is small data, loosely joined• More from the Guardian on big data• More data journalism and data visualisations from the Guardian},
	language = {en-GB},
	urldate = {2013-05-02},
	journal = {The Guardian},
	author = {Pollock, Rufus},
	keywords = {big data, Global development, Transparency},
	file = {Guardian Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4QI22VIS/forget-big-data-small-data-revolution.html:text/html},
}

@incollection{wiener_organization_1950,
	title = {Organization of the {Message}},
	booktitle = {The {Human} {Use} of {Human} {Beings}},
	author = {Wiener, Norbet},
	year = {1950},
	note = {00000},
	file = {Wiener - 1950 - Organization of the Message.pdf:/Users/rca2t1/Dropbox/Zotero/storage/IISKKBSM/Wiener - 1950 - Organization of the Message.pdf:application/pdf},
}

@book{wiener_human_1950-1,
	title = {Human {Use} of {Human} {Beings}: {Cybernetics} and {Society}},
	shorttitle = {Human use of human beings},
	url = {http://books.google.com/books?hl=en&lr=&id=l9l6zquHvZIC&oi=fnd&pg=PA6&dq=%22the+human+use+of+human+beings%22&ots=Je-DrClnlG&sig=kCzi4XSBaL83CtjgiEeSK9OzrTs},
	urldate = {2013-12-29},
	publisher = {Da Capo Press},
	author = {Wiener, Norbert},
	year = {1950},
	note = {02963},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/J6IQ6SPP/books.html:text/html;Wiener - 1988 - Human use of human beings Cybernetics and society.pdf:/Users/rca2t1/Dropbox/Zotero/storage/KJCKJ3NC/Wiener - 1988 - Human use of human beings Cybernetics and society.pdf:application/pdf},
}

@article{bateson_cybernetics_1971,
	title = {The {Cybernetics} {Of}'self': {A} {Theory} of {Alcoholism}},
	volume = {34},
	shorttitle = {The cybernetics of'self'},
	url = {http://ift-malta.com/wp-content/uploads/2012/07/The-cybernetics-of-self-A-theory-of-alcoholism.pdf},
	number = {1},
	urldate = {2013-11-21},
	journal = {Psychiatry},
	author = {Bateson, Gregory},
	year = {1971},
	note = {00387},
	keywords = {Transduction},
	pages = {1--18},
	annote = {Key passage about transduction:
Even in very simple self-corrective systems, this holistic character is evident. In the steam engine with a "governor, the very word "governor" is a misnomer if it be taken to mean that this part of the system has unilateral control. The governor is, essentially, a sense organ or transducer which receives a transform of the difference between the actual running speed of the engine and some ideal or preferred speed. This sense organ transforms these differences into differences in some efferent message, for example, to fuel supply or to a brake. The behavior of the governor is determined, in other words, by the behavior of the other parts of the system, and indirectly by its own behavior at a previous time.},
	file = {Bateson - 1971 - The cybernetics of'self' A theory of alcoholism.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3BG74UGE/Bateson - 1971 - The cybernetics of'self' A theory of alcoholism.pdf:application/pdf},
}

@misc{noauthor_mitx:_nodate,
	title = {{MITx}: {MAS}.{S69x}: {Big} {Data} and {Social} {Physics}},
	shorttitle = {{MITx}},
	url = {https://www.edx.org/course/mitx/mitx-mas-s69x-big-data-social-physics-1737},
	abstract = {Understanding big data, how to use it to improve companies, cities, and government, and best-practice for privacy},
	urldate = {2014-05-06},
	journal = {edX},
	keywords = {Course, MITx},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/DT4NBJ54/MITx MAS.S69x Big Data and Social Physics.html:text/html},
}

@article{mayurama_second_1963,
	title = {The second cybernetics},
	volume = {51},
	journal = {American Scientist},
	author = {Mayurama, Magoroh},
	year = {1963},
	note = {00014},
	pages = {164--79},
	file = {Mayurama - 1963 - The second cybernetics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/I5A5MEEC/Mayurama - 1963 - The second cybernetics.pdf:application/pdf},
}

@article{mills_situated_1940,
	title = {Situated {Actions} and {Vocabularies} of {Motive}},
	volume = {5},
	copyright = {Copyright © 1940 American Sociological Association},
	issn = {0003-1224},
	url = {http://www.jstor.org/stable/2084524},
	doi = {10.2307/2084524},
	number = {6},
	urldate = {2014-11-17},
	journal = {American Sociological Review},
	author = {Mills, C. Wright},
	month = dec,
	year = {1940},
	pages = {904--913},
	file = {Mills - 1940 - Situated Actions and Vocabularies of Motive.pdf:/Users/rca2t1/Dropbox/Zotero/storage/R7A68HSB/Mills - 1940 - Situated Actions and Vocabularies of Motive.pdf:application/pdf},
}

@book{hayashi_data_1998,
	address = {Kobe, Japan},
	title = {Data science, classification, and related methods: proceedings of the fifth {Conference} of the {International} {Federation} of {Classification} {Societies} ({IFCS}-96), {Kobe}, {Japan}, {March} 27-30, 1996},
	isbn = {978-4-431-70208-5},
	shorttitle = {Data science, classification, and related methods},
	abstract = {This is the proceedings of the Fifth Conference of the International Federation of Classification Societies held in Kobe, Japan, on March 27-30, 1996: The astounding increase in computer usage over the past decade and the ever-increasing scope of global communication networks have ushered in the information age; however, human intelligence is required to make sense of this sea of data and to use it effectively. Consequently, the rapidly developing cross-disciplinary field of data science has come of age. This volume contains selected papers from the Fifth Conference of the International Federation of Classification Societies (IFCS-96), held in Kobe, Japan, in March 1996. A wide range of topics is covered, including theoretical and methodological advances relating to data gathering, classification and clustering, exploratory and multivariate data analysis, and knowledge seeking and discovery. A broad view of the state of the art is presented, making this an essential work not only for data analysts, mathematicians, and statisticians but also for researchers involved in data processing at all stages from data gathering to decision making.},
	language = {en},
	publisher = {Springer},
	author = {Hayashi, Chikio},
	year = {1998},
	note = {00008},
	keywords = {Computers / Computer Science, Computers / Data Processing, Computers / Intelligence (AI) \& Semantics, MATHEMATICS / Probability \& Statistics / General, Business \& Economics / Economics / Theory, Computers / Expert Systems},
}

@book{weiss_predictive_1998,
	title = {Predictive data mining: a practical guide},
	publisher = {Morgan Kaufmann},
	author = {Weiss, Sholom M and Indurkhya, Nitin},
	year = {1998},
	annote = {Uses "big data" in text.},
}

@article{bourgoin_big_1995,
	title = {Big {Data}–{Better} {Returns}, {Leveraging} {Your} {Hidden} {Data} {Assets} to {Improve} {ROI}},
	journal = {Artificial Intelligence in the Capital Markets, Probus Publishing Company},
	author = {Bourgoin, MO and Smith, SJ},
	year = {1995},
}

@misc{dontha_origins_2017,
	title = {The {Origins} of {Big} {Data}},
	url = {http://www.kdnuggets.com/2017/02/origins-big-data.html},
	abstract = {Big Data has truly come of age in 2013 when OED introduced the term “Big Data” for the first time. But when was the term Big Data first used and Why? Here are the results of our investigation.},
	urldate = {2017-06-24},
	journal = {KDnuggets},
	author = {Dontha, Ramesh},
	month = feb,
	year = {2017},
	file = {The Origins of Big Data:/Users/rca2t1/Dropbox/Zotero/storage/PSZ8PMNB/origins-big-data.html:text/html},
}

@misc{reddy_who_2014,
	title = {Who {Actually} {Coined} the {Term} {Big} {Data}},
	url = {https://www.mytechlogy.com/IT-blogs/3199/who-actually-coined-the-term-big-data/},
	abstract = {Big Data as we speak, may be part of many Business leaders day to day conversations and thousands of professionals researching on extracting value from ...},
	urldate = {2017-06-24},
	journal = {MyTechLogy},
	author = {Reddy, Bharath},
	month = feb,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/SVUVK5P2/who-actually-coined-the-term-big-data.html:text/html},
}

@misc{mashey_big_1998,
	type = {{PowerPoint}},
	title = {Big {Data} ... and the {Next} {Wave} of {InfraStress}},
	url = {http://static.usenix.org/event/usenix99/invited_talks/mashey.pdf},
	author = {Mashey, John},
	year = {1998},
	file = {mashey.pdf:/Users/rca2t1/Dropbox/Zotero/storage/6AZBBEBW/mashey.pdf:application/pdf},
}

@article{doctorow_big_2008,
	title = {Big data: {Welcome} to the petacentre},
	volume = {455},
	copyright = {© 2008 Nature Publishing Group},
	issn = {0028-0836},
	shorttitle = {Big data},
	url = {http://www.nature.com/news/2008/080903/full/455016a.html},
	doi = {10.1038/455016a},
	abstract = {Nature - the world's best science and medicine on your desktop},
	language = {en},
	number = {7209},
	urldate = {2017-06-24},
	journal = {Nature News},
	author = {Doctorow, Cory},
	month = sep,
	year = {2008},
	pages = {16--21},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/95XBRJNT/455016a.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/THC8EC7N/455016a.html:text/html},
}

@article{nelson_big_2008,
	title = {Big data: {The} {Harvard} computers},
	volume = {455},
	copyright = {© 2008 Nature Publishing Group},
	issn = {0028-0836},
	shorttitle = {Big data},
	url = {http://www.nature.com/nature/journal/v455/n7209/full/455036a.html},
	doi = {10.1038/455036a},
	abstract = {The first mass data crunchers were people, not machines. Sue Nelson looks at the discoveries and legacy of the remarkable women of Harvard's Observatory.},
	language = {en},
	number = {7209},
	urldate = {2017-06-24},
	journal = {Nature},
	author = {Nelson, Sue},
	month = sep,
	year = {2008},
	pages = {36--37},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/R2RU66XW/455036a.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/28MFNUW5/455036a.html:text/html},
}

@misc{diebold_big_2000,
	title = {Big {Data} {Dynamic} {Factor} {Models} for {Macroeconomic} {Measurement} and {Forecasting}},
	url = {http://www.ssc.upenn.edu/~fdiebold/papers/paper40/temp-wc.PDF},
	abstract = {Discussion Read to the Eighth World Congress of the Econometric Society, Seattle, August. http://www.ssc.upenn.edu/{\textasciitilde}fdiebold/papers/paper40/temp-wc.PDF.},
	author = {Diebold, Francis X.},
	year = {2000},
}

@inproceedings{diebold_big_2003,
	title = {’{Big} {Data}’{Dynamic} factor models for macroeconomic measurement and forecasting},
	url = {https://books.google.com/books?hl=en&lr=&id=L4oc33OEAOoC&oi=fnd&pg=PA115&dq=%E2%80%9CBig+Data+Dynamic+Factor+Models+for+Macroeconomic+Measurement+and+Forecasting%22&ots=KrJABC18Cx&sig=YK7H6qvPliLd6KhuQ-iBkWbn32A},
	booktitle = {Advances in {Economics} and {Econometrics}: {Theory} and {Applications}, {Eighth} {World} {Congress} of the {Econometric} {Society},”(edited by {M}. {Dewatripont}, {LP} {Hansen} and {S}. {Turnovsky})},
	author = {Diebold, Francis X.},
	year = {2003},
	pages = {115--122},
	file = {[PDF] upenn.edu:/Users/rca2t1/Dropbox/Zotero/storage/T8TFK4WG/Diebold - 2003 - ’Big Data’Dynamic factor models for macroeconomic .pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/GJS87NGQ/books.html:text/html},
}

@article{lynch_big_2008,
	title = {Big data: {How} do your data grow?},
	volume = {455},
	copyright = {© 2008 Nature Publishing Group},
	issn = {0028-0836},
	shorttitle = {Big data},
	url = {http://www.nature.com/nature/journal/v455/n7209/full/455028a.html},
	doi = {10.1038/455028a},
	abstract = {Scientists need to ensure that their results will be managed for the long haul. Maintaining data takes big organization, says Clifford Lynch.},
	language = {en},
	number = {7209},
	urldate = {2017-06-24},
	journal = {Nature},
	author = {Lynch, Clifford},
	month = sep,
	year = {2008},
	pages = {28--29},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/68XV9B37/455028a.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JM4MBGHC/455028a.html:text/html},
}

@article{frankel_big_2008,
	title = {Big data: {Distilling} meaning from data},
	volume = {455},
	copyright = {© 2008 Nature Publishing Group},
	issn = {0028-0836},
	shorttitle = {Big data},
	url = {https://www.nature.com/nature/journal/v455/n7209/full/455030a.html},
	doi = {10.1038/455030a},
	abstract = {Buried in vast streams of data are clues to new science. But we may need to craft new lenses to see them, explain Felice Frankel and Rosalind Reid.},
	language = {en},
	number = {7209},
	urldate = {2017-06-24},
	journal = {Nature},
	author = {Frankel, Felice and Reid, Rosalind},
	month = sep,
	year = {2008},
	pages = {30--30},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/8WRKS8BV/455030a.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/93KME8AA/455030a.html:text/html},
}

@misc{noauthor_randal_nodate,
	title = {Randal {Bryant}, {Randy} {H}. {Katz} and {Edward} {D}. {Lazowska}, “{Big}-{Data} {Computing}: {Creating} {Revolutionary} {Breakthroughs} in {Commerce}, {Science} and {Society},” {December} 2008, pp. 1-15, at http://www.cra.org/ccc/docs/init/{Big}\_Data.pdf. - {Google} {Search}},
	url = {https://www.google.com/search?q=Randal+Bryant%2C+Randy+H.+Katz+and+Edward+D.+Lazowska%2C+%E2%80%9CBig-Data+Computing%3A+Creating+Revolutionary+Breakthroughs+in+Commerce%2C+Science+and+Society%2C%E2%80%9D+December+2008%2C+pp.+1-15%2C+at+http%3A%2F%2Fwww.cra.org%2Fccc%2Fdocs%2Finit%2FBig_Data.pdf.&oq=Randal+Bryant%2C+Randy+H.+Katz+and+Edward+D.+Lazowska%2C+%E2%80%9CBig-Data+Computing%3A+Creating+Revolutionary+Breakthroughs+in+Commerce%2C+Science+and+Society%2C%E2%80%9D+December+2008%2C+pp.+1-15%2C+at+http%3A%2F%2Fwww.cra.org%2Fccc%2Fdocs%2Finit%2FBig_Data.pdf.&aqs=chrome..69i57.911j0j7&sourceid=chrome&ie=UTF-8},
	urldate = {2017-06-24},
	file = {Randal Bryant, Randy H. Katz and Edward D. Lazowska, “Big-Data Computing\: Creating Revolutionary Breakthroughs in Commerce, Science and Society,” December 2008, pp. 1-15, at http\://www.cra.org/ccc/docs/init/Big_Data.pdf. - Google Search:/Users/rca2t1/Dropbox/Zotero/storage/WJDDBURW/search.html:text/html},
}

@article{laney_3d_2001,
	title = {3d {Data} {Management}: {Controlling} {Data} {Volume}, {Velocity} and {Variety}},
	volume = {6},
	shorttitle = {3d {Data} {Management}},
	journal = {META Group Research Note},
	author = {Laney, Doug},
	year = {2001},
	pages = {70},
	file = {Laney - 2001 - 3D data management Controlling data volume, veloc.pdf:/Users/rca2t1/Dropbox/Zotero/storage/38RWYKIE/Laney - 2001 - 3D data management Controlling data volume, veloc.pdf:application/pdf},
}

@misc{owen_what_2015,
	title = {What “50 {Years} of {Data} {Science}” {Leaves} {Out}},
	url = {https://medium.com/@srowen/what-50-years-of-data-science-leaves-out-2366c9b61d3d},
	abstract = {“50 Years of Data Science” takes back the word for Statistics and dismisses big data. The reality is grayer.},
	urldate = {2017-02-11},
	journal = {Sean Owen},
	author = {Owen, Sean},
	month = nov,
	year = {2015},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/C8Z7BWDR/what-50-years-of-data-science-leaves-out-2366c9b61d3d.html:text/html},
}

@misc{davenport_data_2012,
	title = {Data {Scientist}: {The} {Sexiest} {Job} of the 21st {Century}},
	shorttitle = {Data {Scientist}},
	url = {https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century},
	abstract = {Meet the people who can coax treasure out of messy, unstructured data.},
	urldate = {2017-02-11},
	journal = {Harvard Business Review},
	author = {Davenport, Thomas H. and Patil, D. J.},
	month = oct,
	year = {2012},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/DI7SWIBB/data-scientist-the-sexiest-job-of-the-21st-century.html:text/html},
}

@techreport{manyika_big_2011,
	title = {Big {Data}: {The} {Next} {Frontier} for {Innovation}, {Competition}, and {Productivity}},
	shorttitle = {Big {Data}},
	url = {http://www.mckinsey.com/business-functions/digital-mckinsey/our-insights/big-data-the-next-frontier-for-innovation},
	abstract = {Big data will become a key basis of competition, underpinning new waves of productivity growth, innovation, and consumer surplus--as long as the right policies and enablers are in place.},
	urldate = {2017-01-28},
	institution = {Mckinsey \& Company},
	author = {Manyika, James and Chui, Michael and Brown, Brad and Bughin, Jacques and Dobbs, Richard and Roxburgh, Charles and Byers, Angela Hung},
	month = may,
	year = {2011},
	annote = {Basically argues that data is capital.},
	file = {Manyika et al. - 2011 - Big data The next frontier for innovation, compet.pdf:/Users/rca2t1/Dropbox/Zotero/storage/VF79Q3RU/Manyika et al. - 2011 - Big data The next frontier for innovation, compet.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WXUNG3AD/big-data-the-next-frontier-for-innovation.html:text/html},
}

@misc{noauthor_core_nodate,
	title = {The {Core} of {Data} {Science}},
	url = {http://www.kdnuggets.com/2016/08/core-data-science.html},
	urldate = {2017-01-28},
	file = {The Core of Data Science:/Users/rca2t1/Dropbox/Zotero/storage/TE8NQWU6/core-data-science.html:text/html},
}

@misc{garner_data_2016,
	title = {Data {Science} up and down the {Ladder} of {Abstraction}},
	url = {https://www.infoq.com/articles/data-science-abstraction},
	abstract = {Although Clojure lacks the extensive toolbox and analytic community of the most popular data science languages, R and Python, it provides a powerful environment for developing statistical thinking and for practicing effective data science.},
	urldate = {2017-01-28},
	journal = {InfoQ},
	author = {Garner, Henry},
	month = dec,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/PWMJZZFQ/data-science-abstraction.html:text/html},
}

@article{miller_more_2016,
	title = {More on {Statistics} vs {Data} {Science}},
	url = {http://www.information-management.com/blogs/data-management/more-on-statistics-vs-data-science-10030457-1.html},
	abstract = {Statistical models, which emphasize inference driven from underlying or generative probability distributions, are concerned with both explanation and prediction, while ML obsesses on prediction.},
	urldate = {2017-01-28},
	journal = {Information Management Blogs},
	author = {Miller, Steve},
	month = dec,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WZMDHNBN/more-on-statistics-vs-data-science-10030457-1.html:text/html},
}

@misc{noauthor_nsf_nodate,
	title = {{NSF} {Award} {Search}: {Award}\#1626983 - {Envisioning} the {Data} {Science} {Discipline}: {The} {Undergraduate} {Perspective}},
	url = {https://nsf.gov/awardsearch/showAward?AWD_ID=1626983&HistoricalAwards=false},
	urldate = {2016-11-22},
	note = {00000},
	file = {NSF Award Search\: Award#1626983 - Envisioning the Data Science Discipline\: The Undergraduate Perspective:/Users/rca2t1/Dropbox/Zotero/storage/TSAGGGFX/showAward.html:text/html},
}

@article{cleveland_data_2001,
	title = {Data {Science}: {An} {Action} {Plan} for {Expanding} the {Technical} {Areas} of the {Field} of {Statistics}},
	volume = {69},
	issn = {0306-7734},
	shorttitle = {Data {Science}},
	url = {http://www.jstor.org/stable/1403527},
	doi = {10.2307/1403527},
	abstract = {An action plan to enlarge the technical areas of statistics focuses on the data analyst. The plan sets out six technical areas of work for a university department, and advocates a specific allocation of resources devoted to research in each area and to courses in each area. The value of technical work is judged by the extent to which it benefits the data analyst, either directly or indirectly. The plan is also applicable to government research labs and corporate research organizations. /// Cet article propose un plan d'action pour élargir les domaines techniques de la statistique, centré sur l'analyste de données. Le plan présente six domaines techniques de travail pour un département d'université, et recommandre une répartition spécifique des ressources consacrées à la recherche et à l'enseignement dans chaque domaine. La valeur du travail technique est évaluée par l'intérêt qu'en retire l'analyste de données, soit directement soit indirectement. Le plan est aussi applicable aux laboratoires publics de recherche et aux sociétés de recherche privées.},
	number = {1},
	urldate = {2016-07-02},
	journal = {International Statistical Review / Revue Internationale de Statistique},
	author = {Cleveland, William S.},
	year = {2001},
	pages = {21--26},
	file = {Cleveland - 2001 - Data Science An Action Plan for Expanding the Tec.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HC2C5D2B/Cleveland - 2001 - Data Science An Action Plan for Expanding the Tec.pdf:application/pdf},
}

@book{loukides_what_2011,
	title = {What is data science?},
	url = {https://books.google.com/books?hl=en&lr=&id=-OQ2q5JqOdEC&oi=fnd&pg=PT2&dq=%22data+science%22&ots=1Y7O922KDq&sig=yQ1XsyNG6eckn6oUjVjfvtNzKzY},
	urldate = {2016-07-02},
	publisher = {" O'Reilly Media, Inc."},
	author = {Loukides, Mike},
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/34M339AB/books.html:text/html},
}

@article{tukey_future_1962,
	title = {The {Future} of {Data} {Analysis}},
	volume = {33},
	issn = {0003-4851},
	url = {http://www.jstor.org/stable/2237638},
	number = {1},
	urldate = {2016-05-23},
	journal = {The Annals of Mathematical Statistics},
	author = {Tukey, John W.},
	year = {1962},
	pages = {1--67},
	annote = {"All in all, I have come to feel that my central interest is in data analysis, which I take to include, among other things: procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data."},
	file = {Tukey - 1962 - The Future of Data Analysis.pdf:/Users/rca2t1/Dropbox/Zotero/storage/EQ7IKP5I/Tukey - 1962 - The Future of Data Analysis.pdf:application/pdf},
}

@article{alvarado_big_2017,
	title = {Big {Data}, {Thick} {Mediation}, and {Representational} {Opacity}},
	volume = {48},
	issn = {1080-661X},
	url = {https://muse.jhu.edu/article/685099},
	doi = {10.1353/nlh.2017.0037},
	abstract = {{\textless}p{\textgreater}In 2008, the phrase "big data" shifted in meaning. It turned from referring to a problem and an opportunity for organizations with very large data sets to being the talisman for an emerging economic and cultural order that is both celebrated and feared for its deep and pervasive effects on the human condition. Economically, the phrase now denotes a data-mediated form of commerce exemplified by Google. Culturally, the phrase stands for a new form of knowledge and knowledge production. In this essay, we explore the connection between these two implicit meanings, considered as dimensions of a real social and scientific transformation with observable properties. We develop three central concepts: the datasphere, thick mediation, and representational opacity. These concepts provide a theoretical framework for making sense of how the economic and cultural dimensions interact to produce a set of effects, problems, and opportunities, not all of which have been addressed by big data's critics and advocates.{\textless}/p{\textgreater}},
	language = {en},
	number = {4},
	urldate = {2018-02-26},
	journal = {New Literary History},
	author = {Alvarado, Rafael and Humphreys, Paul},
	year = {2017},
	pages = {729--749},
}

@article{press_very_2013,
	title = {A {Very} {Short} {History} {Of} {Data} {Science}},
	url = {https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/},
	abstract = {The story of how data scientists became sexy is mostly the story of the coupling of the mature discipline of statistics with a very young one--computer science.  The term “Data Science” has emerged only recently to specifically designate a new profession that is expected to make sense of the vast [...]},
	language = {en},
	urldate = {2018-04-10},
	journal = {Forbes},
	author = {Press, Gil},
	month = may,
	year = {2013},
	annote = {Shows that data science emerges within information tech first, although Tukey's Data Analysis precedes this.},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/HJ8F5TYL/a-very-short-history-of-data-science.html:text/html},
}

@misc{wladawsky-berger_why_2014,
	title = {Why {Do} {We} {Need} {Data} {Science} {When} {We}’ve {Had} {Statistics} for {Centuries}?},
	url = {https://blogs.wsj.com/cio/2014/05/02/why-do-we-need-data-science-when-weve-had-statistics-for-centuries/},
	abstract = {Because while statistics can explain something happening now, data science aims to discover and extract actionable knowledge that can be used to make decisions and predictions, writes Guest Columnist Irving Wladawsky-Berger. And now, "given our newfound ability to gather valuable data on almost any topic," he writes, data science "can now apply to softer disciplines like the health and social sciences."},
	language = {en-US},
	urldate = {2018-04-10},
	journal = {WSJ},
	author = {Wladawsky-Berger, Irving},
	month = may,
	year = {2014},
	keywords = {DATA SCIENCE, DATA SCIENTIST},
}

@article{breiman_statistical_2001,
	title = {Statistical {Modeling}: {The} {Two} {Cultures}},
	volume = {16},
	issn = {0883-4237, 2168-8745},
	shorttitle = {Statistical {Modeling}},
	url = {https://projecteuclid.org/euclid.ss/1009213726},
	doi = {10.1214/ss/1009213726},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.

Includes comments and a rejoinder by the author.},
	language = {en},
	number = {3},
	urldate = {2018-04-10},
	journal = {Statistical Science},
	author = {Breiman, Leo},
	month = aug,
	year = {2001},
	mrnumber = {MR1874152},
	zmnumber = {1059.62505},
	pages = {199--231},
	file = {Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:/Users/rca2t1/Dropbox/Zotero/storage/FDJ6DMNE/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/45QH645A/1009213726.html:text/html},
}

@article{donoho_50_2017,
	title = {50 {Years} of {Data} {Science}},
	volume = {26},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2017.1384734},
	doi = {10.1080/10618600.2017.1384734},
	abstract = {More than 50 years ago, John Tukey called for a reformation of academic statistics. In “The Future of Data Analysis,” he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or “data analysis.” Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name “data science” for this envisioned field. A recent and growing phenomenon has been the emergence of “data science” programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a \$100M “Data Science Initiative” that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as “cultural appropriation.” This article reviews some ingredients of the current “data science moment,” including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for “scaling up” to “big data.” This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere “scaling up,” but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts field-by-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are “learning from data,” and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today’s data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.},
	number = {4},
	urldate = {2018-04-13},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Donoho, David},
	month = oct,
	year = {2017},
	keywords = {Cross-study analysis, Data analysis, Data science, Meta analysis, Predictive modeling, Quantitative programming environments, Statistics},
	pages = {745--766},
	file = {Donoho - 2017 - 50 Years of Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HWSGEDEQ/Donoho - 2017 - 50 Years of Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/FRWV6XWK/10618600.2017.html:text/html},
}

@misc{donoho_high-dimensional_2000,
	title = {High-{Dimensional} {Data} {Analysis}: {The} {Curses} and {Blessings} of {Dimensionality}},
	url = {http://statweb.stanford.edu/~donoho/Lectures/AMS2000/AMS2000.html},
	abstract = {My lecture "High-Dimensional Data Analysis: The Curses and Blessings of Dimensionality" was delivered the morning of August 8, 2000, exactly 100 years to the day after David Hilbert's Math. Problems lecture of August 8 1900. However, my 23 problems of that day had largely to do with my own chromosome pairs and the inherent limitations they impose.},
	author = {Donoho, David},
	month = aug,
	year = {2000},
	file = {Donoho - 2000 - High-Dimensional Data Analysis The Curses and Ble.pdf:/Users/rca2t1/Dropbox/Zotero/storage/BJQRD4AG/Donoho - 2000 - High-Dimensional Data Analysis The Curses and Ble.pdf:application/pdf;MathChallengeSlides2_2.pdf:/Users/rca2t1/Dropbox/Zotero/storage/AVUFVMZN/MathChallengeSlides2_2.pdf:application/pdf},
}

@article{hernan_data_2018,
	title = {Data {Science} {Is} {Science}'s {Second} {Chance} to {Get} {Causal} {Inference} {Right}: {A} {Classification} of {Data} {Science} {Tasks}},
	shorttitle = {Data {Science} {Is} {Science}'s {Second} {Chance} to {Get} {Causal} {Inference} {Right}},
	journal = {arXiv preprint arXiv:1804.10846},
	author = {Hernán, Miguel A. and Hsu, John and Healy, Brian},
	year = {2018},
	file = {Hernán et al. - 2018 - Data science is science's second chance to get cau.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2E9EW42T/Hernán et al. - 2018 - Data science is science's second chance to get cau.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WNAFVUTT/1804.html:text/html},
}

@article{beaton_how_2016,
	title = {How to {Respond} to {Data} {Science}: {Early} {Data} {Criticism} by {Lionel} {Trilling}},
	volume = {51},
	issn = {2166-3033},
	shorttitle = {How to {Respond} to {Data} {Science}},
	url = {https://muse.jhu.edu/article/624953},
	doi = {10.1353/lac.2016.0014},
	abstract = {{\textless}p{\textgreater}This article was originally drafted just four weeks after the publishing of \textit{Dataclysm}, a 2014 book by Christian Rudder that sought to popularize data and data science by, in part, dismissing the social sciences and humanities as obsolete approaches to knowledge production. In looking for a potential way of responding to data scientists like Rudder, this article examines a 1948–50 essay about data that was written by Lionel Trilling (1905–75). Trilling frames data as part of our broader cultural history, which includes literature, drama, epic poetry, and the arts. This article argues that what Trilling models in the essay is a line of writing and thinking about data—a type of \textit{data criticism}—that today offers tremendous promise for responding to data science and to evangelists like Christian Rudder.{\textless}/p{\textgreater}},
	language = {en},
	number = {3},
	urldate = {2018-05-10},
	journal = {Information \& Culture: A Journal of History},
	author = {Beaton, Brian},
	month = jul,
	year = {2016},
	pages = {352--372},
	file = {Beaton - 2016 - How to Respond to Data Science Early Data Critici.pdf:/Users/rca2t1/Dropbox/Zotero/storage/S8FYL6X8/Beaton - 2016 - How to Respond to Data Science Early Data Critici.pdf:application/pdf},
}

@misc{noauthor_goodbye_2010,
	title = {Goodbye {Polling}, {Hello} {Big} {Data}},
	url = {https://enga.ge/goodbye-polling-hello-big-data/},
	abstract = {Whenever a pundit rushes to proclaim the “death of” something, that”s the surest sign it”ll probably outlive the person making that bold prediction. Nonetheless, as a general rule, I tend to bet on the future and the old incumbent industries and ways of doing things (eventually) being dislodged, even if progress in that direction is …},
	language = {en},
	urldate = {2019-04-09},
	journal = {Engage},
	month = nov,
	year = {2010},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TNETM8X8/goodbye-polling-hello-big-data.html:text/html},
}

@inproceedings{hayashi_what_1998,
	series = {Studies in {Classification}, {Data} {Analysis}, and {Knowledge} {Organization}},
	title = {What is {Data} {Science}? {Fundamental} {Concepts} and a {Heuristic} {Example}},
	isbn = {978-4-431-65950-1},
	shorttitle = {What is {Data} {Science} ?},
	abstract = {SummaryData Science is not only a synthetic concept to unify statistics, data analysis and their related methods but also comprises its results. It includes three phases, design for data, collection of data, and analysis on data. Fundamental concepts and various methods based on it are discussed with a heuristic example.},
	language = {en},
	booktitle = {Data {Science}, {Classification}, and {Related} {Methods}},
	publisher = {Springer Japan},
	author = {Hayashi, Chikio},
	editor = {Hayashi, Chikio and Yajima, Keiji and Bock, Hans-Hermann and Ohsumi, Noboru and Tanaka, Yutaka and Baba, Yasumasa},
	year = {1998},
	keywords = {Comparative Survey, Cultural Sphere, Exploratory Approach, National Character, Opinion Distribution},
	pages = {40--51},
	file = {Hayashi - 1998 - What is Data Science Fundamental Concepts and a H.pdf:/Users/rca2t1/Dropbox/Zotero/storage/8DLV8W23/Hayashi - 1998 - What is Data Science Fundamental Concepts and a H.pdf:application/pdf},
}

@book{vapnik_nature_2000,
	edition = {2nd},
	series = {Statistics for {Engineering} and {Information} {Science}},
	title = {The {Nature} of {Statistical} {Learning} {Theory}},
	publisher = {Springer},
	author = {Vapnik, Vladimir},
	year = {2000},
}

@book{janssens_data_2014,
	edition = {First},
	title = {Data {Science} at the {Command} {Line}},
	url = {https://www.datascienceatthecommandline.com/},
	abstract = {This hands-on guide demonstrates how the flexibility of the command line can help you become a more efficient and productive data scientist. You’ll learn how to combine small, yet powerful, command-line tools to quickly obtain, scrub, explore, and model your data.},
	urldate = {2020-05-13},
	publisher = {O'Reilly},
	author = {Janssens, Jeroen},
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BMZ3NH9X/www.datascienceatthecommandline.com.html:text/html},
}

@misc{mason_taxonomy_2010,
	title = {A {Taxonomy} of {Data} {Science}},
	url = {http://www.dataists.com/2010/09/a-taxonomy-of-data-science/},
	language = {en-US},
	urldate = {2020-05-13},
	journal = {Dataists},
	author = {Mason, Hilary and Wiggins, Christopher},
	month = sep,
	year = {2010},
	note = {Library Catalog: www.dataists.com},
	file = {Mason and Wiggins - 2010 - A Taxonomy of Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/C2GWUV6X/Mason and Wiggins - 2010 - A Taxonomy of Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/MKKKL2PM/a-taxonomy-of-data-science.html:text/html},
}

@article{de_veaux_curriculum_2017,
	title = {Curriculum {Guidelines} for {Undergraduate} {Programs} in {Data} {Science}},
	volume = {4},
	issn = {2326-8298},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-statistics-060116-053930},
	doi = {10.1146/annurev-statistics-060116-053930},
	abstract = {The Park City Math Institute 2016 Summer Undergraduate Faculty Program met for the purpose of composing guidelines for undergraduate programs in data science. The group consisted of 25 undergraduate faculty from a variety of institutions in the United States, primarily from the disciplines of mathematics, statistics, and computer science. These guidelines are meant to provide some structure for institutions planning for or revising a major in data science.},
	number = {1},
	urldate = {2020-05-13},
	journal = {Annual Review of Statistics and Its Application},
	author = {De Veaux, Richard D. and Agarwal, Mahesh and Averett, Maia and Baumer, Benjamin S. and Bray, Andrew and Bressoud, Thomas C. and Bryant, Lance and Cheng, Lei Z. and Francis, Amanda and Gould, Robert and Kim, Albert Y. and Kretchmar, Matt and Lu, Qin and Moskol, Ann and Nolan, Deborah and Pelayo, Roberto and Raleigh, Sean and Sethi, Ricky J. and Sondjaja, Mutiara and Tiruviluamala, Neelesh and Uhlig, Paul X. and Washington, Talitha M. and Wesley, Curtis L. and White, David and Ye, Ping},
	month = mar,
	year = {2017},
	note = {Publisher: Annual Reviews},
	pages = {15--30},
	file = {De Veaux et al. - 2017 - Curriculum Guidelines for Undergraduate Programs i.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RA3BPZKR/De Veaux et al. - 2017 - Curriculum Guidelines for Undergraduate Programs i.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4E7PWGAX/annurev-statistics-060116-053930.html:text/html},
}

@misc{das_data_2019,
	title = {Data {Science} {Life} {Cycle} 101 for {Dummies} like {Me}},
	url = {https://towardsdatascience.com/data-science-life-cycle-101-for-dummies-like-me-e66b47ad8d8f},
	abstract = {Data science is quickly evolving to be one of the hottest fields in the technology industry. With rapid advancements in computational…},
	language = {en},
	urldate = {2020-05-13},
	journal = {Medium},
	author = {Das, Sangeet Moy},
	month = sep,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/9IA53YBR/data-science-life-cycle-101-for-dummies-like-me-e66b47ad8d8f.html:text/html},
}

@book{hayashi_data_2013,
	title = {Data {Science}, {Classification}, and {Related} {Methods}: {Proceedings} of the {Fifth} {Conference} of the {International} {Federation} of {Classification} {Societies} ({IFCS}-96), {Kobe}, {Japan}, {March} 27–30, 1996},
	isbn = {978-4-431-65950-1},
	shorttitle = {Data {Science}, {Classification}, and {Related} {Methods}},
	abstract = {This volume, Data Science, Classification, and Related Methods, contains a selection of papers presented at the Fifth Conference of the International Federation of Oassification Societies (IFCS-96), which was held in Kobe, Japan, from March 27 to 30,1996. The volume covers a wide range of topics and perspectives in the growing field of data science, including theoretical and methodological advances in domains relating to data gathering, classification and clustering, exploratory and multivariate data analysis, and knowledge discovery and seeking. It gives a broad view of the state of the art and is intended for those in the scientific community who either develop new data analysis methods or gather data and use search tools for analyzing and interpreting large and complex data sets. Presenting a wide field of applications, this book is of interest not only to data analysts, mathematicians, and statisticians but also to scientists from many areas and disciplines concerned with complex data: medicine, biology, space science, geoscience, environmental science, infonnation science, image and pattern analysis, economics, statistics, social sciences, psychology, cognitive science, behavioral science, marketing and survey research, data mining, and knowledge organization.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Hayashi, Chikio and Yajima, Keiji and Bock, Hans H. and Ohsumi, Noboru and Tanaka, Yutaka and Baba, Yasumasa},
	month = nov,
	year = {2013},
	note = {Google-Books-ID: YGryCAAAQBAJ},
	keywords = {Business \& Economics / Economics / Theory, Computers / Data Modeling \& Design, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes, Computers / Programming / Algorithms},
}

@book{caffo_executive_2015,
	title = {Executive {Data} {Science}},
	url = {https://leanpub.com/eds},
	abstract = {This book teaches you how to assemble and lead a data science enterprise so that your organization can move towards extracting information from big data. This book is based on the acclaimed Johns Hopkins Executive Data Science Specialization. Printed copies of this book are available through Lulu.},
	language = {eng},
	urldate = {2020-05-14},
	publisher = {Leanpub},
	author = {Caffo, Brian and Peng, Roger D. and Leek, Jeffrey},
	month = jun,
	year = {2015},
	file = {Caffo et al. - 2015 - Executive Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/WQMFE35R/Caffo et al. - 2015 - Executive Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/A2YXM79I/eds.html:text/html},
}

@misc{vorhies_crisp-dm_2016,
	title = {{CRISP}-{DM} – a {Standard} {Methodology} to {Ensure} a {Good} {Outcome}},
	url = {https://www.datasciencecentral.com/profiles/blogs/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome},
	abstract = {Summary: To ensure quality in your data science group, make sure you’re enforcing a standard methodology. This includes not only traditional data analytic pr…},
	language = {en},
	urldate = {2020-05-15},
	journal = {Data Science Central},
	author = {Vorhies, William},
	month = jul,
	year = {2016},
	note = {Library Catalog: www.datasciencecentral.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/UDF5IMWD/crisp-dm-a-standard-methodology-to-ensure-a-good-outcome.html:text/html},
}

@misc{porter_framework_2020,
	title = {A {Framework} for {Data} {Science}},
	author = {Porter, Michael D.},
	month = may,
	year = {2020},
	file = {Porter - 2020 - A Framework for Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/YKL744PW/Porter - 2020 - A Framework for Data Science.pdf:application/pdf},
}

@article{wirth_crisp-dm_1999,
	title = {{CRISP}-{DM}: {Towards} a {Standard} {Process} {Model} for {Data} {Mining}},
	abstract = {The CRISP-DM (CRoss Industry Standard Process for Data Mining) project proposed a comprehensive process model for carrying out data mining projects. The process model is independent of both the industry sector and the technology used. In this paper we argue in favor of a standard process model for data mining and report some experiences with the CRISP-DM process model in practice.},
	author = {Wirth, Rüdiger and Hipp, Jochen},
	year = {1999},
	file = {Wirth and Hipp - CRISP-DM Towards a Standard Process Model for Dat.pdf:/Users/rca2t1/Dropbox/Zotero/storage/K427SX4Z/Wirth and Hipp - CRISP-DM Towards a Standard Process Model for Dat.pdf:application/pdf},
}

@article{studer_towards_2020,
	title = {Towards {CRISP}-{ML}({Q}): {A} {Machine} {Learning} {Process} {Model} with {Quality} {Assurance} {Methodology}},
	shorttitle = {Towards {CRISP}-{ML}({Q})},
	url = {http://arxiv.org/abs/2003.05155},
	abstract = {We propose a process model for the development of machine learning applications. It guides machine learning practitioners and project organizations from industry and academia with a checklist of tasks that spans the complete project life-cycle, ranging from the very first idea to the continuous maintenance of any machine learning application. With each task, we propose quality assurance methodology that is drawn from practical experience and scientific literature and that has proven to be general and stable enough to include them in best practices. We expand on CRISP-DM, a data mining process model that enjoys strong industry support but lacks to address machine learning specific tasks.},
	urldate = {2020-05-16},
	journal = {arXiv:2003.05155 [cs, stat]},
	author = {Studer, Stefan and Bui, Thanh Binh and Drescher, Christian and Hanuschkin, Alexander and Winkler, Ludwig and Peters, Steven and Mueller, Klaus-Robert},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.05155},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Computer Science - Software Engineering},
	annote = {Comment: Machine Learning Applications, Quality Assurance Methodology, Process Model, Best Practices for Machine Learning Applications, Automotive Industry and Academia, Best Practices, Guidelines},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/G5N9EMSG/Studer et al. - 2020 - Towards CRISP-ML(Q) A Machine Learning Process Mo.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/37P62DWE/2003.html:text/html},
}

@misc{lao_beginners_2019,
	title = {A {Beginner}’s {Guide} to the {Data} {Science} {Pipeline}},
	url = {https://towardsdatascience.com/a-beginners-guide-to-the-data-science-pipeline-a4904b2d8ad3},
	abstract = {“Believe it or not, you are no different than Data. Put yourself into Data’s shoes and you’ll see why.”},
	language = {en},
	urldate = {2020-05-17},
	journal = {Medium},
	author = {Lao, Randy},
	month = dec,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/HW55BE9L/a-beginners-guide-to-the-data-science-pipeline-a4904b2d8ad3.html:text/html},
}

@book{bramer_principles_2016,
	address = {London},
	series = {Undergraduate {Topics} in {Computer} {Science}},
	title = {Principles of {Data} {Mining}},
	isbn = {978-1-4471-7307-6},
	url = {https://doi.org/10.1007/978-1-4471-7307-6_1},
	language = {en},
	urldate = {2020-05-18},
	publisher = {Springer},
	author = {Bramer, Max},
	year = {2016},
	doi = {10.1007/978-1-4471-7307-6_1},
	keywords = {Association Rule, Data Mining Algorithm, Data Warehouse, Fraud Detection, Unlabelled Data},
	file = {Springer Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/9MELGEHA/Bramer - 2016 - Introduction to Data Mining.pdf:application/pdf},
}

@book{kelleher_data_2018,
	series = {The {MIT} {Press} {Essential} {Knowledge} {Series}},
	title = {Data {Science}},
	isbn = {978-0-262-53543-4},
	publisher = {MIT Press},
	author = {Kelleher, John D. and Tierney, Brendan},
	year = {2018},
	annote = {Uses CRISP-DM
 },
	file = {Kelleher and Tierney - 2018 - Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/VKJ7FIN5/Kelleher and Tierney - 2018 - Data Science.pdf:application/pdf},
}

@misc{conway_data_2010,
	title = {The {Data} {Science} {Venn} {Diagram}},
	url = {http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram},
	abstract = {On Monday I—humbly—joined a group of NYC's most sophisticated thinkers on all things data for a half-day  unconference  to help  O'Reily  organize their upcoming  Strata conference . The break out sessions were fantastic, and the number of people in each allowed for outstanding, expert driven, discu},
	language = {en-US},
	urldate = {2020-05-20},
	journal = {Drew Conway},
	author = {Conway, Drew},
	month = sep,
	year = {2010},
	note = {Library Catalog: drewconway.com},
	annote = {"As I have said before, I think the term "data science" is a bit of a misnomer, but I was very hopeful after this discussion; mostly because of the utter lack of agreement on what a curriculum on this subject would look like. The difficulty in defining these skills is that the split between substance and methodology is ambiguous, and as such it is unclear how to distinguish among hackers, statisticians, subject matter experts, their overlaps and where data science fits."},
	file = {Data_Science_VD.png:/Users/rca2t1/Dropbox/Zotero/storage/AZTN2TAS/Data_Science_VD.png:image/png;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ATHBGBBI/the-data-science-venn-diagram.html:text/html},
}

@misc{watters_data_2011,
	title = {Data science is a pipeline between academic disciplines},
	url = {http://radar.oreilly.com/2011/08/data-science-social-science-academic.html},
	abstract = {Strata speaker and PhD candidate Drew Conway discusses how data science is influencing the processes and outcomes of academic research in the social sciences.},
	language = {en-US},
	urldate = {2020-05-20},
	journal = {O'Reilly Radar},
	author = {Watters, Audrey},
	month = aug,
	year = {2011},
	note = {Library Catalog: radar.oreilly.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/M2GSMUWQ/data-science-social-science-academic.html:text/html},
}

@article{garber_data_2019,
	title = {Data {Science}: {What} the {Educated} {Citizen} {Needs} to {Know}},
	volume = {1},
	issn = {,},
	shorttitle = {Data {Science}},
	url = {https://hdsr.mitpress.mit.edu/pub/pjl0jtkp/release/4},
	doi = {10.1162/99608f92.88ba42cb},
	language = {en},
	number = {1},
	urldate = {2020-05-23},
	journal = {Harvard Data Science Review},
	author = {Garber, Alan M.},
	month = jun,
	year = {2019},
	note = {Publisher: PubPub},
	file = {Garber - 2019 - Data Science What the Educated Citizen Needs to K.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LVDZNTVZ/Garber - 2019 - Data Science What the Educated Citizen Needs to K.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JMFPS5XP/4.html:text/html},
}

@article{cao_data_2017,
	title = {Data {Science}: {A} {Comprehensive} {Overview}},
	volume = {50},
	issn = {0360-0300},
	shorttitle = {Data {Science}},
	url = {https://doi.org/10.1145/3076253},
	doi = {10.1145/3076253},
	abstract = {The 21st century has ushered in the age of big data and data economy, in which data DNA, which carries important knowledge, insights, and potential, has become an intrinsic constituent of all data-based organisms. An appropriate understanding of data DNA and its organisms relies on the new field of data science and its keystone, analytics. Although it is widely debated whether big data is only hype and buzz, and data science is still in a very early phase, significant challenges and opportunities are emerging or have been inspired by the research, innovation, business, profession, and education of data science. This article provides a comprehensive survey and tutorial of the fundamental aspects of data science: the evolution from data analysis to data science, the data science concepts, a big picture of the era of data science, the major challenges and directions in data innovation, the nature of data analytics, new industrialization and service opportunities in the data economy, the profession and competency of data education, and the future of data science. This article is the first in the field to draw a comprehensive big picture, in addition to offering rich observations, lessons, and thinking about data science and analytics.},
	number = {3},
	urldate = {2020-05-23},
	journal = {ACM Computing Surveys},
	author = {Cao, Longbing},
	month = jun,
	year = {2017},
	keywords = {statistics, data science, computing, data analysis, advanced analytics, Big data, big data analytics, data analytics, data DNA, data economy, data education, data engineering, data industry, data innovation, data profession, data scientist, data service, informatics},
	pages = {43:1--43:42},
	file = {Cao - 2017 - Data Science A Comprehensive Overview.pdf:/Users/rca2t1/Dropbox/Zotero/storage/N4PLI6MB/Cao - 2017 - Data Science A Comprehensive Overview.pdf:application/pdf},
}

@book{lide_codata_2012,
	address = {Paris, France},
	title = {{CODATA} @ 45 {Years}: {The} {Story} of the {ICSU} {Committee} on {Data} for {Science} and {Technology} ({CODATA}) from 1966 to 2010},
	isbn = {978-0-9917424-0-0},
	url = {https://books.google.com/books/about/CODATA_45_Years.html?id=NjA8kgEACAAJ&utm_source=gb-gplus-shareCODATA},
	urldate = {2020-05-23},
	publisher = {CODATA},
	author = {Lide, David R. and Wood, Gordon H.},
	year = {2012},
	file = {CODATA @ 45 Years\: The Story of the ICSU Committee on Data for Science and ... - David R. Lide, Gordon H. Wood - Google Books:/Users/rca2t1/Dropbox/Zotero/storage/A6LYIT2H/CODATA_45_Years.html:text/html;Lide and Wood - CODATA @ 45 Years The Story of the ICSU Committee.pdf:/Users/rca2t1/Dropbox/Zotero/storage/24NGUB73/Lide and Wood - CODATA @ 45 Years The Story of the ICSU Committee.pdf:application/pdf},
}

@misc{wu_statistics_1997,
	title = {Statistics = {Data} {Science}?},
	author = {Wu, C. F. Jeff},
	year = {1997},
	note = {Slides to Wu's inaugural lecture for his appointment to the H. C. Carver Professorship at the University of Michigan.},
	annote = {In November 1997, he gave the inaugural lecture entitled "Statistics = Data Science?"[17] for his appointment to the H. C. Carver Professorship at the University of Michigan.[18] He popularized the term "data science" and advocated that statistics be renamed data science and statisticians data scientists.[17] Later, he presented his lecture entitled "Statistics = Data Science?" as the first of his 1998 P.C. Mahalanobis Memorial Lectures.[19] These lectures honor Prasanta Chandra Mahalanobis, an Indian scientist and statistician and founder of the Indian Statistical Institute. (Wikipedia)},
	file = {Wu - 1996 - Statistics = Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/QQIKSMWT/Wu - 1996 - Statistics = Data Science.pdf:application/pdf},
}

@article{wu_convergence_1983,
	title = {On the {Convergence} {Properties} of the {EM} {Algorithm}},
	volume = {11},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/euclid.aos/1176346060},
	doi = {10.1214/aos/1176346060},
	abstract = {Two convergence aspects of the EM algorithm are studied: (i) does the EM algorithm find a local maximum or a stationary value of the (incomplete-data) likelihood function? (ii) does the sequence of parameter estimates generated by EM converge? Several convergence results are obtained under conditions that are applicable to many practical situations. Two useful special cases are: (a) if the unobserved complete-data specification can be described by a curved exponential family with compact parameter space, all the limit points of any EM sequence are stationary points of the likelihood function; (b) if the likelihood function is unimodal and a certain differentiability condition is satisfied, then any EM sequence converges to the unique maximum likelihood estimate. A list of key properties of the algorithm is included.},
	language = {EN},
	number = {1},
	urldate = {2020-05-23},
	journal = {Annals of Statistics},
	author = {Wu, C. F. Jeff},
	month = mar,
	year = {1983},
	mrnumber = {MR684867},
	zmnumber = {0517.62035},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {EM algorithm, curved exponential family, GEM algorithm, incomplete data, maximum likelihood estimate},
	pages = {95--103},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TPM8A3KP/DPubS.html:text/html;Wu - 1983 - On the Convergence Properties of the EM Algorithm.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RCHSJG3H/Wu - 1983 - On the Convergence Properties of the EM Algorithm.pdf:application/pdf},
}

@misc{noauthor_kdd-89_nodate,
	title = {{KDD}-89 {Workshop}},
	url = {https://www.kdnuggets.com/meetings-past/kdd89/index.html},
	urldate = {2020-05-23},
	file = {KDD-89 Workshop:/Users/rca2t1/Dropbox/Zotero/storage/H58V5S97/index.html:text/html},
}

@article{piatetsky-shapiro_knowledge_1991,
	title = {Knowledge {Disovery} in {Real} {Databases}: {A} {Report} on the {IJCAI}-89 {Workshop}},
	volume = {11},
	url = {https://www.kdnuggets.com/meetings-past/kdd89/kdd-89-report-aimag.html},
	number = {5},
	urldate = {2020-05-23},
	journal = {AI Magazine},
	author = {Piatetsky-Shapiro, Gregory},
	month = jan,
	year = {1991},
	note = {https://doi.org/10.1609/aimag.v11i4.873},
	pages = {68--70},
	annote = {"The growth in the amount of available databases far outstrips the growth of corresponding knowledge. This creates both a need and an opportunity for extracting knowledge from databases."https://diigo.com/0hn64l},
	file = {KDD-89 Report, AI Magazine 1991:/Users/rca2t1/Dropbox/Zotero/storage/BZMR3W7J/kdd-89-report-aimag.html:text/html;Piatetsky-Shapiro - 1991 - Knowledge Disovery in Real Databases A Report on .pdf:/Users/rca2t1/Dropbox/Zotero/storage/TFEGYHQB/Piatetsky-Shapiro - 1991 - Knowledge Disovery in Real Databases A Report on .pdf:application/pdf},
}

@misc{noauthor_kdd_nodate,
	title = {{KDD} {Process}/{Overview}},
	url = {http://www2.cs.uregina.ca/~dbd/cs831/notes/kdd/1_kdd.html},
	urldate = {2020-05-23},
	annote = {Data := A set of facts, F.
The overall process of finding and interpreting patterns from data involves the repeated application of the following steps:

Developing an understanding of

the application domain
the relevant prior knowledge
the goals of the end-user


Creating a target data set: selecting a data set, or focusing on a subset of variables, or data samples, on which discovery is to be performed.
Data cleaning and preprocessing.

Removal of noise or outliers.
Collecting necessary information to model or account for noise.
Strategies for handling missing data fields.
Accounting for time sequence information and known changes.


Data reduction and projection.

Finding useful features to represent the data depending on the goal of the task.
Using dimensionality reduction or transformation methods to reduce the effective number of variables under consideration or to find invariant representations for the data.


Choosing the data mining task.

Deciding whether the goal of the KDD process is classification, regression, clustering, etc.


Choosing the data mining algorithm(s).

Selecting method(s) to be used for searching for patterns in the data.
Deciding which models and parameters may be appropriate.
Matching a particular data mining method with the overall criteria of the KDD process.


Data mining.

Searching for patterns of interest in a particular representational form or a set of such representations as classification rules or trees, regression, clustering, and so forth.


Interpreting mined patterns.
Consolidating discovered knowledge.
},
	file = {KDD Process/Overview:/Users/rca2t1/Dropbox/Zotero/storage/SX5AJPQC/1_kdd.html:text/html},
}

@incollection{fayyad_data_1996,
	address = {USA},
	title = {From {Data} {Mining} to {Knowledge} {Discovery}: {An} {Overview}},
	isbn = {978-0-262-56097-9},
	shorttitle = {From {Data} {Mining} to {Knowledge} {Discovery}},
	urldate = {2020-05-23},
	booktitle = {Advances in knowledge discovery and data mining},
	publisher = {American Association for Artificial Intelligence},
	author = {Fayyad, Usama M. and Piatetsky-Shapiro, Gregory and Smyth, Padhraic},
	month = feb,
	year = {1996},
	pages = {1--34},
	file = {Fayyad et al. - 1996 - From Data Mining to Knowledge Discovery An Overvi.pdf:/Users/rca2t1/Dropbox/Zotero/storage/X2HAZL4W/Fayyad et al. - 1996 - From Data Mining to Knowledge Discovery An Overvi.pdf:application/pdf},
}

@inproceedings{fayyad_knowledge_1996,
	title = {Knowledge {Discovery} and {Data} {Mining}: {Towards} a {Unifying} {Framework}.},
	volume = {96},
	booktitle = {{KDD}},
	author = {Fayyad, Usama M and Piatetsky-Shapiro, Gregory and Smyth, Padhraic and {others}},
	year = {1996},
	pages = {82--88},
	file = {Fayyad et al. - 1996 - Knowledge Discovery and Data Mining Towards a Uni.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NAE7V24J/Fayyad et al. - 1996 - Knowledge Discovery and Data Mining Towards a Uni.pdf:application/pdf},
}

@misc{noauthor_computer_nodate,
	title = {Computer {Science} 831: {Knowledge} {Discovery} in {Databases}},
	url = {http://www2.cs.uregina.ca/~dbd/cs831/index.html},
	urldate = {2020-05-23},
	file = {Computer Science 831 Home Page:/Users/rca2t1/Dropbox/Zotero/storage/34LRZZCM/index.html:text/html},
}

@article{us_department_of_commerce_international_1978,
	title = {International {Association} for {Statistical} {Computing}},
	volume = {1},
	language = {en},
	journal = {Statistical Reporter},
	author = {US Department of Commerce},
	year = {1978},
	note = {Google-Books-ID: foXQOEJ8gbcC},
	pages = {332},
	file = {1978 - Statistical Reporter.pdf:/Users/rca2t1/Dropbox/Zotero/storage/R7H9G92E/1978 - Statistical Reporter.pdf:application/pdf},
}

@book{geron_hands-machine_2017,
	address = {Beijing ; Boston},
	edition = {1 edition},
	title = {Hands-{On} {Machine} {Learning} with {Scikit}-{Learn} and {TensorFlow}: {Concepts}, {Tools}, and {Techniques} to {Build} {Intelligent} {Systems}},
	isbn = {978-1-4919-6229-9},
	shorttitle = {Hands-{On} {Machine} {Learning} with {Scikit}-{Learn} and {TensorFlow}},
	abstract = {Graphics in this book are printed in black and white.Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how.By using concrete examples, minimal theory, and two production-ready Python frameworks—scikit-learn and TensorFlow—author Aurélien Géron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You’ll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what you’ve learned, all you need is programming experience to get started.Explore the machine learning landscape, particularly neural netsUse scikit-learn to track an example machine-learning project end-to-endExplore several training models, including support vector machines, decision trees, random forests, and ensemble methodsUse the TensorFlow library to build and train neural netsDive into neural net architectures, including convolutional nets, recurrent nets, and deep reinforcement learningLearn techniques for training and scaling deep neural netsApply practical code examples without acquiring excessive machine learning theory or algorithm details},
	language = {English},
	publisher = {O'Reilly Media},
	author = {Géron, Aurélien},
	month = apr,
	year = {2017},
}

@misc{dumbill_smaq_2010,
	title = {The {SMAQ} stack for big data},
	url = {http://radar.oreilly.com/2010/09/the-smaq-stack-for-big-data.html},
	abstract = {We're at the beginning of a revolution in data-driven products and services, driven by a software stack that enables big data processing on commodity hardware. Learn about the SMAQ stack, and where today's big data tools fit in.},
	language = {en-US},
	urldate = {2020-05-23},
	journal = {O'Reilly Radar},
	author = {Dumbill, Edd},
	month = sep,
	year = {2010},
	note = {Library Catalog: radar.oreilly.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Q5U9XM9K/the-smaq-stack-for-big-data.html:text/html},
}

@book{kennedy_statistical_1980,
	address = {New York},
	series = {Statistics: {A} {Series} of {Textbooks} and {Monographs}},
	title = {Statistical {Computing}},
	volume = {33},
	isbn = {0-8247-6898-1},
	abstract = {In this convenient textbook and reference work, the reader will find an introduction to statistical computing and a critical, balanced presentation of the algorithms and computational methods currently in use. Emphasizing the most accurate and widely used of these methods, the book thoroughly describes the algorithms that have been incorporated into the leading software systems of today, and discusses techniques for implementing algorithms in a computer. Statistical Computing contains the detail that researchers need, in the form of a textbook that gives advanced students a broad understanding of the subject, even in its most sophisticated aspects. Complete with exercises and extensive reference lists, Statistical Computing can be applied to a one-semester course for graduate students in statistics, mathematics, computer science, and any field in which numerical methods and algorithms are used in statistical data analyses. Book jacket.},
	language = {en},
	publisher = {Marcel Dekker, Inc.},
	author = {Kennedy, William J. and Gentle, James E.},
	month = mar,
	year = {1980},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General},
}

@book{naur_concise_1974,
	address = {New York},
	edition = {1st edition},
	title = {Concise {Survey} of {Computer} {Methods}},
	isbn = {978-0-88405-314-9},
	language = {English},
	publisher = {Petrocelli Books},
	author = {Naur, Peter},
	year = {1974},
	annote = {From the related web page:
"Data science is the science of dealing with data, once they have been established, while the relation of data to what they represent is delegated to other fields and sciences."
"A basic principle of data science is this: The data representation must be chosen with due regard to the transformation to be achieved and the data processing tools available. This stresses the importance of concern for the characteristics of the data processing tools."
"the concept of data, as defined in I. H. Gould (ed.): ‘IFIP guide to concepts and terms in data processing’, North-Holland Publ. Co., Amsterdam, 1971: DATA: A representation of facts or ideas in a formalised manner capable of being communicated or manipulated by some process. Data science is the science of dealing with data, once they have been established, while the relation of data to what they represent is delegated to other fields and sciences.
Data science as a science of data that emerges from the practice of data processing.
 },
}

@misc{naur_peter_1992,
	title = {Peter {Naur}: {Concise} {Survey} of {Computer} {Methods}, 397 p},
	url = {http://www.naur.com/Conc.Surv.html},
	urldate = {2020-05-24},
	author = {Naur, Peter},
	year = {1992},
	annote = {Part 1 - Basic Concepts, Tools and Methods
1. Data and their Applications (Reprinted as section 1.2 of Peter Naur: Computing, a Human Activity, 1992, ACM Press, ISBN 0-201-58069-1)
1.1. Data and What They Represent; 1.2. Data Processes and Models; 1.3. Data Recognition and Context; 1.4. Data Representations; 1.5. Numbers and Numerals; 1.6. Data Conversions; 1.7. Data Processing; 1.8. A Basic Principle of Data Science; 1.9. Limitations of Data Processing; 1.10. Summary of the Chapter; 1.11. Exercises.
Summary of the Chapter
The starting point is the concept of data, as defined in I. H. Gould (ed.): ‘IFIP guide to concepts and terms in data processing’, North-Holland Publ. Co., Amsterdam, 1971: DATA: A representation of facts or ideas in a formalised manner capable of being communicated or manipulated by some process. Data science is the science of dealing with data, once they have been established, while the relation of data to what they represent is delegated to other fields and sciences.
The usefulness of data and data processes derives from their application in building and handling models of reality.
Data representation may be chosen freely, and data used in practice differ along several dimensions, being static or dynamic, digital or analog, and using one out of a number of different media.
Numbers and their representation illustrate the concept of data, besides being of central importance in formulating data processes of any kind.
Data conversions are the simplest kind of data processes, but may illustrate wide ranges of data representations, particularly the interplay of static and dynamic representations.
In general data processing, data representing some meaning is processed in accordance with some intent to form new, so far unknown, data. In good data processing these latter may be used directly by humans to guide their actions.
A basic principle of data science is this: The data representation must be chosen with due regard to the transformation to be achieved and the data processing tools available. This stresses the importance of concern for the characteristics of the data processing tools.
Limits on what may be achieved by data processing may arise both from the difficulty of establishing data that represent a field of interest in a relevant manner, and from the difficulty of formulating the data processing that is needed. Some of the difficulty of understanding these limits is caused by the ease with which certain data processing tasks are performed by humans.
 
2. Computers and Programming Languages
2.1. Sequential Data Processes; 2.2. Computers, Programs, and Input Data; 2.3. Programming Languages, Interpretation and Translation; 2.4. Statements, Levels of Description and Primitive Operations; 2.5. Primitive Operations as State Transitions; 2.6. Data Stores, Variables and Values; 2.7. Machine Language Instructions; 2.8. Flow of Control and Flow Charts; 2.9. Operators and Types of Values; 2.10. Input and Output Conversions and Statements; 2.11. Limitations of Programming Languages Systems; 2.12. Execution Times; 2.13. Optimization in Programming Language Systems; 2.14. Source Program Error Treatment; 2.15. Theoretical Limitations of Programming; 2.16. Summary of the Chapter; 2.17. Exercises.
Summary of the Chapter
The chapter is a review of the common, general ideas and characteristics of electronic digital computers and their associated programming languages. Starting from the notion of sequential data processes, the ideas of computers, programs and and their input data are introduced. This leads to a description of the use of higher level programming languages, with the additional stages of program interpretation or translation.
The notions of levels of process description is introduced as a means for humans to retain the mental grasp of large programs. Each level is characterized by a set of primitive operations belonging to it. The meaning, or semantics, of the primitive operations is explained as the relation between the states of the process before and after the execution of the operation.
A data store is explained as a means for holding a set of values. Values are data viewed in a context where several or many different would be possible. A variable is an identifiable ability to hold a value. Variables may be simple or subscripted.
The essentials of machine language instructions are reviewed, with special attention to the address calculation algorithm.
The low of control of a program indicates how the position of the instruction or statement being executed moved about the program text. Flow charts are program descriptions in which the flow of control is displayed graphically by means of lines and arrows.
Operators are the denotation within programming languages for operations. Monadic operators have one, dyadic two, operands. An operand may be a literal, the identification of a variable, or the denotation of a more complicated process, involving further operators. Values are classified into types. The effect of the operators will generally depend on the types of their operands.
The special problems raised by input and output conversions in the present text that includes a systematic development of the principles of such conversions are discussed.
The chapter end with a discussion of the limitations of programming languages systems and of programming as such. The limitations are partly quantitative, caused by the finite capacity and finite speed of computers, partly qualitative, caused by mistakes in the computer and the associated software. An example of a problem that in principle cannot be solved by programming is finally given.
3. Construction, Documentation, Proof, and Testing of Programs
3.1. Programming, Communication and Documentation; 3.2. The Stylistic Details of Programs and Documentation; 3.3. General Snapshots and Invariants of the Program State; 3.4. The Programming of Loops; 3.5. Data Representations and Action Clusters; 3.6. Structured Programming and Problem Solving; 3.7. Avoiding Go To Statements; 3.8. Proving Programs; 3.9. Program Testing; 3.10. Testing of Subprograms; 3.11. Using Random Data for Testing; 3.12. Documentation Check List; 3.13. Summary of the Chapter; 3.14. Exercises.
Summary of the Chapter
The chapter is concerned with the methodology of constructing correct programs. The importance of documentation of the construction process and of its resulting program is first stressed. The documentation should describe not only the final solution, but also the reasoning leading up to it. It should be worked out carefully, using a clear handwriting style or a typewriter, making deliberate use of a notation and a typographical arrangement that is likely to aid the reader’s understanding.
An important part of the documentation of programs consists of precise assertions about the values of the variables. A general snapshot is a set of assertions that holds true whenever the flow of control passes through a particular point in the program. An invariant assertion holds throughout a section of the program, or the complete program. General snapshots may be used as an aid during program development. In particular, loops are conveniently constructed by starting with a general snapshot for a point within them.
The data representation used within a program is best described by a set of invariants. To make this possible the changes to the values of the variables should only be made within the context of action clusters, worked out to ensure the continued validity of the invariants.
The overall structure of the program is made to match the structure of the problem it solves by starting the development at a high level of description and only gradually filling in details at lower levels (structured programming). Normally this approach will have to be balanced by a study of alternative solution possibilities, using general methods of problem solving. In order to achieve a transparent program structure, go to statements should best be avoided.
Programs may be proved formally to be correct, on the basis of general snapshots and the formal rules of semantics of the programming language being used. Such proofs are usually impractical, however.
Program testing is used during program development and whenever a change has been made to a program. Diagnostic tests are used to locate mistakes, acceptance tests to verify that the program has no known errors. Test cases should be worked out during the program development, to make sure that all parts of the program test are tried and that the full range of external specifications is covered.
Random data are adequate for testing only to a limited extent, and mostly as an aid to obtaining information about the execution time efficiency of programs.
 
Part 2 - Processes with Single Data Elements
4. Digital Data Representations
4.1. Digital Data for Humans and for Computers; 4.2. The ISO 7-Bit Character Set; 4.3. Data Holding Abilities; 4.4. Quantitative Measurement of Digital Data; 4.5. Redundancy; 4.6. Redundancy Checking; 4.7. The Design of Redundancy Checking; 4.8. Digital Representations Used Inside Computers; 4.9. Variable-Length Representations; 4.10. Internal Representation of Properties and States; 4.11. Building the Action Table; 4.12. Primary Conversion of Character Strings; 4.13. Levels of Analysis of Character Strings; 4.14. Data Transmission; 4.15. Summary of the Chapter; 4.16. Exercises.
Summary of the Chapter
The chapter is concerned with the most detailed properties of the digital representations used by people and in computers. As a concrete starting point the ISO 7-bit character set is first described, as an example of a character set that includes the feature that are required when it is intended to be used both by people and in computers.
The quantitative measurement of digital data is discussed on the basis of the concepts of data holding abilities and their degrees of freedom and the variability of the phenomena represented by data. Quantities of data are expressed in terms of equivalent binary digits.
This is followed by a discussion of redundancy and its use for increasing process efficiency, for improving the match to computer storage structures, and for checking.
The representations used with single computer words are described, including field packing and arithmetical packing. Variable-length representations are discussed, and a comparison of fixed length, variable-length-by-delimiter, and variable length-by-size representations is made.
A systematic procedure for developing representations of properties and states, for use in controlling the flow of processes, is described and illustrated in an application to the primary conversion of character strings. The analysis of character string is further discussed in terms of the levels of analysis that are involved.
The chapter ends with a review of the basic concepts involved in data transmission over long distances.
5. Processes of Action Choice
5.1. Classification of Single Data Items; 5.2. Multi-Item Choices; 5.3. Decision Tables; 5.4. The Use of Quantitative Measures of Uncertainty; 5.5. Composite Binary Conditions; 5.6. Testing for Rare Agreement; 5.7. Summary of the Chapter; 5.8. Exercises.
Summary of the Chapter
The chapter treats the problem of the most effective way to formulate the choice of alternative flow paths in programs. As the first case, the selection of one out of several paths on the basis of a single data item is discussed. The use of multi-way switches, rather than two-way, is advocated.
The second case is flow selection on the basis of two or more data items. The discussion brings out the importance of taking the relative frequency of outcomes into account, and of looking for the bottleneck of the execution.
Next, the description of choice processes by means of decision tables is discussed.
As an approach to the design of truly optimal choice processes, quantitative measures of the uncertainty of choice situations are discussed. The discussion includes the entropy of information theory and the weighted average length of the optimal binary coding of the outcomes.
Next, choices having binary outcome determined from a number of independent binary tests are considered. They may be designed for optimum performance on the basis of a single rule.
Finally, choices made on the basis of a complicated rule and having a binary outcome, with one result very rare, are discussed. The use of specially designed intermediate choice classes is described, using the spelling error problem as illustration.
6. Numbers and Arithmetic
6.1. Three Classes of Numbers; 6.2. Computer Integers; 6.3. Computer arithmetic with Integers; 6.4. Programmed Multiple-Length Integers; 6.5. Floating-Point Representations; 6.6. Floating-Point Arithmetic; 6.7. Avoiding the Pitfalls of Floating-Point Arithmetic; 6.8. Summary of the Chapter; 6.9. Exercises.
Summary of the Chapter
The representation of numbers in computers is discussed on the basis of a distinction between mathematical numbers, application numbers, and computer numbers.
Computer integers are defined in terms of the concepts of positional representations. This gives the basis for discussing the arithmetic of computer integers and the use of programmed multiple-length integers.
Floating-point representations are described as the most important means for handling continuous variables in computers. The central concepts as far as the user is concerned are the precision of the representation and the accuracy of particular number representations.
The chapter ends with a discussion of the characteristics and shortcomings of floating-point arithmetics, including illustrations of the loss of significant digits.
Part 3 - Intermediate Amounts of Data
7. Searching, Ordering and Sorting
7.1. Search; 7.2. Simple Search; 7.3. Scatter Storage Search; 7.4. Binary Search; 7.5. Programming Binary Search; 7.6. Internal Ordering or Sorting; 7.7. The Shell Sort Method; 7.8. Programming the Shell Sort Method; 7.9. Testing the Performance of SHLSRT (Shell Sort); 7.10. Other Sorting Methods; 7.11. Summary of the Chapter; 7.12. Exercises.
Summary of the Chapter
The chapter is concerned with data organized as files consisting of a number of records of similar structure. The first half deals with search, that is the process of locating, within a file, of a record having a specified key. Three methods of search are described, simple search, scatter store search, and binary search. They differ as to the way the file must be organized and in their execution time efficiency.
As an illustration of the methods of systematic program development discussed in chapter 3, the details of the design steps leading to a program for binary search is given.
The second half of the chapter deals with methods for ordering or sorting of files. Only one sorting method is described in detail, the so-called Shell sort method. In addition to an explanation of the logic of the method in general terms, the design steps leading to a program for the method, and the details of a test of this program are given.
8. Structure and Analysis of Linear Texts
8.1. Generative Syntax Descriptions; 8.2. Finite State Analysis of Linear Texts; 8.3. The Testing of Finite State Control Tables; 8.4. The Equivalence of Control Tables and Syntax Descriptions; 8.5. Summary of the Chapter; 8.6. Exercises.
Summary of the Chapter
The chapter begins with a description of several ways of expressing the rules for forming texts, generative syntactic rules. Starting from the used of examples and forms, the main stress is on metalanguages. The notation introduced by Backus, BNF, is described in detail. In addition, several extensions of this notation are described.
The second part of the chapter deals with the analysis of texts through a sequential treatment of the characters of which they are composed. The use of a finite state algorithm, based on a control table, is demonstrated. Following the construction of the control table in a special example, the construction of a complete set of internal test cases is described.
The chapter ends with a discussion of some of the relations between generative syntax descriptions and finite state analysis algorithms. In particular it is shown that any text structure that is defined by means of a control table may also be described in BNF.
9. Evaluative Expressions
9.1. Nested Structures; 9.2. Extending the State with a Stack; 9.3. Sequential Evaluation; 9.4. Adequacy of the Postfix Form of Expressions; 9.5. Conversion from Infix to Postfix Form; 9.6. Left-to-Right Evaluation and Pseudo-Evaluation; 9.7. Summary of the Chapter; 9.8. Exercises.
Summary of the Chapter
The chapter starts with a description of nested structures, and with a demonstration that they cannot be adequately checked by means of a finite state algorithm. This leads to a description of the use of a stack for recording left parentheses during the left-to-right check of nested structures.
The problem of a sequential evaluation of ordinary expressions in infix form is next discussed. It is suggested that for convenience of evaluation the infix form should be replaced by the postfix, or Reverse Polish, form, in which the operator is placed after both of its operands. To prepare for the study this form a review of the rules of evaluation of expressions in infix form is given. These rules are concerned with the treatment of expressions within parentheses, with operator priorities, and with additional ordering of evaluation, such as left-to-right evaluation.
A syntax of expressions in postfix form is now given. It is shown how expression in this form may be analyzed into their constituent parts and evaluated. The evaluation is first shown as it may be done on the basis of the syntactic analysis of the expression and then as it may be performed by means of a stack of operand values. A proof of the correctness of this latter form of evaluation is given.
The adequacy of the postfix form is now demonstrated, in that it is shown that any expression in infix form, including parentheses, and with arbitrary evaluation rules attached, may be rendered by an expression in postfix form. Conversely, it is shown that any expression in postfix form can be rewritten as an expression in infix form.
A sequential method for converting expression in infix form to postfix form is now described. This uses a stack to hold left parentheses and operators. This is finally combined with the evaluation algorithm for expressions in postfix form given earlier, to produce an algorithm for left-to-right evaluation of expressions in infix form. Several uses of this algorithm for pseudo-evaluation during program translation are described briefly.
10. Lists and Pointers
10.1. Explicit Data Association by Pointers; 10.2. List Processes; 10.3. General List Structures; 10.4. Storage Allocation; 10.5. Deletion and Garbage Collection; 10.6. List Processing Systems and Languages; 10.7. Binary Tree Search; 10.8. Summary of the Chapter; 10.9. Exercises.
Summary of the Chapter
Explicit association of data items by means of pointers is explained by means of examples of string representations. The notion of lists is introduced, and several simple list processes are shown.
More general data structures based on pointers are explained in terms of an example, a structure that allows representations of family relations of a group of people.
The discussion continues with the problems of storage allocation of general data structures. The use of storage boxed of a fixed size and of a list of free boxes is explained.
The problem of regaining the storage capacity of items that have been deleted from a data structure is described. Alternative solutions are described, including the use of a garbage collection process that collects the unused boxes of storage whenever the list of free boxes is empty.
A few general remarks concerning list processing languages are made. Although these languages may be very useful, the ideas of lists and pointers may be exploited successfully even without access to any such language.
As an example of the use of pointers purely for facilitating internal processing, binary tree structures and the processes of search, insertion, and deletion, of records in them are developed in detail.
Part 4 - Data Interchanges between Man and Computer
11. Input Data from Human Sources
11.1. Humans as Sources and Receivers of Data; 11.2. Input Devices; 11.3. Principles of Design of Input from Humans; 11.4. Input Mistake Analysis; 11.5. Issues of Psychology; 11.6. The Input Format as a Language; 11.7. Summary of the Chapter; 11.8. Exercises.
Summary of the Chapter
The chapter is concerned with input data to programs, particularly the problems related to humans as sources of data. The essential characteristics of humans in this role and of the devices used for transfer of data from humans to computers are first briefly reviewed.
The chief contents of the chapter is a description of a number of concrete guidelines for the designers of input data formats. special attention is given to mistakes and their consequences.
As a way to overcome some problems of human psychology it is suggested that the people who will actually act as sources of data are consulted during the design of the input data format, and that their motivation for the work is taken into account.
12. Computer Output for Human Use
12.1. Output Devices; 12.2. Output Format Design Considerations; 12.3. Experiments on the Format of Output; 12.4. Digital Curves and Pictures; 12.5. Large Tables; 12.6. Summary of the Chapter; 12.7. Exercises.
Summary of the Chapter
The chapter gives a number of rules for helping to made the printed output from a computer convenient and useful to human readers. The rules center around the need to adjust the volume and form of the output to the human capacity and mode of comprehension. The value of output in analogue or pictorial form is emphasized, and some guidance in the use of line printers for producing output in these forms is given. The chapter ends with a few notes on the production of large tables, including a warning against such productions.
13. Conversations between Man and Computer
13.1. Conversational Devices; 13.2. Potentials of Conversational Techniques; 13.3. Experimental Development of Man-Machine Conversations; 13.4. Summary of the Chapter; 13.5. Exercises.
Summary of the Chapter
Conversational interchanges between persons and computers offer increased convenience and speed for the human side of the interchange, by relieving the person of the burden of mastering all details of the language of interchange, by allowing rapid feedback of error messages, and by making it possible to limit the output to precisely that which is desired. In addition conversational techniques open the possibility of a more intimate relationship between man and computer. In attacking complicated problems involving creative problem solving, such as the development of large programs, this close relationship may help to achieve superior solutions.
The development of systems for conversational interchanges must to a considerable extent be based on experimental development, involving the actual users.
Part 5 - Processes with Large Amounts of Data
14. Computer Storage of Large Amounts of Data
14.1. Auxiliary Stores; 14.2. Working Store, Channels and Concurrent Operation; 14.3. Time Sharing, Multiprogramming and Operating Systems; 14.4. Program Environments; 14.5. The Importance of Designing for Low Latency; 14.6. Summary of the Chapter; 14.7. Exercises.
Summary of the Chapter
The functional characteristics of auxiliary stores, such as tapes, drums, and discs, are reviewed. Transfers of data between auxiliary stores and the working stores of computers are made a block at a time. The access time of a block is composed of a latency and a transfer time. In order to achieve good time-effectiveness when using auxiliary stores it is necessary that the relative contribution of the latency to the execution time is kept low. For this reason the block length should, as far as possible, be chosen to be large.
Auxiliary stores are connection to computers via channels. The channels make it possible that data transfers with auxiliary stores may proceed in parallel with other, unrelated, process activity in the central processor of the computer. One way of exploiting this possibility is to arrange the storage block of the working store that is used for the transfers as a double buffer.
In order to achieve an intensive utilization of the various parts of a computer system, with a high degree of concurrency of operation, the system may be organized to allow concurrent execution of several independent programs with the aid of multiprogramming. The complete operation must then be under the control of a special program, the operating system.
The user environment offered by various operating systems varies greatly form one system to the other. As the first, crude distinction one may speak of uniprogramming and multiprogramming environments. Under uniprogramming the part of the computer being used remains under the exclusive control of one user for as long as he wishes; under multiprogramming the part may be expected to be given to another user whenever it is left unused for even the shortest moment.
Irrespective of the environment there is a gain to be had by designing data processes for low latency. This may be done, first, by arranging the processing in such a manner that the data being transferred to or from auxiliary stores have been used for significant processing, and second, by ordering accesses to auxiliary stores in accordance with the physical arrangement of the store.
15. Maintenance, Searching and Sorting of Large Files
15.1. Records and Blocks; 15.2. The Maintenance of Large files; 15.3. Large File Design; 15.4. Searching in Large Files; 15.5. Queuing and Ordering of Transaction; 15.6. Tape File Merging and Sorting; 15.7. Large File Splitting and File Directories; 15.8. Summary of the Chapter; 15.9. Exercises.
Summary of the Chapter
The chapter is concerned with the basic concepts related to files that are so large that they have to be stored in an auxiliary store. In addition to searching and sorting, the operation of maintenance is prominent in dealing with such large files. The maintenance slip is the time interval elapsed, from a change in the part of the real world that is represented by the data of the files has taken place, until the corresponding change has also been made in the file.
The design of a large file requires that several, often conflicting, issues are taken into account: capacity, requests, maintenance, reliability, and cost.
Searching in large files has to be arranged to avoid unnecessary block transfers. For this reason, when the search processes have to be completed one by one, a suitable adaption of the scatter storage search method is generally to be recommended. However, often a more effective solution may be had by collecting the transactions in a queue and sorting them in accordance with most convenient order of access to the auxiliary store. The important principle of this approach may be adapted at the levels of both the computer hardware, machine language and magnetic tape processing and manual handling.
Effective use of magnetic tapes is always based on the process of tape merging, which is perfectly adapted to the characteristics of this medium. Tape merging may be used for sorting of magnetic tape files in a number of different ways. As an example the polyphase merge sort method is described. For use as the first phase of the method the formation of long suites of records by means of the replacement-selection method is discussed.
The chapter ends with a few notes on the splitting of one file into several and on the use of file directories.
16. Miscellaneous Storage Methods
16.1. Tape Libraries; 16.2. Multipass Processing; 16.3. Paging and Virtual Stores; 16.4. Summary of the Chapter; 16.5. Exercises.
Summary of the Chapter
The chapter describes certain methods of handling large amounts of data that cannot in a natural way be regarded as files of records. The methods have important applications to the handling of large program texts, but are not restricted in their use to such data.
The first method deals with libraries of files held on tape. It gives a rules about ordering the files in such a way that the average latency incurred in transferring the files is minimized.
The second topic discussed is the processing of a large amount of data by means of a large program using multipass processing. The variants of this approach that are described include alternation of the processing in the forward and backward directions and the organization of the auxiliary storage capacity used for the large amount of data as a ring.
The third part of the chapter describes paging and virtual stores, that allow the used of a computer system that is equipped with a small working store and a large auxiliary store in the form of a drum or a disc to ignore the difference of the two stores and to refer directly to the locations of the auxiliary store.
Part 6 - Large Data Systems
17. Large Data Systems in Human Society
17.1. Large Data System Characteristics; 17.2. Political and Ethical Issues; 17.3. People Involved in Large Data Systems; 17.4. Large Data System Adequacy and Convenience; 17.5. Large Data System Reliability and Stability; 17.6. Large Data System Security and Supervisability; 17.7. The Political Weight of Large Data Systems; 17.8. Summary of the Chapter; 17.9. Exercises.
Summary of the Chapter
The chapter starts with a characterization of a class of large data systems in terms of the number of people involved, the cost of development and maintenance, the lifespan, the amounts of data included, the coupling of the actions of the computer and people involved, and the need for a whole family of programs to control the computer work. The concept is illustrated by examples of large data systems used in land surveying, business administration, and public administration.
The problems raised by a large data system may be not only technical, but also political and ethical. To describe these problems, a characterization is given of several groups of people who are in various ways related to the data system: the owner, the operators, the programmers, the managers, the clients, the adversaries, the society.
Large data systems have problems of their adequacy and convenience. These are of concern to the owner, the managers, the operators, and the clients. Further they raise problems of their reliability and stability. The problems concern the manager and the operators. Finally these systems have problems of security and supervisability. These problems are created by the possible presence of adversaries. They further concern the operators, the programmers, and the managers.
Large data systems may influence the power balance of various groups of the society. So far the most conspicuous effect of this kind is the tendency for a weakening of the position of the individual relative to that of large organizations, or a problem of privacy for the individual.
18. Design and Development of Large Data Systems (Reprinted as section 5.5 of Peter Naur: Computing, a Human Activity, 1992, ACM Press, ISBN 0-201-58069-1)
18.1. Controversial Issues of Large Data Systems; 18.2. The Management View of the Large Data System Project; 18.3. Overall Design and the Experimental Attitude; 18.4. The Human Feedback; 18.5. Techniques of Problem Solving and Large Data System Design; 18.6. Documentation of Large Data Systems; 18.7. Documentation of Computer Operation; 18.8. Design Decisions of Large Data Systems; 18.9. Experiments as Part of the Design Process; 18.10. Design Check Points; 18.11. Summary of the Chapter; 18.12. Exercises.
Summary of the Chapter
The development of large data systems has given rise to difficulties owing to: lack of the technical understanding of the problems; lag in the development of the appropriate educations; poor mutual understanding between project manager, system designers and programmers, and computer scientists; inadequate management methods, lack of standards of methods and performance; tendency to overpromise the achievement to be expected of projected systems.
As one approach to managing large data system projects, the development may be regarded as taking place by 5 stages: analysis of requirements; design; implementation; installation; and maintenance. The analogy with projects of development of physical items, which is the basis of this view of data system projects, is not so close as to prevent difficulties from this approach, however.
As an alternative approach, the development problem may be regarded as primarily one of overall design. Recognizing that the overall design can only be regarded as a hypothesis until all its parts have been worked out in detail, one arrives at a view of the project as a succession of experimental stages.
Large data systems contain important human elements, both during their design and operation. It is suggested that the insight into the psychological and sociological factors which will be of importance to the system design be gained through a dialog involving the designers and the people who will be involved in the operation.
The actual work on the design of large data systems may profit from an insight into general problem solving methods. Some of the essential issues are that the designer should view the problem from many different sides before making any design decisions, and that he should keep an open eye for alternative solutions.
With large systems a major design problem is to find an order of treatment of the usually conflicting design requirements. A sketch of a systematic method for finding such an order is given.
As a technique for arriving at the initial design goals it is suggested that a meeting between the people that will be involved in the system be held. During the meeting a list of design goals is set up, with a grading of each goal along both a usefulness and a cost scale.
As a help towards solving the difficult problem of documentation of large data systems 4 rules are given: First, let the documentation be produced while the actual development is in progress. Second, maintain a plan and a table of contents of the intended final documentation at all times during the development of the system. Third, help the reader to find his way in the documentation. Fourth, choose and hold a suitable terminology.
As part of the development of the design of a large data system it is helpful to look at the proposed design from the angle of several design areas: the interfaces of the processing done by people and that done by computers; the processing cycles of the system; the computer programs; the processing to be done by people; what will not be done and why.
Certain areas of a large data system can only be designed on the basis of experiments. Typical areas of this kind are: input and output formats; statistical properties of input data; the difficult processes.
A proposed design of a large data system should be checked against several general points: coverage of goals; simplicity; performance; reliability and stability; security and supervisability; modifiability.
 
 },
	file = {Peter Naur\: Concise Survey of Computer Methods, 397 p:/Users/rca2t1/Dropbox/Zotero/storage/QSFSLZRD/Conc.Surv.html:text/html},
}

@book{gould_ifip_1971,
	address = {London},
	title = {{IFIP} {Guide} to {Concepts} and {Terms} in {Data} {Processing}},
	volume = {2},
	copyright = {Copyright © 1972 John Wiley \& Sons, Ltd},
	url = {https://www.google.com/books/edition/IFIP_Guide_to_Concepts_and_Terms_in_Data/S9C7AAAAIAAJ?hl=en&gbpv=0},
	language = {en},
	urldate = {2020-05-24},
	publisher = {North-Holland},
	editor = {Gould, I. H.},
	year = {1971},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.4380020318
, I. H. Gould (Ed.), North-Holland, London, 1971. No. of pages: 161. Price: \$7.00},
	annote = {Data = A representation of facts or ideas in a formalised manner capable of being communicated or manipulated by some process.},
	file = {Gould - 1971 - IFIP Guide to Concepts and Terms in Data Processin.pdf:/Users/rca2t1/Dropbox/Zotero/storage/8DIER96E/Gould - 1971 - IFIP Guide to Concepts and Terms in Data Processin.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BUQWPUU8/spe.html:text/html},
}

@book{ratner_statistical_2017,
	title = {Statistical and {Machine}-{Learning} {Data} {Mining}: {Techniques} for {Better} {Predictive} {Modeling} and {Analysis} of {Big} {Data}, {Third} {Edition}},
	isbn = {978-1-351-65238-4},
	shorttitle = {Statistical and {Machine}-{Learning} {Data} {Mining}},
	abstract = {Interest in predictive analytics of big data has grown exponentially in the four years since the publication of Statistical and Machine-Learning Data Mining: Techniques for Better Predictive Modeling and Analysis of Big Data, Second Edition. In the third edition of this bestseller, the author has completely revised, reorganized, and repositioned the original chapters and produced 13 new chapters of creative and useful machine-learning data mining techniques. In sum, the 43 chapters of simple yet insightful quantitative techniques make this book unique in the field of data mining literature.  What is new in the Third Edition:   The current chapters have been completely rewritten.    The core content has been extended with strategies and methods for problems drawn from the top predictive analytics conference and statistical modeling workshops.   Adds thirteen new chapters including coverage of data science and its rise, market share estimation, share of wallet modeling without survey data, latent market segmentation, statistical regression modeling that deals with incomplete data, decile analysis assessment in terms of the predictive power of the data, and a user-friendly version of text mining, not requiring an advanced background in natural language processing (NLP).   Includes SAS subroutines which can be easily converted to other languages.  As in the previous edition, this book offers detailed background, discussion, and illustration of specific methods for solving the most commonly experienced problems in predictive modeling and analysis of big data. The author addresses each methodology and assigns its application to a specific type of problem. To better ground readers, the book provides an in-depth discussion of the basic methodologies of predictive modeling and analysis. While this type of overview has been attempted before, this approach offers a truly nitty-gritty, step-by-step method that both tyros and experts in the field can enjoy playing with.},
	language = {en},
	publisher = {CRC Press},
	author = {Ratner, Bruce},
	month = jul,
	year = {2017},
	note = {Google-Books-ID: ulAsDwAAQBAJ},
	keywords = {Computers / Databases / Data Mining, Mathematics / Probability \& Statistics / General, Computers / Machine Theory},
	annote = {EDA described as a paradigm shift.},
	annote = {"Statisticians know who they are. They will turn around to engage, not keep walking, if called data scientists. All others believe that the big data-related changes necessitate a redefining of statistics and statisticians, yet they have not even proposed a working definition that differentiates data science and data scientist from statistics and statisticians, respectively." (2.5 Summary).
 },
}

@techreport{geiger_career_2018,
	type = {preprint},
	title = {Career {Paths} and {Prospects} in {Academic} {Data} {Science}: {Report} of the {Moore}-{Sloan} {Data} {Science} {Environments} {Survey}},
	shorttitle = {Career {Paths} and {Prospects} in {Academic} {Data} {Science}},
	url = {https://osf.io/xe823},
	abstract = {This report is based on a 2016 survey of members and affiliates of three institutes of data science at major U.S. research universities, focusing on career paths for data scientists within academia. After considering how our respondents define data science, we identify various activities, priorities, resources, and concerns around data science in academia, especially with respect to data science careers. We end by providing recommendations about how universities can better support an emerging set of roles and responsibilities around data and computation within and across academic fields.},
	urldate = {2020-05-24},
	institution = {SocArXiv},
	author = {Geiger, R. Stuart and Cabasse, Charlotte and Cullens, Chihoko Y. and Norén, Laura and Fiore-Gartland, Brittany and Das, Diya and Brady, Henry},
	month = jun,
	year = {2018},
	doi = {10.31235/osf.io/xe823},
	file = {Submitted Version:/Users/rca2t1/Dropbox/Zotero/storage/TIXS79F6/Geiger et al. - 2018 - Career Paths and Prospects in Academic Data Scienc.pdf:application/pdf},
}

@book{naur_computing_1992,
	title = {Computing, a {Human} {Activity}},
	isbn = {978-0-201-58069-3},
	abstract = {In this comprehensive anthology Peter Naur, one of the world's foremost computer scientists, presents his selected writings from 1951 to 1990. The book features Naur's original and stimulating reflections on the nature of computing, with perceptive analyses of many issues that remain controversial. Comprising the author's published and unpublished writings on scientific, technical, philosophical, and social aspects of computing, the volume highlights his view of computing as, essentially, a human activity.},
	language = {en},
	publisher = {ACM Press},
	author = {Naur, Peter},
	month = jan,
	year = {1992},
	note = {Google-Books-ID: d4NQAAAAMAAJ},
	keywords = {Computers / General},
	annote = {"Data science is the science of dealing with data, once they have been established, while the relation of data to what they represent is delegated to other fields and sciences."
"The usefulness of data and data processes derives from their application in building and handling models of reality."
 },
	file = {Computing\: A Human Activity:/Users/rca2t1/Dropbox/Zotero/storage/J6NEZS7B/comp.html:text/html},
}

@misc{bandyopadhyay_data_2016,
	title = {The {Data} {Science} {Process}},
	url = {https://www.kdnuggets.com/the-data-science-process-2.html/},
	abstract = {What does a day in the data science life look like? Here is a very helpful framework that is both a way to understand what data scientists do, and a cheat sheet to break down any data science problem.},
	language = {en-US},
	urldate = {2020-05-24},
	journal = {KDnuggets},
	collaborator = {Bandyopadhyay, Raj},
	month = mar,
	year = {2016},
	note = {Library Catalog: www.kdnuggets.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/DW6SKR92/data-science-process.html:text/html},
}

@book{noauthor_understanding_2014,
	title = {Understanding the data science pipeline - {Practical} {Data} {Science} {Cookbook}},
	isbn = {978-1-78398-024-6},
	url = {https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781783980246/1/ch01lvl1sec09/understanding-the-data-science-pipeline},
	abstract = {Before we start installing any software, we need to understand the repeatable set of steps that we will use for data analysis throughout the book.},
	language = {en},
	urldate = {2020-05-25},
	month = sep,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2XGFN3LB/understanding-the-data-science-pipeline.html:text/html},
}

@book{ojeda_practical_2014,
	address = {Birmingham},
	title = {Practical {Data} {Science} {Cookbook}},
	isbn = {978-1-78398-024-6},
	abstract = {Key FeaturesLearn how to tackle every step in the data science pipeline and use it to acquire, clean, analyze, and visualize dataGet beyond the theory with real-world projectsExpand your numerical programming skills through step-by-step code examples and learn more about the robust features of R and PythonBook DescriptionData's value has grown exponentially in the past decade, with 'Big Data' today being one of the biggest buzzwords in business and IT, and data scientist hailed as 'the sexiest job of the 21st century'. Practical Data Science Cookbook helps you see beyond the hype and get past the theory by providing you with a hands-on exploration of data science. With a comprehensive range of recipes designed to help you learn fundamental data science tasks, you'll uncover practical steps to help you produce powerful insights into Big Data using R and Python.Use this valuable data science book to discover tricks and techniques to get to grips with your data. Learn effective data visualization with an automobile fuel efficiency data project, analyze football statistics, learn how to create data simulations, and get to grips with stock market data to learn data modelling. Find out how to produce sharp insights into social media data by following data science tutorials that demonstrate the best ways to tackle Twitter data, and uncover recipes that will help you dive in and explore Big Data through movie recommendation databases.Practical Data Science Cookbook is your essential companion to the real-world challenges of working with data, created to give you a deeper insight into a world of Big Data that promises to keep growing.What you will learnFollow the recipes in this essential data science cookbook to learn the fundamentals of data science and data analysisPut theory into practice with a selection of real-world Big Data projectsLearn the data science pipeline and successfully structure your data science projectFind out how to clean, munge, and manipulate dataLearn different approaches to data modelling and how to determine the most appropriate for your dataLearn numerical computing with NumPy and SciPyAbout the AuthorsTony Ojeda is the founder of District Data Labs, a cofounder of Data Community DC, and is actively involved in promoting data science education through both organizations.Sean Patrick Murphy spent 15 years as a senior scientist at The Johns Hopkins University Applied Physics Laboratory, where he focused on machine learning, modeling and simulation, signal processing, and high performance computing in the Cloud. Now, he acts as an advisor and data consultant for companies in SF, NY, and DC.Benjamin Bengfort has worked in military, industry, and academia for the past 8 years. He is currently pursuing his PhD in Computer Science at the University of Maryland, College Park, researching Metacognition and Natural Language Processing.Abhijit Dasgupta is a data consultant working in the greater DC-Maryland-Virginia area, with several years of experience in biomedical consulting, business analytics, bioinformatics, and bioengineering consulting.Table of ContentsPreparing Your Data Science EnvironmentDriving Visual Analysis with Automobile Data (R)Simulating American Football Data (R)Modeling Stock Market Data (R)Visually Exploring Employment Data (R)Creating Application-oriented Analyses Using Tax Data (Python)Driving Visual Analyses with Automobile Data (Python)Working with Social Graphs (Python)Recommending Movies at Scale (Python)Harvesting and Geolocating Twitter Data (Python)Optimizing Numerical Code with Numpy and Scipy (Python)},
	language = {English},
	publisher = {Packt Publishing},
	author = {Ojeda, Tony and Murphy, Sean Patrick and Bengfort, Benjamin and Dasgupta, Abhijit},
	month = sep,
	year = {2014},
}

@misc{noauthor_data_nodate,
	title = {Data {Science} {In} 5 {Minutes}},
	shorttitle = {Data {Science} {In} 5 {Minutes} {\textbar} {Data} {Science} {For} {Beginners} {\textbar} {What} {Is} {Data} {Science}?},
	url = {https://www.youtube.com/watch?v=X3paOmcrTjQ&feature=youtu.be},
	abstract = {This Data Science tutorial video will give you an idea on the life of a Data Scientist, steps involved in Data science project, roles \&amp; salary offered to a Data Scientist. Data is everywhere. In fact, the amount of digital data that exists is growing at a rapid rate, doubling every two years, and changing the way we live. Data Science is basically dealing with unstructured and structured data. Data Science is a field that comprises of everything that is related to data cleansing, preparation, and analysis. In simple terms, it is the umbrella of techniques used when trying to extract insights and information from data. Now, let us get started and understand what is Data Science all about.

Below topics are explained in this Data Science tutorial:
1. Life of a Data Scientist
2. Steps in Data Science project
 - Understanding the business problem
 - Data acquisition
 - Data preparation
 - Exploratory data analysis
 - Data modeling
 - Visualization and communication
 - Deploy \&amp; maintenance
3. Roles offered to a Data Scientist
4. Salary of a Data Scientist

To learn more about Data Science, subscribe to our YouTube channel: https://www.youtube.com/user/Simplile...

Download the Data Science career guide to explore and step into the exciting world of data, and follow the path towards your dream career: https://bit.ly/34ZGYRw

Watch more videos on Data Science: https://www.youtube.com/watch?v=0gf5i...

\#DataScience \#WhatIsDataScience \#DataScienceForBeginners \#DataScientist \#DataScienceTutorial \#DataScienceWithPython \#DataScienceWithR \#DataScienceCourse  \#BusinessAnalytics \#DataScience101 \#MachineLearning

This Post Graduate Program in Data Analytics, in partnership with Purdue University and in collaboration with IBM, will make you an expert in data analytics. In this Data Analytics course, you'll learn analytics tools and techniques, the languages of R and Python (with no prior programming experience required), how to create data visualizations with Tableau, and how to apply statistics and analytics in a business environment. Simplilearn’s PGP in Data Analytics will provide you with extensive expertise in the booming data analytics and data science fields.

Key features:
1. Purdue Post Graduate Program Certification
2. Purdue Alumni Association Membership
3. Enrollment in Simplilearn’s JobAssist
4. Industry-recognized IBM certificates
5. 180+ hours of Blended Learning
6. 14+ hands-on projects on integrated labs
7. Capstone Project in 3 Domains
8. Masterclasses from Purdue faculty

Skills covered:
1. Data analytics
2. Statistical analysis using Excel
3. Data analysis: Python \&amp; R
4. Data visualization: Tableau \&amp; PowerBI
5. Linear and logistic regression modules
6. Clustering using k-meansSupervised learning

Program details:
Fast track your career in the data analytics field via a comprehensive curriculum covering the concepts of data analytics and statistics foundation, analyzing data using Python and R programming languages, interacting with databases using SQL, and visualizing the data using Tableau and powerBI.

Learn more at: https://www.simplilearn.com/post-grad...

For more information about Simplilearn’s courses, visit: 
- Facebook: https://www.facebook.com/Simplilearn 
- Twitter: https://twitter.com/simplilearn 
- LinkedIn: https://www.linkedin.com/company/simp... 
- Website: https://www.simplilearn.com 

Get the Android app: http://bit.ly/1WlVo4u 
Get the iOS app: http://apple.co/1HIO5J0},
	urldate = {2020-05-25},
}

@article{kaufer_condensation_1993,
	title = {Condensation {Symbols}: {Their} {Variety} and {Rhetorical} {Function} in {Political} {Discourse}},
	volume = {26},
	issn = {0031-8213},
	shorttitle = {Condensation {Symbols}},
	url = {https://www.jstor.org/stable/40237768},
	number = {3},
	urldate = {2020-05-25},
	journal = {Philosophy \& Rhetoric},
	author = {Kaufer, David S. and Carley, Kathleen M.},
	year = {1993},
	note = {Publisher: Penn State University Press},
	pages = {201--226},
	file = {Kaufer and Carley - 1993 - Condensation Symbols Their Variety and Rhetorical.pdf:/Users/rca2t1/Dropbox/Zotero/storage/XS7RIE9G/Kaufer and Carley - 1993 - Condensation Symbols Their Variety and Rhetorical.pdf:application/pdf},
}

@book{schmidt_processing_1971,
	title = {Processing {Size}, {Frequency}, and {Speed} {Data} from {Snow} {Particle} {Counters}},
	language = {en},
	publisher = {Rocky Mountain Forest and Range Experiment Station},
	author = {Schmidt, R. A.},
	year = {1971},
	note = {Google-Books-ID: FcZIMxaIYwAC},
	keywords = {data processing},
}

@book{bessinger_literary_1964,
	title = {Literary {Data} {Processing} {Conference} proceedings, {September} 9, 10, 11, 1964},
	language = {en},
	publisher = {IBM, Data Processing Division},
	author = {Bessinger, Jess B. and Parrish, Stephen Maxfield},
	year = {1964},
	note = {Google-Books-ID: gUQYAQAAMAAJ},
	keywords = {data processing, Literature, Language Arts \& Disciplines / Linguistics, Computational linguistics},
}

@article{yan_first_2019,
	title = {A {First} {Course} in {Data} {Science}},
	volume = {27},
	issn = {null},
	url = {https://doi.org/10.1080/10691898.2019.1623136},
	doi = {10.1080/10691898.2019.1623136},
	abstract = {Data science is a discipline that provides principles, methodology, and guidelines for the analysis of data for tools, values, or insights. Driven by a huge workforce demand, many academic institutions have started to offer degrees in data science, with many at the graduate, and a few at the undergraduate level. Curricula may differ at different institutions, because of varying levels of faculty expertise, and different disciplines (such as mathematics, computer science, and business) in developing the curriculum. The University of Massachusetts Dartmouth started offering degree programs in data science from Fall 2015, at both the undergraduate and the graduate level. Quite a few articles have been published that deal with graduate data science courses, much less so dealing with undergraduate ones. Our discussion will focus on undergraduate course structure and function, and specifically, a first course in data science. Our design of this course centers around a concept called the data science life cycle. That is, we view tasks or steps in the practice of data science as forming a process, consisting of states that indicate how it comes into life, how different tasks in data science depend on or interact with others until the birth of a data product or a conclusion. Naturally, different pieces of the data science life cycle then form individual parts of the course. Details of each piece are filled up by concepts, techniques, or skills that are popular in industry. Consequently, the design of our course is both “principled” and practical. A significant feature of our course philosophy is that, in line with activity theory, the course is based on the use of tools to transform real data to answer strongly motivated questions related to the data.},
	number = {2},
	urldate = {2020-05-26},
	journal = {Journal of Statistics Education},
	author = {Yan, Donghui and Davis, Gary E.},
	month = may,
	year = {2019},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10691898.2019.1623136},
	keywords = {Data visualization, Curriculum design, Data science life cycle, Exploratory data analysis},
	pages = {99--109},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/7HMZNXI7/Yan and Davis - 2019 - A First Course in Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/AH2F66NB/10691898.2019.html:text/html},
}

@article{smith_data_2006,
	title = {Data {Science} as an {Academic} {Discipline}},
	volume = {5},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {1683-1470},
	url = {http://datascience.codata.org/articles/abstract/482/},
	abstract = {The CODATA\&nbsp;Data Science Journal\&nbsp;is a peer-reviewed, open access, electronic journal, publishing papers on the management, dissemination, use and reuse of research data and databases across all research domains, including science, technology, the humanities and the arts. The scope of the journal includes descriptions of data systems, their implementations and their publication, applications, infrastructures, software, legal, reproducibility and transparency issues, the availability and usability of complex datasets, and with a particular focus on the principles, policies and practices for open data.All data is in scope, whether born digital or converted from other sources.},
	language = {en},
	number = {0},
	urldate = {2020-05-26},
	journal = {Data Science Journal},
	author = {Smith, F.},
	month = nov,
	year = {2006},
	note = {Number: 0
Publisher: Ubiquity Press},
	pages = {163--164},
	file = {Smith - 2006 - Data Science as an Academic Discipline.pdf:/Users/rca2t1/Dropbox/Zotero/storage/SEM6YJNI/Smith - 2006 - Data Science as an Academic Discipline.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4RHBNRDQ/482.html:text/html},
}

@article{tukey_philosophy_1991,
	title = {The {Philosophy} of {Multiple} {Comparisons}},
	volume = {6},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/2245714},
	abstract = {This paper is based on the 1989 Miller Memorial Lecture at Stanford University. The topic was chosen because of Rupert Miller's long involvement and significant contributions to multiple comparison procedures and theory. Our emphasis will be on the major questions that have received relatively little attention--on what one wants multiple comparisons to do, on why one wants to do that, and on how one can communicate the results. Very little attention will be given to how the results can be calculated--after all, there are books about that (e.g., Miller, 1966, 1981; Hochberg and Tamhane, 1987).},
	number = {1},
	urldate = {2020-05-27},
	journal = {Statistical Science},
	author = {Tukey, John W.},
	year = {1991},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {causal inference},
	pages = {100--116},
	file = {Tukey - 1991 - The Philosophy of Multiple Comparisons.pdf:/Users/rca2t1/Dropbox/Zotero/storage/JRZDGDR8/Tukey - 1991 - The Philosophy of Multiple Comparisons.pdf:application/pdf},
}

@misc{marsman_tukeys_2017,
	title = {Tukey’s {Lament}: {Are} {Statisticians} {Living} a {Lie}?},
	shorttitle = {Tukey’s {Lament}},
	url = {https://jasp-stats.org/2017/09/14/tukeys-lament-statisticians-living-lie/},
	abstract = {John Tukey is famous. In his youth he coined the term “bit” (as an abbreviation of “binary information digit”), later he promoted exploratory data analysis, and throughout his entire life he worked on a broad range of statistical techniques, some… Continue reading →},
	language = {en-US},
	urldate = {2020-05-27},
	journal = {JASP - Free and User-Friendly Statistical Software},
	author = {Marsman, Maarten},
	month = sep,
	year = {2017},
	note = {Library Catalog: jasp-stats.org},
	annote = {“Statisticians classically asked the wrong question—and were willing to answer with a lie, one that was often a downright lie. They asked “Are the effects of A and B different?” and they were willing to answer “no.”
All we know about the world teaches us that the effects of A and B are always different—in some decimal place—for any A and B. Thus asking “Are the effects different?” is foolish.
What we should be answering first is “Can we tell the direction in which the effects of A differ from the effects of B?” In other words, can we be confident about the direction from A to B? Is it ”up,” “down” or “uncertain”?
The third answer to this first question is that we are “uncertain about the direction”—it is not, and never should be, that we “accept the null hypothesis.” (Tukey, 1991, p. 100)},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/SFZ9EQYB/tukeys-lament-statisticians-living-lie.html:text/html},
}

@misc{dataman_data_2020,
	title = {Data {Science} {Modeling} {Process} \& {Six} {Consultative} {Roles}},
	url = {https://towardsdatascience.com/data-science-modeling-process-fa6e8e45bf02},
	abstract = {There are many online articles talking about the modeling process. Why do I write this post? Two reasons. The first one is to show…},
	language = {en},
	urldate = {2020-05-28},
	journal = {Medium},
	author = {Dataman, Dr},
	month = feb,
	year = {2020},
	note = {Library Catalog: towardsdatascience.com},
}

@misc{noauthor_domino_nodate,
	title = {Domino {Data} {Science} {Lifecycle} – {Data} {Science} {Project} {Management}},
	url = {http://www.datascience-pm.com/domino-data-science-lifecycle/},
	language = {en-US},
	urldate = {2020-06-01},
	note = {Library Catalog: www.datascience-pm.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6LWHG54E/domino-data-science-lifecycle.html:text/html},
}

@misc{noauthor_data_nodate-1,
	title = {Data {Science} {Journal}},
	url = {http://datascience.codata.org/},
	abstract = {The CODATA\&nbsp;Data Science Journal\&nbsp;is a peer-reviewed, open access, electronic journal, publishing papers on the management, dissemination, use and reuse of research data and databases across all research domains, including science, technology, the humanities and the arts. The scope of the journal includes descriptions of data systems, their implementations and their publication, applications, infrastructures, software, legal, reproducibility and transparency issues, the availability and usability of complex datasets, and with a particular focus on the principles, policies and practices for open data.All data is in scope, whether born digital or converted from other sources.},
	language = {en},
	urldate = {2020-06-10},
	note = {Library Catalog: datascience.codata.org},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JXFV7FA2/datascience.codata.org.html:text/html},
}

@misc{noauthor_ios_nodate,
	title = {{IOS} {Press}},
	url = {https://www.iospress.nl/journal/data-science/},
	language = {en-US},
	urldate = {2020-06-10},
	note = {Library Catalog: www.iospress.nl},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BN429AUB/data-science.html:text/html},
}

@article{patil_building_2011,
	title = {Building data science teams},
	url = {http://radar.oreilly.com/2011/09/building-data-science-teams.html},
	abstract = {A data science team needs people with the right skills and perspectives, and it also requires strong tools, processes, and interaction between the team and the rest of the company.},
	language = {en-US},
	urldate = {2020-06-10},
	journal = {O'Reilly Radar},
	author = {Patil, D. J.},
	month = sep,
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NP4NE4GS/building-data-science-teams.html:text/html},
}

@book{naur_concise_1974-1,
	title = {Concise {Survey} of {Computer} {Methods}},
	isbn = {978-0-88405-314-9},
	language = {en},
	publisher = {Petrocelli Books},
	author = {Naur, Peter},
	year = {1974},
	note = {Google-Books-ID: 0KEpAQAAIAAJ},
	keywords = {Computers / Data Processing, Reference / Questions \& Answers},
}

@book{hogben_computer_1978,
	title = {Computer {Science} and {Statistics}--{Tenth} {Annual} {Symposium} on the {Interface}: {Proceedings} of the 10th {Annual} {Symposium} {Held} at the {National} {Bureau} of {Standards}, {Gaithersburg}, {Maryland}, {April} 14-15, 1977},
	shorttitle = {Computer {Science} and {Statistics}--{Tenth} {Annual} {Symposium} on the {Interface}},
	language = {en},
	publisher = {U.S. Department of Commerce, National Bureau of Standards},
	author = {Hogben, David and Fife, Dennis W.},
	year = {1978},
	note = {Google-Books-ID: XMzqjQDtAFIC},
}

@techreport{parzen_nonparametric_1977,
	title = {Nonparametric {Statistical} {Data} {Science}: {A} {Unified} {Approach} {Based} on {Density} {Estimation} and {Testing} for'{White} {Noise}'.},
	shorttitle = {Nonparametric {Statistical} {Data} {Science}},
	institution = {STATE UNIV OF NEW YORK AT BUFFALO AMHERST STATISTICAL SCIENCE DIV},
	author = {Parzen, Emanuel},
	year = {1977},
	file = {Parzen - 1977 - Nonparametric Statistical Data Science A Unified .pdf:/Users/rca2t1/Dropbox/Zotero/storage/A9SVFPPG/Parzen - 1977 - Nonparametric Statistical Data Science A Unified .pdf:application/pdf},
}

@article{newton_conversation_2002,
	title = {A {Conversation} with {Emanuel} {Parzen}},
	volume = {17},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/3182796},
	abstract = {Emanuel Parzen was born in New York City on April 21, 1929. He attended the Bronx High School of Science, received an A.B. in Mathematics from Harvard University in 1949, an M.A. in Mathematics from the University of California at Berkeley in 1951 and his Ph.D. in Mathematics and Statistics in 1953, also at Berkeley. He was a research scientist at Hudson Labs, Physics Department of Columbia University, from 1953 to 1956 and an Assistant Professor of Mathematical Statistics at Columbia from 1955 to 1956. In 1956, he moved to Stanford University, where he stayed until 1970, at which time he joined the faculty at the State University of New York at Buffalo, where he served first as Leading Professor and Chairman of the Department of Statistics and then as Director of Statistical Science. In 1978 he moved to Texas A\&M University as a Distinguished Professor, a post he currently holds. He has been a Fellow at Imperial College London, at IBM Systems Research Institute and at the Center for Advanced Study in the Behavioral Sciences at Stanford, as well as a Visiting Professor at the Sloan School of MIT, the Department of Statistics at Harvard and the Department of Biostatistics at Harvard. In 1959 he married Carol Tenowitz. They have two children and four grandchildren. Professor Parzen has authored or coauthored over 100 papers and 6 books. He has served on innumerable editorial boards and national committees, and has organized several influential conferences and workshops. He has directed the research of many graduate students and provided advice, encouragement and collaboration to students and colleagues around the world. To honor these contributions, he has been elected a Fellow of the American Statistical Association, of the Institute of Mathematical Statistics and of the American Association for the Advancement of Science. In 1994, he was awarded the prestigious Samuel S. Wilks Memorial Medal by the American Statistical Association.},
	number = {3},
	urldate = {2020-06-11},
	journal = {Statistical Science},
	author = {Newton, H. Joseph},
	year = {2002},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {357--378},
	file = {Newton - 2002 - A Conversation with Emanuel Parzen.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3UREPHSI/Newton - 2002 - A Conversation with Emanuel Parzen.pdf:application/pdf},
}

@article{blei_science_2017,
	title = {Science and data science},
	volume = {114},
	issn = {0027-8424},
	url = {https://www.jstor.org/stable/26487026},
	doi = {10.2307/26487026},
	abstract = {Data science has attracted a lot of attention, promising to turn vast amounts of data into useful predictions and insights. In this article, we ask why scientists should care about data science. To answer, we discuss data science from three perspectives: statistical, computational, and human. Although each of the three is a critical component of data science, we argue that the effective combination of all three components is the essence of what data science is about.},
	number = {33},
	urldate = {2020-06-11},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Blei, David M. and Smyth, Padhraic},
	year = {2017},
	note = {Publisher: National Academy of Sciences},
	pages = {8689--8692},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/89BRM7Q7/Blei and Smyth - 2017 - Science and data science.pdf:application/pdf},
}

@book{office_catalog_1979,
	title = {Catalog of {Copyright} {Entries}. {Third} {Series}: 1977: {July}-{December}: {Index}},
	shorttitle = {Catalog of {Copyright} {Entries}. {Third} {Series}},
	language = {en},
	publisher = {Copyright Office, Library of Congress},
	author = {Office, Library of Congress Copyright},
	year = {1979},
	note = {Google-Books-ID: VUIhAQAAIAAJ},
}

@book{noauthor_library_1977,
	title = {Library {Journal}},
	language = {en},
	publisher = {Library Journal},
	year = {1977},
	note = {Google-Books-ID: tl88AQAAIAAJ},
}

@book{noauthor_computer_1971,
	title = {Computer {Industry} {Annual}},
	language = {en},
	publisher = {Computer Design Publishing Corporation},
	year = {1971},
	note = {Google-Books-ID: qVcgAQAAIAAJ},
}

@book{noauthor_data_1972,
	title = {Data {Systems}},
	language = {en},
	year = {1972},
	note = {Google-Books-ID: vV\_yAAAAMAAJ},
}

@book{noauthor_acta_1970,
	title = {Acta {Symbolica}},
	abstract = {Vols. for , 1975- includes Proceedings of the Auditory Processing and Learning Disabilities Symposium.},
	language = {en},
	publisher = {Department of Audiology and Speech Pathology, Memphis State University},
	year = {1970},
	note = {Google-Books-ID: YzYoAQAAIAAJ},
}

@book{noauthor_data_1970,
	title = {Data {Processing} {Magazine}},
	language = {en},
	publisher = {American Data Processing, Incorporated},
	year = {1970},
	note = {Google-Books-ID: 3JYgAAAAMAAJ},
}

@article{miller_cognitive_2003,
	title = {The cognitive revolution: a historical perspective},
	volume = {7},
	issn = {1364-6613},
	shorttitle = {The cognitive revolution},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661303000299},
	doi = {10.1016/S1364-6613(03)00029-9},
	abstract = {Cognitive science is a child of the 1950s, the product of a time when psychology, anthropology and linguistics were redefining themselves and computer science and neuroscience as disciplines were coming into existence. Psychology could not participate in the cognitive revolution until it had freed itself from behaviorism, thus restoring cognition to scientific respectability. By then, it was becoming clear in several disciplines that the solution to some of their problems depended crucially on solving problems traditionally allocated to other disciplines. Collaboration was called for: this is a personal account of how it came about.},
	language = {en},
	number = {3},
	urldate = {2020-06-25},
	journal = {Trends in Cognitive Sciences},
	author = {Miller, George A},
	month = mar,
	year = {2003},
	pages = {141--144},
	file = {ScienceDirect Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/FEXDSJ7F/Miller - 2003 - The cognitive revolution a historical perspective.pdf:application/pdf;ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/DB3SERPM/S1364661303000299.html:text/html},
}

@article{ha_application_1998,
	title = {Application of data mining tools to hotel data mart on the {Intranet} for database marketing},
	volume = {15},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417498000086},
	doi = {10.1016/S0957-4174(98)00008-6},
	abstract = {Data mining, which is also referred to as knowledge discovery in databases, is the process of extracting valid, previously unknown, comprehensible and actionable information from large databases and using it to make crucial business decisions. In this paper, we present the data mining process from data extraction to knowledge interpretation and data mining tasks, and corresponding algorithms. Before applying data mining techniques to a real-world application, we build a data mart on the enterprise Intranet. RFM (recency, frequency, and monetary) data extracted from the data mart are used extensively for our analysis. We then propose a new marketing strategy that fully utilizes the knowledge resulting from data mining.},
	language = {en},
	number = {1},
	urldate = {2020-06-27},
	journal = {Expert Systems with Applications},
	author = {Ha, Sung Ho and Park, Sang Chan},
	month = jul,
	year = {1998},
	pages = {1--31},
	file = {ScienceDirect Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/JYJLIV7E/Ha and Park - 1998 - Application of data mining tools to hotel data mar.pdf:application/pdf;ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NWGK6S9W/S0957417498000086.html:text/html},
}

@misc{noauthor_according_nodate,
	title = {According to {Microsoft}, the fourth paradigm of science is data},
	url = {https://blog.revolutionanalytics.com/2009/12/fourth-paradigm.html},
	abstract = {In scientific discovery, the first three paradigms were experimental, theoretical and (more recently) computational science. A new book of essays published by Microsoft (and available for free download -- kudos, MS!) argues that a fourth paradigm of scientific discovery is at hand: the analysis of massive data sets. The book is dedicated to the late Microsoft researcher Dr Jim Gray, who pioneered the idea with the catchphrase: "It's the data, stupid". The basic idea is that our capacity for collecting scientific data has far outstripped our present capacity to analyze it, and so our focus should be on developing technologies...},
	urldate = {2020-06-27},
	journal = {Revolutions},
	note = {Library Catalog: blog.revolutionanalytics.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/84IUKUTL/fourth-paradigm.html:text/html},
}

@book{hey_fourth_2009,
	title = {The {Fourth} {Paradigm}: {Data}-{Intensive} {Scientific} {Discovery}},
	isbn = {978-0-9825442-0-4},
	shorttitle = {The {Fourth} {Paradigm}},
	url = {https://www.microsoft.com/en-us/research/publication/fourth-paradigm-data-intensive-scientific-discovery/},
	abstract = {Increasingly, scientific breakthroughs will be powered by advanced computing capabilities that help researchers manipulate and explore massive datasets. The speed at which any given scientific discipline advances will depend on how well its researchers collaborate with one another, and with technologists, in areas of eScience such as databases, workflow management, visualization, and cloud computing technologies. […]},
	language = {en-US},
	urldate = {2020-06-27},
	author = {Hey, Tony and Tansley, Stewart and Tolle, Kristin},
	month = oct,
	year = {2009},
	file = {Hey et al. - 2009 - The Fourth Paradigm Data-Intensive Scientific Dis.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HJS3BZ53/Hey et al. - 2009 - The Fourth Paradigm Data-Intensive Scientific Dis.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/S7I5M7BK/fourth-paradigm-data-intensive-scientific-discovery.html:text/html},
}

@article{sveinsdottir_datalogy_1988,
	title = {Datalogy — {The} copenhagen tradition of computer science},
	volume = {28},
	issn = {1572-9125},
	url = {https://doi.org/10.1007/BF01941128},
	doi = {10.1007/BF01941128},
	abstract = {Since the middle of the 1960s, computer science has been practised in Denmark under Peter Naur's termdatalogy, the science of data processes. Starting at Regenecentralen and the University of Copenhagen, the Copenhagen Tradition of Computer Science has developed its own special characteristics by means of a close connection with applications and other fields of knowledge. The tradition is not least visible in the area of education. Comprehensive project activity is an integral part of the curriculum, thus presenting theory as an aspect of realistic solutions known primarily through actual experience. Peter Naur early recognized the particular educational challenges presented by computer science. His innovations have shown their quality and vitality also at other universities. There is a close connection between computer science training as it has been formed at Copenhagen University, and the view of computer science which has characterized Peter Naur's research. We illustrate how the study of programming and system development conceived as a human activity has been an all-pervasive theme in Naur's work. This approach has set the scene for central research issues in software development which today seem more topical than ever.},
	language = {en},
	number = {3},
	urldate = {2020-06-27},
	journal = {BIT Numerical Mathematics},
	author = {Sveinsdottir, Edda and Frøkjær, Erik},
	month = sep,
	year = {1988},
	pages = {450--472},
}

@misc{naur_peter_nodate,
	title = {Peter {Naur}: {Concise} {Survey} of {Computer} {Methods}, 397 p},
	url = {http://www.naur.com/Conc.Surv.html},
	urldate = {2020-06-27},
	journal = {Introduction to the works of Peter Naur},
	author = {Naur, Peter},
	file = {Peter Naur\: Concise Survey of Computer Methods, 397 p:/Users/rca2t1/Dropbox/Zotero/storage/DPEPEAVK/Conc.Surv.html:text/html},
}

@article{naur_science_1966,
	title = {The {Science} of {Datalogy}},
	volume = {9},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/365719.366510},
	doi = {10.1145/365719.366510},
	number = {7},
	urldate = {2020-06-27},
	journal = {Communications of the ACM},
	author = {Naur, Peter},
	month = jul,
	year = {1966},
	pages = {485},
	file = {Naur - 1966 - The Science of Datalogy.pdf:/Users/rca2t1/Dropbox/Zotero/storage/CXRKPTN5/Naur - 1966 - The Science of Datalogy.pdf:application/pdf;naur-1966.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3B6GR3T9/naur-1966.pdf:application/pdf},
}

@incollection{crawford_jr_connections_1974,
	title = {On the {Connections} between {Data} and {Things} in the {Real} {World}},
	booktitle = {Management of {Data} {Elements} in {Information} {Processing}, {Proceedings}},
	author = {Crawford, Jr., Perry},
	year = {1974},
	pages = {51--57},
	annote = {Discusses "information algebra" in context of ways to connect data to things.
Two approaches: inside-out, outside-in.},
	annote = {May be useful in thinking about literacy and its relationship to data. Labels first = literacy.},
	annote = {Quote from Strachey  (1966) on "time-varying variables":
"Programming presents us with certain new questions that are not present, or at least not important, in any other branch of mathematics. Mathematics in general does not recognize the existence of variables. . .  that is values varying over a period of time. . . In programming on the other hand we deal with time-varying variables by the very nature of the process."
Are random variables "time-varying variables"?
 },
	annote = {Refers to a "data science task group" formed in 1966.
"From the beginning of the X3L8 program vigorous efforts were made to formulate views of data and definitions of data terms that would meet needs of the program and be accepted by all participants. In 1966, a "Data Science Task Group" was established to help accomplish this result. The chief output of the Task Group was a formulation of views of data and definition of data terms that stood as an alternative to the DOD formulation. The proposals of the Task Group were not accepted by the membership of X3L8; the views of data and definitions of data terms used in the X3L8 program are essentially those of the original DOD proposals."},
	file = {Crawford, Jr. - 1974 - On the Connections between Data and Things in the .pdf:/Users/rca2t1/Dropbox/Zotero/storage/48RSG3HU/Crawford, Jr. - 1974 - On the Connections between Data and Things in the .pdf:application/pdf},
}

@article{strachey_system_1966,
	title = {System {Analysis} and {Programming}},
	volume = {215},
	issn = {0036-8733},
	url = {https://www.jstor.org/stable/24931050},
	number = {3},
	urldate = {2020-06-28},
	journal = {Scientific American},
	author = {Strachey, Christopher},
	year = {1966},
	note = {Publisher: Scientific American, a division of Nature America, Inc.},
	pages = {112--127},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/EMWPJT7U/09-01.html:text/html;Strachey - 1966 - System Analysis and Programming.pdf:/Users/rca2t1/Dropbox/Zotero/storage/Z94RTYXB/Strachey - 1966 - System Analysis and Programming.pdf:application/pdf},
}

@book{noauthor_perceptual_1968,
	title = {Perceptual {Cognitive} {Development}},
	volume = {4},
	language = {en},
	publisher = {The Institute},
	year = {1968},
	note = {Google-Books-ID: V4htAAAAMAAJ},
}

@book{haider_getting_2015,
	title = {Getting {Started} with {Data} {Science}: {Making} {Sense} of {Data} with {Analytics}},
	isbn = {978-0-13-399123-9},
	shorttitle = {Getting {Started} with {Data} {Science}},
	abstract = {Master Data Analytics Hands-On by Solving Fascinating Problems You’ll Actually Enjoy!   Harvard Business Review recently called data science “The Sexiest Job of the 21st Century.” It’s not just sexy: For millions of managers, analysts, and students who need to solve real business problems, it’s indispensable. Unfortunately, there’s been nothing easy about learning data science–until now.  Getting Started with Data Science takes its inspiration from worldwide best-sellers like Freakonomics and Malcolm Gladwell’s Outliers: It teaches through a powerful narrative packed with unforgettable stories. Murtaza Haider offers informative, jargon-free coverage of basic theory and technique, backed with plenty of vivid examples and hands-on practice opportunities. Everything’s software and platform agnostic, so you can learn data science whether you work with R, Stata, SPSS, or SAS. Best of all, Haider teaches a crucial skillset most data science books ignore: how to tell powerful stories using graphics and tables. Every chapter is built around real research challenges, so you’ll always know why you’re doing what you’re doing. You’ll master data science by answering fascinating questions, such as:• Are religious individuals more or less likely to have extramarital affairs?• Do attractive professors get better teaching evaluations?• Does the higher price of cigarettes deter smoking?• What determines housing prices more: lot size or the number of bedrooms?• How do teenagers and older people differ in the way they use social media?• Who is more likely to use online dating services?• Why do some purchase iPhones and others Blackberry devices?• Does the presence of children influence a family’s spending on alcohol? For each problem, you’ll walk through defining your question and the answers you’ll need; exploring howothers have approached similar challenges; selecting your data and methods; generating your statistics;organizing your report; and telling your story. Throughout, the focus is squarely on what matters most:transforming data into insights that are clear, accurate, and can be acted upon.},
	language = {en},
	publisher = {IBM Press},
	author = {Haider, Murtaza},
	month = dec,
	year = {2015},
	note = {Google-Books-ID: b4YxCwAAQBAJ},
	keywords = {Computers / Databases / Data Mining, Business \& Economics / Statistics},
	annote = {States: "The earliest mention of the prhase data science in the news media is that of the firm Mohawk Data Science Corp. in the New York Times in April 1969." The company was founded in 1964 and specialized in document digitization.},
}

@article{bryce_curriculum_2001,
	title = {Curriculum {Guidelines} for {Bachelor} of {Science} {Degrees} in {Statistical} {Science}},
	volume = {55},
	issn = {0003-1305},
	url = {https://www.jstor.org/stable/2685523},
	number = {1},
	urldate = {2020-06-28},
	journal = {The American Statistician},
	author = {Bryce, G. Rex and Gould, Robert and Notz, William I. and Peck, Roxy L.},
	year = {2001},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {7--13},
	annote = {Refers to "data scientist" as a special track, but not mention of data science.},
	file = {Bryce et al. - 2001 - Curriculum Guidelines for Bachelor of Science Degr.pdf:/Users/rca2t1/Dropbox/Zotero/storage/C4GC5S3P/Bryce et al. - 2001 - Curriculum Guidelines for Bachelor of Science Degr.pdf:application/pdf},
}

@book{noauthor_monthly_1965,
	title = {Monthly {Catalog} of {United} {States} {Government} {Publications}},
	language = {en},
	publisher = {U.S. Government Printing Office},
	year = {1965},
	note = {Google-Books-ID: r7wYyuESiGAC},
}

@article{noauthor_virgil_1969,
	title = {Virgil {Johnson} personality sketch.},
	abstract = {Role as Mohawk Data Sciences Corp pres discussed.},
	journal = {New York Times},
	month = apr,
	year = {1969},
	pages = {3},
}

@article{noauthor_mohawk_1966,
	chapter = {Archives},
	title = {Mohawk {Data} {Sciences}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/1966/07/30/archives/mohawk-data-sciences.html},
	language = {en-US},
	urldate = {2020-06-28},
	journal = {The New York Times},
	month = jul,
	year = {1966},
}

@book{cao_data_2018,
	title = {Data {Science} {Thinking}: {The} {Next} {Scientific}, {Technological} and {Economic} {Revolution}},
	isbn = {978-3-319-95092-1},
	shorttitle = {Data {Science} {Thinking}},
	abstract = {This book explores answers to the fundamental questions driving the research, innovation and practices of the latest revolution in scientific, technological and economic development: how does data science transform existing science, technology, industry, economy, profession and education? How does one remain competitive in the data science field? What is responsible for shaping the mindset and skillset of data scientists? Data Science Thinking paints a comprehensive picture of data science as a new scientific paradigm from the scientific evolution perspective, as data science thinking from the scientific-thinking perspective, as a trans-disciplinary science from the disciplinary perspective, and as a new profession and economy from the business perspective.},
	language = {en},
	publisher = {Springer},
	author = {Cao, Longbing},
	month = aug,
	year = {2018},
	note = {Google-Books-ID: tiBqDwAAQBAJ},
	keywords = {Computers / Information Technology, Computers / Intelligence (AI) \& Semantics, Computers / Databases / Data Mining, Business \& Economics / Business Mathematics, Business \& Economics / Industries / Computers \& Information Technology},
}

@techreport{afcrl_report_1963,
	address = {Bedford, Mass.},
	title = {Report on {Research} at {AFCRL}: {July} 1962 - {July} 1963},
	abstract = {For the Period July 1962 -- July 1963},
	language = {English},
	author = {{AFCRL}},
	year = {1963},
	note = {Publisher: Air Force Cambridge Research Laboratories
OCLC: 16107187},
	file = {AFCRL - 1963 - Report on Research at AFCRL.pdf:/Users/rca2t1/Dropbox/Zotero/storage/GU3GLTGE/AFCRL - 1963 - Report on Research at AFCRL.pdf:application/pdf;data-sciences-lab.png:/Users/rca2t1/Dropbox/Zotero/storage/9A3YCA3E/data-sciences-lab.png:image/png;dsl-image.png:/Users/rca2t1/Dropbox/Zotero/storage/Y8KL8MSH/dsl-image.png:image/png},
}

@inproceedings{bosak_information_1961,
	address = {New York, NY, USA},
	series = {{ACM} '61},
	title = {An information {Algebra}},
	isbn = {978-1-4503-7388-3},
	url = {https://doi.org/10.1145/800029.808523},
	doi = {10.1145/800029.808523},
	abstract = {The Algebra is concerned with three undefined concepts; entity, property, and value. Although these concepts are formally undefined, certain intuitive statements can be made. Data processing is the activity of maintaining and processing data to accomplish certain objectives. The data are collections of values of certain selected properties of certain selected entities. e.g. A payroll manager has many objectives of which the primary one is the payment of his employees (the entities). He selects certain properties such as employee number, name, sex, hourly payrate, and he maintains a file in which he records values of these properties for each entity.},
	urldate = {2020-06-28},
	booktitle = {Proceedings of the 1961 16th {ACM} national meeting},
	publisher = {Association for Computing Machinery},
	author = {Bosak, R.},
	month = jan,
	year = {1961},
	pages = {62.101--62.104},
	annote = {Defines data as "collections of values of certain selected properties of certain selected entities."},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/VW4ENRHH/Bosak - 1961 - An information Algebra.pdf:application/pdf},
}

@article{afcrl_report_1959,
	title = {Report on {Research} at {AFCRL}},
	url = {https://catalog.hathitrust.org/Record/002138479},
	urldate = {2020-06-28},
	author = {{AFCRL}},
	year = {1959},
	note = {Place: Bedford, Mass.},
	annote = {"AFCRL 68-0039."},
	file = {Hathi Trust Record:/Users/rca2t1/Dropbox/Zotero/storage/EL8FTNZ4/002138479.html:text/html},
}

@techreport{afcrl_report_1967,
	address = {Bedford, Massachusetts},
	title = {Report on {Research} at {AFCRL}: {July} 1965 - {June} 1967},
	abstract = {For the Period July 1965 -- June 1967.},
	number = {AFCRL-68-0039},
	institution = {Air Foce Cambridge Research Laboratories},
	author = {{AFCRL}},
	month = nov,
	year = {1967},
	annote = {The Data Sciences Laboratory and researchers at other places are heavily engaged in research on various recognition processes.
Objects, situations and physical processes can be described in a multiplicity of ways. But in all cases, one seeks set of invariant attributes which describe the pattern or process in the simplest and most effective way according to a set of specified criteria.
But this is not a simple task except, perhaps, when the data have definable statistical properties. Part of the problem is that the choice of the attributes most effective for classification depends not only on the nature of the input data but also on the subjective point of view of the classifier. The choice of proper attributes is not obvious, although in certain relatively simple cases an intuitive choice followed by tests to identify the most efficient attributes can be successful. In more complex situations, there are usually very few clues to attributes that describe best, from a classification point of view, the patterns in question. Often it proves necessary to apply transformations of the data that bring out previously hidden features, which is the process used in medial axis transformation and in statistical filtering, to be described later.
pp. 14-15},
	file = {AFCRL - 1967 - Report on Research at AFCRL.pdf:/Users/rca2t1/Dropbox/Zotero/storage/PWAI4I5T/AFCRL - 1967 - Report on Research at AFCRL.pdf:application/pdf},
}

@misc{noauthor_univac_2020,
	title = {{UNIVAC}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=UNIVAC&oldid=964044972},
	abstract = {UNIVAC (Universal Automatic Computer) is a line of electronic digital stored-program computers starting with the products of the Eckert–Mauchly Computer Corporation. Later the name was applied to a division of the Remington Rand company and successor organizations.
The BINAC, built by the Eckert–Mauchly Computer Corporation, was the first general-purpose computer for commercial use.  The descendants of the later UNIVAC 1107 continue today as products of the Unisys company.},
	language = {en},
	urldate = {2020-06-28},
	journal = {Wikipedia},
	month = jun,
	year = {2020},
	note = {Page Version ID: 964044972},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ZZ8Z7CY9/index.html:text/html},
}

@misc{noauthor_mohawk_nodate,
	title = {Mohawk {Data} {Sciences} {Corporation} ({MDS}) {\textbar} {Selling} the {Computer} {Revolution} {\textbar} {Computer} {History} {Museum}},
	url = {https://www.computerhistory.org/brochures/m-p/},
	urldate = {2020-06-28},
	file = {Mohawk Data Sciences Corporation (MDS) | Selling the Computer Revolution | Computer History Museum:/Users/rca2t1/Dropbox/Zotero/storage/ZCBVVHWL/m-p.html:text/html},
}

@misc{noauthor_wikivisuallycom_nodate,
	title = {{WikiVisually}.com},
	url = {http://wikivisually.com},
	abstract = {The entire wiki with photo and video galleries for each article},
	urldate = {2020-06-28},
	note = {Library Catalog: wikivisually.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/84VLEFZ4/Mohawk_Data_Sciences_Corporation.html:text/html},
}

@misc{noauthor_mohawk_nodate-1,
	title = {Mohawk {Data} {Sciences} {Corp}. - {New} {York} 1970's},
	url = {http://www.scripophily.net/modascconewy.html},
	abstract = {Beautifully engraved stock certificate stamped specimen from the  Mohawk Data Sciences Corp.     printed in the 1970's.  This historic document was printed by the Security Columbian Banknote Company an},
	urldate = {2020-06-28},
	journal = {Scripophily},
	note = {Library Catalog: scripophily.net},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/EZHB2N6P/modascconewy.html:text/html},
}

@book{hart_systems_1967,
	title = {Systems and {Computer} {Science}: {Proceedings} of a {Conference} held at the {University} of {Western} {Ontario} {September} 10-11, 1965},
	isbn = {978-1-4875-8982-0},
	shorttitle = {Systems and {Computer} {Science}},
	abstract = {This book presents the papers delivered at the Conference on Systems and Computer Science held at the University of Western Ontario in September 1965. The primary purposes of the Conference were the promotion of research and the development of the teaching of computer science in Canadian universities. The papers focus attention on some of the concepts of Computer Science as a new field of study and at the same time provide a background for scientists looking at the subject for the first time. The chief developments in computer science have been concerned with the "applied" rather than the "pure" areas of the field: numerical analysis, applied statistics and operations research, and data processing. But there is something more to computers than the physical components and this book represents an attempt to correct the imbalance between "applied" and "pure" by drawing attention to certain theoretical aspects of computer and information science. Among the topics discussed are the theory of finite and infinite automata, aspects of formal language theory, heuristic and non-heuristic approaches to theorem proving and the mathematical formulation of the theory of general systems. There are also references to the problems of machine design, to software systems including higher-level languages, to multiple control computer models and to applied systems. This collection of papers will appeal first to graduate students and professors in Computer Science. It will also be of interest to computer scientists in industry and in government and university research groups and to the scientific public interested in discovering some of the principal ingredients and directions of the computer and information sciences.},
	language = {en},
	publisher = {University of Toronto Press},
	author = {Hart, John F. and Takasu, Satoru},
	month = dec,
	year = {1967},
	note = {Google-Books-ID: 8jM5DwAAQBAJ},
	keywords = {Education / Computers \& Technology, Science / History, Education / Higher},
}

@book{schwartz_mathematical_1967,
	title = {Mathematical {Aspects} of {Computer} {Science}},
	isbn = {978-0-8218-6728-0},
	language = {en},
	publisher = {American Mathematical Soc.},
	author = {Schwartz, Jacob T. and Society, American Mathematical},
	month = dec,
	year = {1967},
	note = {Google-Books-ID: ynigSICJflYC},
}

@book{carroll_careers_1967,
	title = {Careers and {Opportunities} in {Computer} {Science}},
	abstract = {Introduction to computer science; Your career as a general programmer; Careers as specialized programmes; Managerial careers in computer scince; Designing and manufacturing computers.},
	language = {en},
	publisher = {Dutton},
	author = {Carroll, John Millar},
	year = {1967},
	note = {Google-Books-ID: f44mAAAAMAAJ},
}

@book{noauthor_digital_1961,
	title = {Digital {Computer} {Newsletter}},
	language = {en},
	publisher = {Office of Naval Research, Mathematical Sciences Division.},
	year = {1961},
	note = {Google-Books-ID: DR8pjs4SVR4C},
}

@article{noauthor_back_1943,
	title = {Back {Matter}},
	volume = {8},
	issn = {0022-4812},
	url = {https://www.jstor.org/stable/2271064},
	number = {4},
	urldate = {2020-06-28},
	journal = {The Journal of Symbolic Logic},
	year = {1943},
	note = {Publisher: Association for Symbolic Logic},
}

@techreport{afcrl_report_1970,
	address = {Bedford, Massachusetts},
	title = {Report on {Research} at {AFCRL}: {July} 1967 – {June} 1970},
	abstract = {For the Period July 1967 – June 1970.},
	number = {AFCRL-71-0022},
	institution = {Air Foce Cambridge Research Laboratories},
	author = {{AFCRL}},
	month = dec,
	year = {1970},
	file = {AFCRL - 1970 - Report on Research at AFCRL.pdf:/Users/rca2t1/Dropbox/Zotero/storage/DBTZ85XV/AFCRL - 1970 - Report on Research at AFCRL.pdf:application/pdf},
}

@article{higgins_nonmathematical_1999,
	title = {Nonmathematical {Statistics}: {A} {New} {Direction} for the {Undergraduate} {Discipline}},
	volume = {53},
	issn = {0003-1305},
	shorttitle = {Nonmathematical {Statistics}},
	url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1999.10474418},
	doi = {10.1080/00031305.1999.10474418},
	abstract = {The explosion in the amount of data available to society today has not led to a corresponding growth in undergraduate statistics programs to produce statisticians to deal with such data. Instead, the profession is faced with the specter of “statistics departments under siege.” It is time to reexamine the undergraduate discipline in light of society's needs. The traditional emphasis on the mathematics of the discipline may have resulted in insufficient attention being paid to its nonmathematical aspects. These things are very much a part of what a practicing statistician does and what customers of statistics need. They include things like designing scientific studies in a team-oriented environment, ensuring protocol compliance, ensuring data quality, managing the storage/transmission/retrieval of data, and providing descriptive and graphical analyses of data. To bring greater purpose and practicality to programs for the undergraduate statistics major, it will be necessary to give greater prominence to nonmathematical statistics. Courses are suggested that would meet important needs of the undergraduate statistics major and set the discipline of statistics apart from mathematics.},
	number = {1},
	urldate = {2020-06-30},
	journal = {The American Statistician},
	author = {Higgins, James J.},
	month = feb,
	year = {1999},
	note = {Publisher: Taylor \& Francis},
	pages = {1--6},
	file = {Higgins - 1999 - Nonmathematical Statistics A New Direction for th.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NS8J8JH8/Higgins - 1999 - Nonmathematical Statistics A New Direction for th.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/W2GXP54S/00031305.1999.html:text/html},
}

@article{kettenring_shaping_1997,
	title = {Shaping {Statistics} for {Success} in the 21st {Century}},
	volume = {92},
	issn = {0162-1459},
	url = {https://doi.org/10.1080/01621459.1997.10473641},
	doi = {10.1080/01621459.1997.10473641},
	number = {440},
	urldate = {2020-06-30},
	journal = {Journal of the American Statistical Association},
	author = {Kettenring, Jon R.},
	month = dec,
	year = {1997},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01621459.1997.10473641},
	pages = {1229--1234},
	file = {Kettenring - 1997 - Shaping Statistics for Success in the 21st Century.pdf:/Users/rca2t1/Dropbox/Zotero/storage/434V2YGM/Kettenring - 1997 - Shaping Statistics for Success in the 21st Century.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/MLS9RUNN/01621459.1997.html:text/html},
}

@incollection{reid_man_2016,
	address = {London},
	title = {Man vs. {Machine}: {The} {Battle} for the {Soul} of {Data} {Science}},
	isbn = {978-1-349-94885-7},
	shorttitle = {Man vs. {Machine}},
	url = {https://doi.org/10.1057/978-1-349-94885-7_2},
	abstract = {David Reid asks if data science is just a trendy rebadging of statistics, or whether it is something fundamentally new. The chapter describes how two camps—data scientists and statisticians—are battling for the ‘soul’ of data science. The essence of this fight is the argument for and against the concept of ‘automated reasoning’. Just as the wheel allowed mankind to physically carry far greater loads, could another technology—automated reasoning—enable people to share intellectual burdens? Advances in Artificial Intelligence using Big Data could mean people are no longer the sole agents of genuine discovery and may soon share this special attribute with genuinely intelligent and inventive machines.},
	language = {en},
	urldate = {2020-07-01},
	booktitle = {Big {Data} {Challenges}: {Society}, {Security}, {Innovation} and {Ethics}},
	publisher = {Palgrave Macmillan UK},
	author = {Reid, David},
	editor = {Bunnik, Anno and Cawley, Anthony and Mulqueen, Michael and Zwitter, Andrej},
	year = {2016},
	doi = {10.1057/978-1-349-94885-7_2},
	keywords = {Artificial intelligence, Algorithms, Data science, Statistics, Machine learning, Automated reasoning, Big Data, Human intelligence},
	pages = {11--22},
}

@misc{noauthor_data_nodate-2,
	title = {Data {Science} {Corporation}},
	url = {https://www.manta.com/c/mm2cgdg/data-science-corporation},
	urldate = {2020-07-01},
	journal = {Manta.com},
	file = {Data Science Corporation Saint Louis MO, 63103 – Manta.com:/Users/rca2t1/Dropbox/Zotero/storage/HVMLZDWA/data-science-corporation.html:text/html},
}

@misc{noauthor_allen_nodate,
	title = {Allen, {Robert} ({Bob}) {E}. {Died} {July} 1st},
	url = {https://advance.lexis.com/document/teaserdocument/?pdmfid=1516831&crid=5f352f35-ed0e-4896-9dcc-cbb42fb4169e&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A5CKR-KK01-DY37-30GF-00000-00&pddocid=urn%3AcontentItem%3A5CKR-KK01-DY37-30GF-00000-00&pdcontentcomponentid=11810&pdteaserkey=h1&pditab=allpods&ecomp=kb63k&earg=sr8&prid=3e0f152c-ec6a-4c84-870b-a9fdb34097c1},
	urldate = {2020-07-01},
	file = {Allen, Robert (Bob) E. Died July 1st:/Users/rca2t1/Dropbox/Zotero/storage/KSG5GXJH/teaserdocument.html:text/html},
}

@article{noauthor_allen_2014,
	address = {Missouri},
	title = {Allen, {Robert} ({Bob}) {E}. {Died} {July} 1st.},
	url = {https://advance.lexis.com/api/document?collection=news&id=urn:contentItem:5CKR-KK01-DY37-30GF-00000-00&context=1516831},
	journal = {St. Louis Post-Dispatch},
	month = jul,
	year = {2014},
}

@misc{noauthor_document_nodate,
	title = {Document {\textbar} {America}'s {Historical} {Newspapers} {\textbar} {Readex}},
	url = {https://infoweb.newsbank.com/apps/readex/doc?p=EANX&sort=YMD_date%3AA&page=1&fld-base-0=alltext&val-base-0=%22data%20science%22&val-database-0=&fld-database-0=database&fld-nav-0=YMD_date&val-nav-0=&docref=image/v2%3A11A73E5827618330%40EANX-12FCC365104A4B0A%402440275-12FCB93BB7B1DA54%4071-12FCB93BB7B1DA54%40&firsthit=yes},
	urldate = {2020-07-01},
	file = {Document | America's Historical Newspapers | Readex:/Users/rca2t1/Dropbox/Zotero/storage/LA53DLDF/doc.html:text/html},
}

@book{altshuler_rise_2013,
	title = {The {Rise} and {Fall} of {Air} {Force} {Cambridge} {Research} {Laboratories}},
	isbn = {978-1-4818-3251-9},
	abstract = {This monograph provides a chronological account of how a fledgling research laboratory, which evolved from the MIT Radiation Laboratory and the Harvard Radio Research Laboratory after World War II, rose to become one of the premier research laboratories in the world as evidenced by its major accomplishments throughout its 66 year history. After many years of outstanding productivity the laboratory began to slowly decline. Even though the downsizing began in1974, the Hanscom Field Site continued to be very productive until its final days. In 2005 it was placed on the Base Realignment And Closure (BRAC) list and in August 2011 it was closed. Many of the major events that led to this decline were politically motivated. I had the privilege of collaborating with outstanding scientists from May 1960 to May 2011 and was blessed with a very rewarding career. One of the most ironic outcomes of the AFCRL history was the fact that when the laboratory was first established, the original plan was to move the new laboratory to Wright Field in Dayton, Ohio in 1946; this move actually occurred 65 years later. Also, after the Geophysics Research Directorate (GRD), was moved from New Jersey to Cambridge, MA in July 1948, there were numerous attempts to move GRD to Kirtland AFB. This also occurred in 2011.},
	language = {English},
	publisher = {CreateSpace Independent Publishing Platform},
	author = {Altshuler, Edward E.},
	month = jan,
	year = {2013},
}

@article{noauthor_about_nodate,
	title = {About this {Journal}},
	url = {http://datascience.codata.org/},
	abstract = {The CODATA Data Science Journal is a peer-reviewed, open access, electronic journal, publishing papers on the management, dissemination, use and reuse of research data and databases across all research domains, including science, technology, the humanities and the arts. The scope of the journal includes descriptions of data systems, their implementations and their publication, applications, infrastructures, software, legal, reproducibility and transparency issues, the availability and usability of complex datasets, and with a particular focus on the principles, policies and practices for open data.All data is in scope, whether born digital or converted from other sources.},
	language = {en},
	urldate = {2020-07-01},
	journal = {Data Science Journal},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/887P66MB/datascience.codata.org.html:text/html},
}

@article{parsons_revised_2019,
	title = {Revised {Focus} and {Scope}},
	url = {http://datascience.codata.org/},
	language = {en},
	urldate = {2020-07-01},
	journal = {The Data Science Journal},
	author = {Parsons, Mark A.},
	month = nov,
	year = {2019},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QNG8NERK/datascience.codata.org.html:text/html},
}

@phdthesis{stevens_life_2010,
	address = {United States -- Massachusetts},
	type = {Ph.{D}.},
	title = {Life out of sequence: {An} ethnographic account of bioinformatics from the {APPANET} to post -genomics},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	shorttitle = {Life out of sequence},
	url = {https://search.proquest.com/docview/305214317/CA0EA52D48E24CF9PQ/5},
	abstract = {Between the 1960s and the end of the first decade of the twenty-first century computers have transformed from esoteric devices to ubiquitous tools in biological work. Archival research, ethnographic fieldwork, and interviews have been combined to explain and investigate the consequences of this shift.
Early computers were used in the military and soon after for solving problems in the physical sciences. As such they were designed to solve specific kinds of problems: namely, problems of data management, simulations with large numbers of discrete data points, and statistical and stochastic problems. Computers also entailed and required the trappings of Big Science: big funding, multi-disciplinary collaboration, and careful management of laboratory spaces. The introduction of computers into the life sciences has imported both this style of knowledge production and these forms of practice and organization into the discipline of biology. Biology questions have become re-oriented from those that seek to understand individual genes or proteins towards those that seek to use the data management and statistical power of computer to understand large sets of biological objects. Meanwhile, biological practice has been transformed to organize and manage the interdisciplinary intersections between biologists, mathematicians, computer scientists, statisticians, and engineers who are all required in order to perform productive biological work.
Moreover, the long strings of letters that represent protein and DNA sequences were especially susceptible to the kinds of data and statistical manipulations which could be performed on computers. The computer enabled the study of life 'out of sequence,' finding patterns in the apparently disordered spaces of genomes.},
	language = {English},
	urldate = {2020-07-01},
	school = {Harvard University},
	author = {Stevens, Hallam},
	year = {2010},
	note = {ISBN: 9781109644470},
	keywords = {Social sciences, APPANET, Bioinformatics, Biological sciences, Ethnography, Genomics, Sequence},
}

@article{belzer_concise_1976,
	title = {Concise {Survey} of {Computer} {Methods}. {Peter} {Naur}. {New} {York}: {Petrocelli} {Books}, 397 {P}. (1975)},
	volume = {27},
	copyright = {Copyright © 1976 Wiley Periodicals, Inc., A Wiley Company},
	issn = {1097-4571},
	shorttitle = {Concise {Survey} of {Computer} {Methods}. {Peter} {Naur}. {New} {York}},
	url = {https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.4630270213},
	doi = {10.1002/asi.4630270213},
	language = {en},
	number = {2},
	urldate = {2020-07-01},
	journal = {Journal of the American Society for Information Science},
	author = {Belzer, Jack},
	year = {1976},
	note = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.4630270213},
	pages = {125--126},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WD4WTCEX/asi.html:text/html},
}

@inproceedings{naur_datalogy_1968,
	title = {'{Datalogy}', the {Science} of {Data} and {Data} {Processes}.},
	booktitle = {{IFIP} {Congress} (2)},
	author = {Naur, Peter},
	year = {1968},
	pages = {1383--1387},
}

@incollection{bjorner_conceptual_1988,
	title = {Conceptual {Threads} of {Datalogy}, {Informatics} and {Information} {Technology}: {Proposal} for {Their} {Foundation} in {Secondary} and {High} {School} {Education}},
	shorttitle = {Conceptual {Threads} of {Datalogy}, {Informatics} and {Information} {Technology}},
	booktitle = {Children in the {Information} {Age}},
	publisher = {Elsevier},
	author = {BJøRNER, DINES},
	year = {1988},
	pages = {19--36},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3J23J2K5/B9780080364643500077.html:text/html},
}

@article{sveinsdottir_datalogycopenhagen_1988,
	title = {Datalogy—the {Copenhagen} tradition of computer science},
	volume = {28},
	number = {3},
	journal = {BIT Numerical Mathematics},
	author = {Sveinsdottir, Edda and Frøkjær, Erik},
	year = {1988},
	note = {Publisher: Springer},
	pages = {450--472},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/BFJX5LQ6/Sveinsdottir and Frøkjær - 1988 - Datalogy—the Copenhagen tradition of computer scie.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QFYIQ8TD/BF01941128.html:text/html},
}

@inproceedings{kitagawa_datalogy_1981,
	title = {Datalogy and semiology in establishing knowledgeinformation processing systems in researches, {The} {Second} {Intern}},
	booktitle = {{HBDS} {Seminar}},
	author = {Kitagawa, T.},
	year = {1981},
	pages = {9--13},
}

@incollection{gromme_data_2018,
	title = {Data {Scientists}: {A} {New} {Faction} of the {Transnational} {Field} of {Statistics} [forthcoming]},
	author = {Grommé, Francisca and Ruppert, Evelyn and Cakici, Baki},
	year = {2018},
	file = {Grommé et al. - 2018 - Data Scientists A New Faction of the Transnationa.pdf:/Users/rca2t1/Dropbox/Zotero/storage/C5FKVH5S/Grommé et al. - 2018 - Data Scientists A New Faction of the Transnationa.pdf:application/pdf},
}

@book{naur_knowing_2013,
	edition = {1995 edition},
	title = {Knowing and the {Mystique} of {Logic} and {Rules}: including {True} {Statements} in {Knowing} and {Action} * {Computer} {Modelling} of {Human} {Knowing} {Activity} * {Coherent} ...},
	shorttitle = {Knowing and the {Mystique} of {Logic} and {Rules}},
	abstract = {Human knowing is examined as it emerges from classical  empirical psychology, with its ramifications into language, computing,  science, and scholarship. While the discussion takes empirical support  from a wide range, claims for the significance of logic and rules are  challenged throughout. Highlights of the discussion:    knowing is a matter of habits or dispositions that guide the  person's stream of consciousness;    rules of language have no  significance in language production and understanding, being  descriptions of linguistic styles;    statements that may be true  or false enter into ordinary linguistic activity, not as elements of  messages, but merely as summaries of situations, with a view to  action;    in computer programming the significance of logic,  proof, and formalized description, is incidental and subject to the  programmer's personality;    analysis of computer modelling of the  mental activity shows that in describing human knowing the computer is  irrelevant;    in accounting for the scholarly/scientific  activity, logic and rules are impotent;    a novel theory:  scholarship and science have coherent descriptions as their core.       The discussion addresses questions that are basic to advanced  applications of computers and to students of language and science.},
	language = {English},
	publisher = {Springer},
	author = {Naur, P.},
	month = mar,
	year = {2013},
	file = {Naur - 2013 - Knowing and the Mystique of Logic and Rules inclu.pdf:/Users/rca2t1/Dropbox/Zotero/storage/J3YQQFZE/Naur - 2013 - Knowing and the Mystique of Logic and Rules inclu.pdf:application/pdf},
}

@book{noauthor_library_1978,
	title = {Library {Journal}},
	volume = {103},
	abstract = {Includes, beginning Sept. 15, 1954 (and on the 15th of each month, Sept.-May) a special section: School library journal, ISSN 0000-0035, (called Junior libraries, 1954-May 1961). Also issued separately.},
	language = {en},
	publisher = {R.R. Bowker Company},
	year = {1978},
	note = {Google-Books-ID: uNjgAAAAMAAJ},
	annote = {Refers to the Environmental Data Science unit within NOAA.},
}

@article{parzen_nonparametric_1979,
	title = {Nonparametric {Statistical} {Data} {Modeling}},
	volume = {74},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2286734},
	doi = {10.2307/2286734},
	abstract = {This article attempts to describe an approach to statistical data analysis which is simultaneously parametric and nonparametric. Given a random sample X$_{\textrm{1}}$, ⋯, X$_{\textrm{n}}$ of a random variable X, one would like (1) to test the parametric goodness-of-fit hypothesis H$_{\textrm{0}}$ that the true distribution function F is of the form F(x) = F$_{\textrm{0}}$[ (x - μ)/σ], where F$_{\textrm{0}}$ is specified, and (2) when H$_{\textrm{0}}$ is not accepted, to estimate nonparametrically the true density-quantile function fQ(u) and score function J(u) = - (fQ)'(u). The article also introduces density-quantile functions, autoregressive density estimation, estimation of location and scale parameters by regression analysis of the sample quantile function, and quantile-box plots.},
	number = {365},
	urldate = {2020-07-03},
	journal = {Journal of the American Statistical Association},
	author = {Parzen, Emanuel},
	year = {1979},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {105--121},
	annote = {Tukey's comment on misuse of EDA is important.},
	file = {Parzen - 1979 - Nonparametric Statistical Data Modeling.pdf:/Users/rca2t1/Dropbox/Zotero/storage/AWD8REAI/Parzen - 1979 - Nonparametric Statistical Data Modeling.pdf:application/pdf},
}

@book{hayashi_data_1998-1,
	series = {Studies in {Classification}, {Data} {Analysis}, and {Knowledge} {Organization}},
	title = {Data {Science}, {Classification}, and {Related} {Methods}: {Proceedings} of the {Fifth} {Conference} of the {International} {Federation} of {Classification} {Societies} ({IFCS}-96), {Kobe}, {Japan}, {March} 27–30, 1996},
	isbn = {978-4-431-70208-5},
	shorttitle = {Data {Science}, {Classification}, and {Related} {Methods}},
	url = {https://www.springer.com/gp/book/9784431702085},
	abstract = {This volume, Data Science, Classification, and Related Methods, contains a selection of papers presented at the Fifth Conference of the International Federation of Oassification Societies (IFCS-96), which was held in Kobe, Japan, from March 27 to 30,1996. The volume covers a wide range of topics and perspectives in the growing field of data science, including theoretical and methodological advances in domains relating to data gathering, classification and clustering, exploratory and multivariate data analysis, and knowledge discovery and seeking. It gives a broad view of the state of the art and is intended for those in the scientific community who either develop new data analysis methods or gather data and use search tools for analyzing and interpreting large and complex data sets. Presenting a wide field of applications, this book is of interest not only to data analysts, mathematicians, and statisticians but also to scientists from many areas and disciplines concerned with complex data: medicine, biology, space science, geoscience, environmental science, infonnation science, image and pattern analysis, economics, statistics, social sciences, psychology, cognitive science, behavioral science, marketing and survey research, data mining, and knowledge organization.},
	language = {en},
	urldate = {2020-07-03},
	publisher = {Springer Japan},
	editor = {Hayashi, Chikio and Yajima, Keiji and Bock, Hans H. and Ohsumi, Noboru and Tanaka, Yutaka and Baba, Yasumasa},
	year = {1998},
	doi = {10.1007/978-4-431-65950-1},
	file = {Hayashi et al. - 1998 - Data Science, Classification, and Related Methods.pdf:/Users/rca2t1/Dropbox/Zotero/storage/YAK9L8I4/Hayashi et al. - 1998 - Data Science, Classification, and Related Methods.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NKGDGMPA/9784431702085.html:text/html},
}

@incollection{ohsumi_data_2000,
	title = {From {Data} {Analysis} to {Data} {Science}},
	booktitle = {Data analysis, classification, and related methods},
	publisher = {Springer},
	author = {Ohsumi, Noboru},
	year = {2000},
	pages = {329--334},
	file = {Ohsumi - 2000 - From Data Analysis to Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3C6WPP3A/Ohsumi - 2000 - From Data Analysis to Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/5H6YYNJX/978-3-642-59789-3_52.html:text/html},
}

@article{zhang_development_2017,
	title = {The {Development} of {Data} {Science} {Education} in {China} from the {LIS} {Perspective}},
	volume = {2},
	number = {2},
	journal = {International Journal of Librarianship},
	author = {Zhang, Jilong and Fu, Anna and Wang, Hao and Yin, Shenqing},
	year = {2017},
	pages = {3--17},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/WBKCWQZI/Zhang et al. - 2017 - The Development of Data Science Education in China.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/IKSBDKS7/29.html:text/html},
}

@article{liu_use_2017,
	title = {The use of data science for education: {The} case of social-emotional learning},
	volume = {4},
	shorttitle = {The use of data science for education},
	number = {1},
	journal = {Smart Learning Environments},
	author = {Liu, Ming-Chi and Huang, Yueh-Min},
	year = {2017},
	note = {Publisher: Springer},
	pages = {1},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/5R77LHM6/s40561-016-0040-4.html:text/html},
}

@article{murtagh_development_2018,
	title = {The {Development} of {Data} {Science}: {Implications} for {Education}, {Employment}, {Research}, and the {Data} {Revolution} for {Sustainable} {Development}},
	volume = {2},
	shorttitle = {The {Development} of {Data} {Science}},
	number = {2},
	journal = {Big Data and Cognitive Computing},
	author = {Murtagh, Fionn and Devlin, Keith},
	year = {2018},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {14},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/GVEFSM74/Murtagh and Devlin - 2018 - The Development of Data Science Implications for .pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/AXRB9T8Q/14.html:text/html},
}

@book{diday_new_2013,
	title = {New {Approaches} in {Classification} and {Data} {Analysis}},
	isbn = {978-3-642-51175-2},
	abstract = {The subject of this book is the analysis and processing of structural or quantitative data with emphasis on classification methods, new algorithms as well as applications in various fields related to data analysis and classification. The book presents the state of the art in world-wide research and application of methods from the fields indicated above and consists of survey papers as well as research papers.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Diday, Edwin and Lechevallier, Yves and Schader, Martin and Bertrand, Patrice and Burtschy, Bernard},
	month = mar,
	year = {2013},
	note = {Google-Books-ID: CH7yCAAAQBAJ},
	keywords = {Business \& Economics / Economics / Theory, Business \& Economics / Econometrics, Business \& Economics / Economics / General, Mathematics / Applied, Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Medical / Biostatistics},
	annote = {Has essay on Data Science!},
}

@incollection{ohsumi_new_1994,
	address = {Berlin},
	title = {New {Data} and {New} {Tools}: {A} {Hypermedia} {Environment} for {Navigating} {Statistical} {Knowledge} in {Data} {Science}},
	booktitle = {New {Approaches} in {Classification} and {Data} {Analysis}},
	publisher = {Springer-Verlag},
	author = {Ohsumi, Noboru},
	year = {1994},
	pages = {45--54},
}

@book{dodge_computational_2013,
	title = {Computational {Statistics}: {Volume} 1: {Proceedings} of the 10th {Symposium} on {Computational} {Statistics}},
	isbn = {978-3-662-26811-7},
	shorttitle = {Computational {Statistics}},
	abstract = {The Role of the Computer in Statistics David Cox Nuffield College, Oxford OXIINF, U.K. A classification of statistical problems via their computational demands hinges on four components (I) the amount and complexity of the data, (il) the specificity of the objectives of the analysis, (iii) the broad aspects of the approach to analysis, (ill) the conceptual, mathematical and numerical analytic complexity of the methods. Computational requi rements may be limiting in (I) and (ill), either through the need for special programming effort, or because of the difficulties of initial data management or because of the load of detailed analysis. The implications of modern computational developments for statistical work can be illustrated in the context of the study of specific probabilistic models, the development of general statistical theory, the design of investigations and the analysis of empirical data. While simulation is usually likely to be the most sensible way of investigating specific complex stochastic models, computerized algebra has an obvious role in the more analyti cal work. It seems likely that statistics and applied probability have made insufficient use of developments in numerical analysis associated more with classical applied mathematics, in particular in the solution of large systems of ordinary and partial differential equations, integral equations and integra-differential equations and for the ¢raction of "useful" in formation from integral transforms. Increasing emphasis on models incorporating specific subject-matter considerations is one route to bridging the gap between statistical ana.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Dodge, Yadolah and Whittaker, Joe},
	month = nov,
	year = {2013},
	note = {Google-Books-ID: iVv9CAAAQBAJ},
	keywords = {Computers / Information Theory, Business \& Economics / Economics / Theory, Business \& Economics / Economics / General, Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Computers / Programming / Algorithms},
}

@book{dodge_computational_2012,
	title = {Computational {Statistics}: {Volume} 2: {Proceedings} of the 10th {Symposium} on {Computational} {Statistics}, {COMPSTAT}, {Neuchâtel}, {Switzerland}, {August} 1992},
	isbn = {978-3-642-48678-4},
	shorttitle = {Computational {Statistics}},
	abstract = {The papers assembled in this book were presented at the biannual symposium of Inter national Association for Statistical Computing in Neuchcitel, Switzerland, in August of 1992. This congress marked the tenth such meeting from its inception in 1974 at Vienna and maintained the tradition of providing a forum for the open discussion of progress made in computer oriented statistics and the dissemination of new ideas throughout the statistical community. It was gratifying to see how well the groups of theoretical statisti cians, software developers and applied research workers were represented, whose mixing is an event made uniquely possible by this symposium. While maintaining traditions certain new features have been introduced at this con ference: there were a larger number of invited speakers; there was more commercial sponsorship and exhibition space; and a larger body of proceedings have been published. The structure of the proceedings follows a standard format: the papers have been grouped together according to a rough subject matter classification, and within topic follow an approximate aphabetical order. The papers are published in two volumes ac cording to the emphasis of the topics: volume I gives a slight leaning towards statistics and modelling, while volume II is focussed more on computation; but this is certainly only a crude distinction and the volumes have to be thought of as the result of a single en terprise.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Dodge, Yadolah and Whittaker, Joe},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: ApjvCAAAQBAJ},
	keywords = {Computers / Information Theory, Business \& Economics / Economics / Theory, Business \& Economics / Economics / General, Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Computers / Programming / Algorithms},
}

@inproceedings{ohsumi_experimental_1992,
	address = {Heidelberg},
	title = {An {Experimental} {System} for {Navigating} {Statistical} {Meta}-{Information} — {The} {Meta}-{Stat} {Navigator}},
	isbn = {978-3-642-48678-4},
	doi = {10.1007/978-3-642-48678-4_48},
	abstract = {In research organizations handling statistical information, the volume of stored information resources, including research results, materials, and software, is increasing to the point that conventional separate databases and information management systems have become insufficient to deal with the amount. Increasing diversification in the media used these days interferes with the rapid retrieval and use of the information needed by users. A new system that realizes a presentation environment based on new concepts is needed to inform potential users of the value and effectiveness of using the vast amount of diverse data.},
	language = {en},
	booktitle = {Computational {Statistics}},
	publisher = {Physica-Verlag HD},
	author = {Ohsumi, Noboru},
	editor = {Dodge, Yadolah and Whittaker, Joe},
	year = {1992},
	keywords = {Human Interface, Information Management System, Navigation Function, Statistical Information, User Environment},
	pages = {375--380},
	file = {Ohsumi - 1992 - An Experimental System for Navigating Statistical .pdf:/Users/rca2t1/Dropbox/Zotero/storage/SL3NF85A/Ohsumi - 1992 - An Experimental System for Navigating Statistical .pdf:application/pdf},
}

@inproceedings{ohsumi_memories_2004,
	title = {Memories of {Chikio} {Hayashi} and {His} {Great} {Achievement}},
	url = {https://www.researchgate.net/publication/268719699_Memories_of_Chikio_Hayashi_and_his_great_achievement_2004},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2020-07-04},
	booktitle = {{ResearchGate}},
	author = {Ohsumi, Noboru},
	year = {2004},
	file = {2004 - Memories of Chikio Hayashi and His Great Achieveme.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2MYRVSK5/2004 - Memories of Chikio Hayashi and His Great Achieveme.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NTAT25TK/268719699_Memories_of_Chikio_Hayashi_and_his_great_achievement_2004.html:text/html},
}

@book{escoufier_data_1995,
	title = {Data {Science} and {Its} {Applications}},
	publisher = {Academic Press/Harcourt Brace},
	author = {Escoufier, Yves and Hayashi, Chikio and Fichet, Bernard},
	year = {1995},
}

@techreport{parzen_nonparametric_1977-1,
	type = {Grant {Technical} {Report}},
	title = {Nonparametric {Statistical} {Data} {Science}:  {A} {Unified} {Approach} {Based} on {Density} {Estimation} and {Testing} for '{White} {Noise}'},
	shorttitle = {{DTIC} {ADA051090}},
	url = {http://archive.org/details/DTIC_ADA051090},
	abstract = {This paper proposes an approach to non-parametric statistical continuous data science which seems to be consistent with the conventional theories and methods of non-parametric inference but seems to point the way to universally applicable procedures (for continuous data) which are asymptotically as efficient as the best conventional goodness of fit and parameter estimation procedures available for each particular problem. The methods described are programmed and found successful in test cases. However, in the space available here only 'Chapter 1' of this work can be discussed. It outline the ideas:  how the basic general applied problems of statistical inference can be formulated as problems of estimation of distribution functions on the unit interval (or the unit hyper-cube), how such problems are more fruitfully treated as density estimation problems, and how to solve density estimation problems one can use the method which is the essence of the highly successful maximum likelihood method of parameter estimation: using a suitable information-theoretic divergence distance between densities, find the smooth density which is closest to a raw estimator of the density.},
	language = {english},
	number = {ARO-1},
	urldate = {2020-07-04},
	institution = {Defense Technical Information Center},
	author = {Parzen, Emanuel},
	month = jan,
	year = {1977},
	note = {DTIC ADA051090},
	keywords = {*NONPARAMETRIC STATISTICS, *STATISTICAL TESTS, *WHITE NOISE, ASYMPTOTIC NORMALITY, BIVARIATE ANALYSIS, DENSITY, DTIC Archive, ESTIMATES, NORMAL DISTRIBUTION, ORDER STATISTICS, Parzen,Emanuel, RANK ORDER STATISTICS, REGRESSION ANALYSIS, RELIABILITY, STATE UNIV OF NEW YORK AT BUFFALO AMHERST  STATISTICAL SCIENCE DIV, STATISTICAL INFERENCE, TIME SERIES ANALYSIS},
	pages = {63},
	file = {Parzen - 1977 - Nonparametric Statistical Data Science  A Unified.pdf:/Users/rca2t1/Dropbox/Zotero/storage/UJG3SK35/Parzen - 1977 - Nonparametric Statistical Data Science  A Unified.pdf:application/pdf},
}

@book{berners-lee_weaving_2008,
	title = {Weaving the {Web}: {The} {Original} {Design} and {Ultimate} {Destiny} of the {World} {Wide} {Web} by {Its} {Inventor}},
	isbn = {978-1-4395-0036-1},
	shorttitle = {Weaving the {Web}},
	abstract = {Named one of the greatest minds of the 20th century by Time, Tim Berners-Lee is responsible for one of that century's most important advancements: the world wide web.  Now, this low-profile genius-who never personally profitted from his invention -offers a compelling protrait of his invention.  He reveals the Web's origins and the creation of the now ubiquitous http and www acronyms and shares his views on such critical issues as censorship, privacy, the increasing power of softeware companies , and the need to find the ideal balance between commercial and social forces.  He offers insights into the true nature of the Web, showing readers how to use it to its fullest advantage.  And he presents his own plan for the Web's future, calling for the active support and participation of programmers, computer manufacturers, and social organizations to manage and maintain this valuable resource so that it can remain a powerful force for social change and an outlet for individual creativity.},
	language = {en},
	publisher = {Paw Prints},
	author = {Berners-Lee, Tim and Fischetti, Mark},
	month = jun,
	year = {2008},
	note = {Google-Books-ID: Unp4PwAACAAJ},
	keywords = {Computers / Web / General},
}

@article{mcnicholas_data_2019,
	title = {Data science},
	url = {https://www.facetsjournal.com/doi/10.1139/facets-2019-0005},
	doi = {10.1139/facets-2019-0005},
	abstract = {Data science},
	language = {en},
	urldate = {2020-07-04},
	journal = {FACETS},
	author = {McNicholas, Paul D.},
	month = may,
	year = {2019},
	note = {Publisher: Canadian Science Publishing 65 Auriga Drive, Suite 203, Ottawa, ON K2E 7W6},
	file = {McNicholas - 2019 - Data science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/FKCC88NT/McNicholas - 2019 - Data science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/AMVCKFQU/facets-2019-0005.html:text/html},
}

@article{tukey_nonparametric_1979,
	title = {Nonparametric {Statistical} {Data} {Modeling}: {Comment}},
	volume = {74},
	issn = {0162-1459},
	shorttitle = {Nonparametric {Statistical} {Data} {Modeling}},
	url = {https://www.jstor.org/stable/2286735},
	doi = {10.2307/2286735},
	number = {365},
	urldate = {2020-07-05},
	journal = {Journal of the American Statistical Association},
	author = {Tukey, John W.},
	year = {1979},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {121--122},
	annote = {"Replacing chicken by tuna in chicken salad will not give fish wings or train chickens to swim." (122)},
	file = {Tukey - 1979 - Nonparametric Statistical Data Modeling Comment.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3P2YS6ZV/Tukey - 1979 - Nonparametric Statistical Data Modeling Comment.pdf:application/pdf},
}

@incollection{ohsumi_role_1988,
	title = {Role of {Computer} {Graphics} in {Interpretation} of {Clustering} {Results}},
	isbn = {978-0-12-215485-0},
	url = {http://www.sciencedirect.com/science/article/pii/B9780122154850500211},
	abstract = {This chapter discusses the role of computer graphics in interpretation of clustering results. The utility of computer graphics has won the recognition of many researchers specializing in data analysis, and a variety of graphical representation methods have been proposed by them. From graphical representation, data analysts expect to obtain a firm grasp of the intrinsic structure of collected data by visualizing their features. The hardware environment bears closely upon free use of graphical representation as a means of data analysis. It deserves attention that the functional improvement of microcomputers and workstations has provided freedom of graphical representation and greater ease of graphics equipment operation. These graphical representation methods have some common features—(1) representing the features of multivariate data, (2) visual inspection of the relationship among variables, (3) observing data distribution, (4) projections based on data transformation and features selection, and (5) enhancement of intrinsic features in data.},
	language = {en},
	urldate = {2020-07-05},
	booktitle = {Recent {Developments} in {Clustering} and {Data} {Analysis}},
	publisher = {Academic Press},
	author = {Ohsumi, Noboru},
	editor = {Hayashi, Chikio and Jambu, Michel and Diday, Edwin and Ohsumi, Noboru},
	month = jan,
	year = {1988},
	doi = {10.1016/B978-0-12-215485-0.50021-1},
	pages = {201--222},
	file = {ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/N3CX8UH9/B9780122154850500211.html:text/html},
}

@book{bohme_100_1991,
	title = {100 {Years} of {Data} {Processing}: {The} {Punchcard} {Century}},
	shorttitle = {100 {Years} of {Data} {Processing}},
	language = {en},
	publisher = {U.S. Department of Commerce, Bureau of the Census, Data User Services Division},
	author = {Bohme, Frederick G.},
	year = {1991},
	note = {Google-Books-ID: uCeu4sHRLfgC},
}

@misc{bock_history_2001,
	title = {A history of the {International} {Federation} of {Classification} {Societies}},
	author = {Bock, Hans-Hermann},
	year = {2001},
	file = {Bock - 2001 - A history of the International Federation of Class.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RVZFF3ML/Bock - 2001 - A history of the International Federation of Class.pdf:application/pdf},
}

@article{yajima_japanese_1990,
	title = {Japanese {Classification} {Society} ({JCS})},
	volume = {1},
	journal = {International Federation of Classification Societies Newsletter},
	editor = {Yajima, Keiji},
	month = oct,
	year = {1990},
	file = {Murtagh and Yajima - 1990 - Japanese Classification Society (JCS).pdf:/Users/rca2t1/Dropbox/Zotero/storage/6XUC8YBB/Murtagh and Yajima - 1990 - Japanese Classification Society (JCS).pdf:application/pdf},
}

@inproceedings{hayashi_beyond_1998,
	address = {Berlin, Heidelberg},
	series = {Studies in {Classification}, {Data} {Analysis}, and {Knowledge} {Organization}},
	title = {Beyond {Simpson}’s {Paradox}: {One} {Problem} in {Data} {Science}},
	isbn = {978-3-642-72253-0},
	shorttitle = {Beyond {Simpson}’s {Paradox}},
	doi = {10.1007/978-3-642-72253-0_9},
	abstract = {In the present paper, the conditions under which Simpson’s paradox does not occur are discussed for various cases. These conditions are first obtained from the descriptive point of view and then on the assumption of prior probability distributions of parameters. The robustness of the results is discussed with respect to the prior probability distributions. Practically, the result is given as the magnitude of odds ratio (or relative risk), i.e., Simpson’s paradox does not occur if the odds ratio is more or less than a certain values, depending on various cases.},
	language = {en},
	booktitle = {Advances in {Data} {Science} and {Classification}},
	publisher = {Springer},
	author = {Hayashi, Chikio and Yamaoka, Kazue},
	editor = {Rizzi, Alfredo and Vichi, Maurizio and Bock, Hans-Hermann},
	year = {1998},
	keywords = {conditions of non-paradox, descriptive approach, Monte Carlo solution, prior probability distribution of a parameter, robustness of solution, Simpson’s paradox},
	pages = {65--72},
}

@book{rizzi_advances_2013,
	title = {Advances in {Data} {Science} and {Classification}: {Proceedings} of the 6th {Conference} of the {International} {Federation} of {Classification} {Societies} ({IFCS}-98) {Università} “{La} {Sapienza}”, {Rome}, 21–24 {July}, 1998},
	shorttitle = {Advances in {Data} {Science} and {Classification}},
	publisher = {Springer Science \& Business Media},
	author = {Rizzi, Alfredo and Vichi, Maurizio and Bock, Hans-Hermann},
	year = {2013},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JZM9YHPM/books.html:text/html},
}

@book{schader_between_2012,
	title = {Between {Data} {Science} and {Applied} {Data} {Analysis}: {Proceedings} of the 26th {Annual} {Conference} of the {Gesellschaft} {Für} {Klassifikation} {EV}, {University} of {Mannheim}, {July} 22–24, 2002},
	shorttitle = {Between {Data} {Science} and {Applied} {Data} {Analysis}},
	publisher = {Springer Science \& Business Media},
	author = {Schader, Martin and Gaul, Wolfgang A. and Vichi, Maurizio},
	year = {2012},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/PJLLNQCU/books.html:text/html},
}

@misc{noauthor_welcome_nodate,
	title = {Welcome to the {International} {Federation} of {Classification} {Societies} [{International} {Federation} of {Classification} {Societies} ]},
	url = {https://ifcs.boku.ac.at/site/doku.php?id=start},
	urldate = {2020-07-11},
	file = {Welcome to the International Federation of Classification Societies [International Federation of Classification Societies ]:/Users/rca2t1/Dropbox/Zotero/storage/ZPMYR87B/doku.html:text/html},
}

@misc{noauthor_newsletter_nodate,
	title = {Newsletter [{International} {Federation} of {Classification} {Societies} ]},
	url = {https://ifcs.boku.ac.at/site/doku.php?id=newsletter},
	urldate = {2020-07-11},
	file = {Newsletter [International Federation of Classification Societies ]:/Users/rca2t1/Dropbox/Zotero/storage/ADSAXSCL/doku.html:text/html},
}

@misc{garczarek_starting_2020,
	title = {Starting a {Debate}: {Data} {Science} – {Occupation} or {Profession}? {A} {Discussion} {Paper}},
	shorttitle = {Starting a {Debate}},
	url = {https://publikationen.bibliothek.kit.edu/1000120418},
	abstract = {With this contribution at the ECDA-2019 in Bayreuth we want to start a much needed debate about the nature of the work of a data scientist. Is it a mere occupation or does the societal impact together with ethical issues surrounding the work imply data science should become a real profession in the sense of Airaksinen (Airaksinen, 2009). We explore the elements of data science and the responsibility a data scientist has for society. Some barriers are identified and what can be done about them. In this paper, we describe the line of reasoning which was presented, and some lessons learned from the actual discussions with the audience.},
	language = {de},
	urldate = {2020-07-11},
	journal = {Archives of Data Science, Series A},
	author = {Garczarek, Ursula and Steuer, Detlef},
	year = {2020},
	doi = {10.5445/KSP/1000098011/16},
	note = {ISSN: 2363-9881
Issue: 1
Library Catalog: publikationen.bibliothek.kit.edu
Pages: 16
Volume: 6},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/M5U2A78Q/Garczarek and Steuer - 2020 - Starting a Debate Data Science – Occupation or Pr.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/S47EE5FV/1000120418.html:text/html},
}

@article{gallie_essentially_1955,
	title = {Essentially {Contested} {Concepts}},
	volume = {56},
	issn = {0066-7374},
	url = {https://www.jstor.org/stable/4544562},
	urldate = {2020-07-11},
	journal = {Proceedings of the Aristotelian Society},
	author = {Gallie, W. B.},
	year = {1955},
	note = {Publisher: [Aristotelian Society, Wiley]},
	pages = {167--198},
	file = {Gallie - 1955 - Essentially Contested Concepts.pdf:/Users/rca2t1/Dropbox/Zotero/storage/N7998LKI/Gallie - 1955 - Essentially Contested Concepts.pdf:application/pdf},
}

@article{bix_h_1991,
	title = {H. {L}. {A}. {Hart} and the "{Open} {Texture}" of {Language}},
	volume = {10},
	issn = {0167-5249},
	url = {https://www.jstor.org/stable/3504835},
	doi = {10.2307/3504835},
	abstract = {H. L. A. Hart and the "Open Texture" of Language tries to clarify the writings of both Hart and Friedrich Waismann on "open texture". In Waismann's work, "open texture" referred to the potential vagueness of words under extreme (hypothetical) circumstances. Hart's use of the term was quite different, and his work has been misunderstood because those differences were underestimated. Hart should not be read as basing his argument for judicial discretion on the nature of language; primarily, he was putting forward a policy argument for why rules should be applied in a way which would require that discretion.},
	number = {1},
	urldate = {2020-07-11},
	journal = {Law and Philosophy},
	author = {Bix, Brian},
	year = {1991},
	note = {Publisher: Springer},
	pages = {51--72},
	file = {Bix - 1991 - H. L. A. Hart and the Open Texture of Language.pdf:/Users/rca2t1/Dropbox/Zotero/storage/BCHML88U/Bix - 1991 - H. L. A. Hart and the Open Texture of Language.pdf:application/pdf},
}

@article{waismann_many-level-structure_1946,
	title = {The {Many}-{Level}-{Structure} of {Language}},
	volume = {5},
	issn = {0039-7857},
	url = {https://www.jstor.org/stable/20113867},
	number = {5/6},
	urldate = {2020-07-11},
	journal = {Synthese},
	author = {Waismann, Friedrich},
	year = {1946},
	note = {Publisher: Springer},
	pages = {221--229},
	file = {Waismann - 1946 - The Many-Level-Structure of Language.pdf:/Users/rca2t1/Dropbox/Zotero/storage/CWKNHBEA/Waismann - 1946 - The Many-Level-Structure of Language.pdf:application/pdf},
}

@book{levi-strauss_introduction_1987,
	address = {London},
	title = {Introduction to the {Work} of {Marcel} {Mauss}},
	isbn = {978-0-415-15158-0},
	abstract = {First published in 1987. Routledge is an imprint of Taylor \& Francis, an informa company.},
	language = {English},
	publisher = {Routledge},
	author = {Levi-Strauss, Claude},
	month = jan,
	year = {1987},
	file = {Levi-Strauss - 1987 - Introduction to the Work of Marcel Mauss.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ICKWSLU5/Levi-Strauss - 1987 - Introduction to the Work of Marcel Mauss.pdf:application/pdf},
}

@inproceedings{piatetsky-shapiro_overview_1994,
	address = {London},
	series = {Workshops in {Computing}},
	title = {An {Overview} of {Knowledge} {Discovery} in {Databases}: {Recent} {Progress} and {Challenges}},
	isbn = {978-1-4471-3238-7},
	shorttitle = {An {Overview} of {Knowledge} {Discovery} in {Databases}},
	doi = {10.1007/978-1-4471-3238-7_1},
	abstract = {I examine the state of the art in Knowledge Discovery in Databases and review progress in several research areas, including discovery of models, multistrategy discovery systems, and detection of changes and deviations. I describe a number of successful applications and discuss the remaining challenges for further research and application development.},
	language = {en},
	booktitle = {Rough {Sets}, {Fuzzy} {Sets} and {Knowledge} {Discovery}},
	publisher = {Springer},
	author = {Piatetsky-Shapiro, Gregory},
	editor = {Ziarko, Wojciech P.},
	year = {1994},
	keywords = {Discovery System, Fault Isolation, Inductive Logic Programming, Knowledge Discovery, Query Answer},
	pages = {1--10},
	file = {Piatetsky-Shapiro - 1994 - An Overview of Knowledge Discovery in Databases R:/Users/rca2t1/Dropbox/Zotero/storage/7MY73SAT/Piatetsky-Shapiro - 1994 - An Overview of Knowledge Discovery in Databases R:application/pdf},
}

@article{anderson_review_1965,
	title = {Review of {Corporate} {Finance} and {Fixed} {Investment}: {An} {Econometric} {Study}},
	volume = {55},
	issn = {0002-8282},
	shorttitle = {Review of {Corporate} {Finance} and {Fixed} {Investment}},
	url = {https://www.jstor.org/stable/1814608},
	number = {3},
	urldate = {2020-07-12},
	journal = {The American Economic Review},
	author = {White, William H.},
	collaborator = {Anderson, W. H. Locke},
	year = {1965},
	note = {Publisher: American Economic Association},
	pages = {615--617},
	annote = {Early appearance of "data mining" -- picking one model among many.},
	file = {White - 1965 - Review of Corporate Finance and Fixed Investment .pdf:/Users/rca2t1/Dropbox/Zotero/storage/EP2L9NLI/White - 1965 - Review of Corporate Finance and Fixed Investment .pdf:application/pdf},
}

@article{brockhoff_determinants_1970,
	title = {Determinants of {Research} and {Development} {Expenditure} in {Some} {Chemical} {Corporations} in {Germany}},
	volume = {10},
	issn = {0025-181X},
	url = {https://www.jstor.org/stable/40226777},
	number = {4/5},
	urldate = {2020-07-12},
	journal = {Management International Review},
	author = {Brockhoff, Klaus},
	year = {1970},
	note = {Publisher: Springer},
	pages = {71--84},
	annote = {Alternate, positive use pf "data mining."
 },
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/FH8LYNTW/Brockhoff - 1970 - Determinants of Research and Development Expenditu.pdf:application/pdf},
}

@article{jorgenson_comparison_1970,
	title = {A {Comparison} of {Alternative} {Econometric} {Models} of {Quarterly} {Investment} {Behavior}},
	volume = {38},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/1913003},
	doi = {10.2307/1913003},
	abstract = {In this paper four alternative quarterly econometric models of investment behavior are fitted to a common set of data for individual manufacturing industries in the United States. Goodness of fit and absence of autocorrelation of errors are used as a basis for comparison of the performance of the alternative models. The econometric models are compared with each other and with alternative explanations of data on investment based on surveys of anticipated investment and on mechanical forecasting schemes. The four econometric models included in our study are those of Anderson [2], Eisner [15], Jorgenson and Stephenson [38], and Meyer and Glauber [46]. On the basis of our comparison, the ranking of the alternative models is as follows: (1) Jorgenson-Stephenson, (2) Eisner, (3) Meyer-Glauber, (4) Anderson. Anticipatory data give a better fit to data on investment expenditures than that provided by any of the econometric models. Mechanical forecasting schemes provide a fit that is superior to the Anderson and Meyer-Glauber models. These schemes are slightly inferior to the Eisner model and clearly inferior to the Jorgenson-Stephenson model. The alternative econometric models included in our comparison differ in specification of the time structure of the investment process and in the role ascribed to specific determinants of investment behavior. Both aspects of an econometric model affect its performance so that it is difficult to discriminate among alternative determinants of investment behavior on the basis of our results.},
	number = {2},
	urldate = {2020-07-12},
	journal = {Econometrica},
	author = {Jorgenson, Dale W. and Hunter, Jerald and Nadiri, M. Ishag},
	year = {1970},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {187--212},
	annote = {



DATA MINING:: "As Anderson has emphasized [2, p. 108], empirical support at the level of industry groups provides protection against the effects of "data mining," that is, goodness offit resulting solely from the selection of the best fitting hypothesis among a very broad range of alternative specifications at the aggregate level."



},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/VCTY74BU/Jorgenson et al. - 1970 - A Comparison of Alternative Econometric Models of .pdf:application/pdf},
}

@article{jorgenson_predictive_1970,
	title = {The {Predictive} {Performance} of {Econometric} {Models} of {Quarterly} {Investment} {Behavior}},
	volume = {38},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/1913004},
	doi = {10.2307/1913004},
	abstract = {In this paper four alternative quarterly econometric models of investment behavior are compared with regard to predictive performance. Predictive performance may be assessed in two ways: (i) We compare prediction errors for a period of prediction with errors for a period of fit. (ii) We fit investment functions for both periods and test for structural change. These two procedures may be viewed as alternative tests of the hypothesis of structural change; the second is more powerful from the statistical point of view. Test of predictive performance supplement the comparisons of alternative models given in our preceding paper [17]. Goodness of fit may be exaggerated by consideration of a wide range of alternatives and selection of the one that fits best. If goodness of fit is exaggerated, a predictive test should produce evidence of structural change between the period of fit and the period of prediction. Of course, the better an econometric model fits the data, the more stringent this criterion for predictive performance. The econometric models included in our study are those of Anderson [1], Eisner [7], Jorgenson and Stephenson [19], and Meyer and Glauber [21]. On the basis of predictive performance the ranking of the alternative models is as follows: (1) Eisner, (2) Jorgenson-Stephenson, (3) Meyer-Glauber, and (4) Anderson. This ranking is similar to that resulting from comparisons based on goodness of it presented in our preceding paper [17]. For econometric models of quarterly investment behavior, the models that fit the best also have the best predictive performance.},
	number = {2},
	urldate = {2020-07-12},
	journal = {Econometrica},
	author = {Jorgenson, Dale W. and Hunter, Jerald and Nadiri, M. Ishag},
	year = {1970},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {213--224},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/XMIBYZ5I/Jorgenson et al. - 1970 - The Predictive Performance of Econometric Models o.pdf:application/pdf},
}

@article{morawetz_international_1970,
	title = {International {Comparisons} of {Income} {Levels}: {A} {Comment}},
	volume = {80},
	issn = {0013-0133},
	shorttitle = {International {Comparisons} of {Income} {Levels}},
	url = {https://www.jstor.org/stable/2229931},
	doi = {10.2307/2229931},
	number = {320},
	urldate = {2020-07-12},
	journal = {The Economic Journal},
	author = {Morawetz, David},
	year = {1970},
	note = {Publisher: [Royal Economic Society, Wiley]},
	pages = {977--980},
	annote = {Negative use of "data mining."
"These properties of " data mining " procedures have been demonstrated in experiments performed by A. Ando and G. M. Kaufman.2 They examined the general case, of which the Beckerman-Bacon study is an example, of the researcher who has a model with r independent variables but only n {\textless} r observations available."},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/QQSKECMM/Morawetz - 1970 - International Comparisons of Income Levels A Comm.pdf:application/pdf},
}

@article{ando_evaluation_1966,
	title = {Evaluation of an {Ad} {Hoc} {Procedure} for {Estimating} {Parameters} of {Some} {Linear} {Models}},
	volume = {48},
	issn = {0034-6535},
	url = {https://www.jstor.org/stable/1927089},
	doi = {10.2307/1927089},
	number = {3},
	urldate = {2020-07-12},
	journal = {The Review of Economics and Statistics},
	author = {Ando, A. and Kaufman, G. M.},
	year = {1966},
	note = {Publisher: The MIT Press},
	pages = {334--340},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/DZDXQTP4/Ando and Kaufman - 1966 - Evaluation of an Ad Hoc Procedure for Estimating P.pdf:application/pdf},
}

@article{shapiro_is_1973,
	title = {Is {Verification} {Possible}? {The} {Evaluation} of {Large} {Econometric} {Models}},
	volume = {55},
	issn = {0002-9092},
	shorttitle = {Is {Verification} {Possible}?},
	url = {https://www.jstor.org/stable/1238449},
	doi = {10.2307/1238449},
	number = {2},
	urldate = {2020-07-12},
	journal = {American Journal of Agricultural Economics},
	author = {Shapiro, Harold T.},
	year = {1973},
	note = {Publisher: [Agricultural \& Applied Economics Association, Oxford University Press]},
	pages = {250--258},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/4A7DWZIB/Shapiro - 1973 - Is Verification Possible The Evaluation of Large .pdf:application/pdf},
}

@article{lovell_data_1983,
	title = {Data {Mining}},
	volume = {65},
	issn = {0034-6535},
	url = {https://www.jstor.org/stable/1924403},
	doi = {10.2307/1924403},
	number = {1},
	urldate = {2020-07-12},
	journal = {The Review of Economics and Statistics},
	author = {Lovell, Michael C.},
	year = {1983},
	note = {Publisher: The MIT Press},
	pages = {1--12},
	file = {Lovell - 1983 - Data Mining.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ME68FX9U/Lovell - 1983 - Data Mining.pdf:application/pdf},
}

@article{beckerman_international_1970,
	title = {International {Income} {Comparisons}: {A} {Reply} to {Morawetz}},
	volume = {80},
	issn = {0013-0133},
	shorttitle = {International {Income} {Comparisons}},
	url = {https://www.jstor.org/stable/2229932},
	doi = {10.2307/2229932},
	number = {320},
	urldate = {2020-07-12},
	journal = {The Economic Journal},
	author = {Beckerman, Wilfred and Bacon, Robert},
	year = {1970},
	note = {Publisher: [Royal Economic Society, Wiley]},
	pages = {981--982},
	annote = {Defense of data mining.},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/WJZD4C85/Beckerman and Bacon - 1970 - International Income Comparisons A Reply to Moraw.pdf:application/pdf},
}

@article{sargan_review_1971,
	title = {Review of {Essays} in {Industrial} {Econometrics}},
	volume = {81},
	issn = {0013-0133},
	url = {https://www.jstor.org/stable/2229776},
	doi = {10.2307/2229776},
	number = {321},
	urldate = {2020-07-12},
	journal = {The Economic Journal},
	author = {Sargan, J. D.},
	collaborator = {Klein, L. R.},
	year = {1971},
	note = {Publisher: [Royal Economic Society, Wiley]},
	pages = {163--165},
	annote = {There is certainly danger in "data-mining." But there is equally danger in specifying a priori a simple model, and subjecting the resulting estimates ...},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/3VQ86IGR/Sargan - 1971 - Review of Essays in Industrial Econometrics.pdf:application/pdf},
}

@book{hendry_dynamic_1995,
	address = {New York},
	series = {Advanced {Texts} in {Econometrics}},
	title = {Dynamic {Econometrics}},
	isbn = {978-0-19-828316-4},
	url = {https://www.google.com/books/edition/Dynamic_Econometrics/XcWVN2-2ZqIC?hl=en&gbpv=1&dq=%22data+mining%22&pg=PA544&printsec=frontcover},
	urldate = {2020-07-12},
	publisher = {Oxford Univ Press},
	author = {Hendry, David F.},
	year = {1995},
	annote = {See Chapter 15, Section 15.1: Data Mining

"Data mining" is an accusation sometimes used to dismiss results where empirical evidence is deemed to have played an excessive role in modeling." (p. 544)

 },
	file = {Dynamic Econometrics - Google Books:/Users/rca2t1/Dropbox/Zotero/storage/6VCK4EQZ/XcWVN2-2ZqIC.html:text/html},
}

@incollection{bird_thomas_2018,
	edition = {Winter 2018},
	title = {Thomas {Kuhn}},
	url = {https://plato.stanford.edu/archives/win2018/entrieshomas-kuhn/},
	abstract = {Thomas Samuel Kuhn (1922–1996) is one of the most influentialphilosophers of science of the twentieth century, perhaps the mostinfluential. His 1962 book The Structure of ScientificRevolutions is one of the most cited academic books of alltime. Kuhn’s contribution to the philosophy of science marked not onlya break with several key positivist doctrines, but also inaugurated anew style of philosophy of science that brought it closer to thehistory of science. His account of the development of science heldthat science enjoys periods of stable growth punctuated by revisionaryrevolutions. To this thesis, Kuhn added the controversial‘incommensurability thesis’, that theories from differingperiods suffer from certain deep kinds of failure ofcomparability.},
	urldate = {2020-07-12},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Bird, Alexander},
	editor = {Zalta, Edward N.},
	year = {2018},
}

@misc{swan_skills_2008,
	type = {Programme/{Project} deposit},
	title = {The {Skills}, {Role} and {Career} {Structure} of {Data} {Scientists} and {Curators}: {An} {Assessment} of {Current} {Practice} and {Future} {Needs}},
	shorttitle = {The {Skills}, {Role} and {Career} {Structure} of {Data} {Scientists} and {Curators}},
	url = {http://repository.jisc.ac.uk/245/},
	urldate = {2020-07-12},
	author = {Swan, Alma and Brown, Sheridan},
	month = sep,
	year = {2008},
	note = {Library Catalog: repository.jisc.ac.uk},
	annote = {


QUOTE 1: Data Scientist 







Data scientist: people who work where the research is carried out – or, in the case of data centre personnel, in close collaboration with the creators of the data – and may be involved in creative enquiry and analysis, enabling others to work with digital data, and developments in data base technology 







QUOTE 2: Data Science (roughly)










Researchers in general are becoming much more aware of the issues that data-based research raise. Some already possess considerable skills in handling and managing data (so-called ‘native data scientists’), but even those less experienced in this regard show an interest in learning more. They turn, in the absence of a data scientist in their circle, to the institutional IT services or library for assistance and advice. Some UK universities are now beginning to offer taught master’s courses in data management which may help to raise the general data skill level. Just as data centres have been training data scientists for some time now and accepting that they will eventually leave for other jobs, thus helping to diffuse data skills into the research community, so increasing numbers of researchers with postgraduate training specifically in data-related matters will do the same. 






},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/5FEGM2ND/245.html:text/html;Swan and Brown - 2008 - The skills, role and career structure of data scie.pdf:/Users/rca2t1/Dropbox/Zotero/storage/42R6ZYIG/Swan and Brown - 2008 - The skills, role and career structure of data scie.pdf:application/pdf},
}

@misc{noauthor_canary_nodate,
	title = {"{The} canary that forgot its song"},
	url = {https://japanese.livejournal.com/1910649.html},
	abstract = {Hello! I was watching the anime Shangri-la and I heard a Japanese kids song which I'm pretty sure is The Canary that forgot its/his song. I tried Googling for the lyrics or maybe just to listen to the whole song which I didn't have much luck. I also tried…},
	urldate = {2020-07-12},
	note = {Library Catalog: japanese.livejournal.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JTERZULM/1910649.html:text/html},
}

@misc{davis_canary_nodate,
	title = {The {Canary} that {Forgot} {Its} {Song}},
	author = {Davis, Miriam},
	file = {Davis - The Canary that Forgot Its Song.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NLXMS78W/Davis - The Canary that Forgot Its Song.pdf:application/pdf},
}

@article{sveinsdottir_datalogy_1988-1,
	title = {Datalogy — {The} copenhagen tradition of computer science},
	volume = {28},
	issn = {1572-9125},
	url = {https://doi.org/10.1007/BF01941128},
	doi = {10.1007/BF01941128},
	abstract = {Since the middle of the 1960s, computer science has been practised in Denmark under Peter Naur's termdatalogy, the science of data processes. Starting at Regenecentralen and the University of Copenhagen, the Copenhagen Tradition of Computer Science has developed its own special characteristics by means of a close connection with applications and other fields of knowledge. The tradition is not least visible in the area of education. Comprehensive project activity is an integral part of the curriculum, thus presenting theory as an aspect of realistic solutions known primarily through actual experience. Peter Naur early recognized the particular educational challenges presented by computer science. His innovations have shown their quality and vitality also at other universities. There is a close connection between computer science training as it has been formed at Copenhagen University, and the view of computer science which has characterized Peter Naur's research. We illustrate how the study of programming and system development conceived as a human activity has been an all-pervasive theme in Naur's work. This approach has set the scene for central research issues in software development which today seem more topical than ever.},
	language = {en},
	number = {3},
	urldate = {2020-07-13},
	journal = {BIT Numerical Mathematics},
	author = {Sveinsdottir, Edda and Frøkjær, Erik},
	month = sep,
	year = {1988},
	pages = {450--472},
}

@misc{noauthor_asa_nodate,
	title = {{ASA} {Community}},
	url = {https://community.amstat.org},
	abstract = {The ASA Community is an online gateway for member collaboration and connection.},
	language = {en},
	urldate = {2020-07-14},
	note = {Library Catalog: community.amstat.org},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/MKBM2J88/the-role-of-statistics-in-data-science-an-asa-statement.html:text/html},
}

@misc{the_american_statistical_association_asa_2015,
	title = {{ASA} {Statement} on {The} {Role} of {Statistics} in {Data} {Science}},
	publisher = {The American Statistical Association},
	author = {{The American Statistical Association}},
	month = aug,
	year = {2015},
	annote = {


Sees three areas of DS    
(i) Database Management enables transformation, conglomeration, and organization of data resources; 
(ii) Statistics and Machine Learning convert data into knowledge; 
and (iii) Distributed and Parallel Systems provide the computational infrastructure to carry out data analysis. 


},
	file = {The American Statistical Association - 2015 - ASA Statement on The Role of Statistics in Data Sc.pdf:/Users/rca2t1/Dropbox/Zotero/storage/CAWE2BFX/The American Statistical Association - 2015 - ASA Statement on The Role of Statistics in Data Sc.pdf:application/pdf},
}

@article{piatetsky-shapiro_knowledge_1991-1,
	title = {Knowledge {Discovery} in {Real} {Databases}: {A} {Report} on the {IJCAI}-89 {Workshop}},
	volume = {11},
	url = {https://www.kdnuggets.com/meetings-past/kdd89/kdd-89-report-aimag.html},
	number = {5},
	urldate = {2020-07-14},
	journal = {AI Magazine},
	author = {Piatetsky-Shapiro, Gregory},
	month = jan,
	year = {1991},
	pages = {68--70},
	file = {KDD-89 Report, AI Magazine 1991:/Users/rca2t1/Dropbox/Zotero/storage/DN54FPH6/kdd-89-report-aimag.html:text/html;Piatetsky-Shapiro - 1991 - Knowledge Discovery in Real Databases A Report on.pdf:/Users/rca2t1/Dropbox/Zotero/storage/CNBKB2DF/Piatetsky-Shapiro - 1991 - Knowledge Discovery in Real Databases A Report on.pdf:application/pdf},
}

@book{leskovec_mining_2020,
	address = {New York},
	edition = {3rd},
	title = {Mining of {Massive} {Datasets}: {Pattern} recognition and machine learning},
	isbn = {978-1-108-47634-8},
	url = {https://www.cambridge.org/us/academic/subjects/computer-science/pattern-recognition-and-machine-learning/mining-massive-datasets-3rd-edition, https://www.cambridge.org/us/academic/subjects/computer-science/pattern-recognition-and-machine-learning},
	abstract = {Written by leading authorities in database and Web technologies, this book is essential reading for students and practitioners alike. The popularity of the Web and Internet commerce provides many extremely large datasets from which information can be gleaned by data mining. This book focuses on practical algorithms that have been used to solve key problems in data mining and can be applied successfully to even the largest datasets. It begins with a discussion of the MapReduce framework, an important tool for parallelizing algorithms automatically. The authors explain the tricks of locality-sensitive hashing and stream-processing algorithms for mining data that arrives too fast for exhaustive processing. Other chapters cover the PageRank idea and related tricks for organizing the Web, the problems of finding frequent itemsets, and clustering. This third edition includes new and extended coverage on decision trees, deep learning, and mining social-network graphs.},
	language = {en},
	urldate = {2020-07-15},
	publisher = {Cambridge University Press},
	author = {Leskovec, Jure and Rajaramand, Anand and Ullman, Jeffrey David},
	year = {2020},
	keywords = {textbook},
	file = {Mining of Massive Datasets:/Users/rca2t1/Dropbox/Zotero/storage/KBE256QS/www.mmds.org.html:text/html;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/963PPNMF/mining-massive-datasets-3rd-edition.html:text/html},
}

@book{huber_data_2012,
	title = {Data {Analysis}: {What} {Can} {Be} {Learned} {From} the {Past} 50 {Years}},
	isbn = {978-1-118-01826-2},
	shorttitle = {Data {Analysis}},
	abstract = {This book explores the many provocative questions concerning the fundamentals of data analysis. It is based on the time-tested experience of one of the gurus of the subject matter. Why should one study data analysis? How should it be taught? What techniques work best, and for whom? How valid are the results? How much data should be tested? Which machine languages should be used, if used at all? Emphasis on apprenticeship (through hands-on case studies) and anecdotes (through real-life applications) are the tools that Peter J. Huber uses in this volume. Concern with specific statistical techniques is not of immediate value; rather, questions of strategy – when to use which technique – are employed. Central to the discussion is an understanding of the significance of massive (or robust) data sets, the implementation of languages, and the use of models. Each is sprinkled with an ample number of examples and case studies. Personal practices, various pitfalls, and existing controversies are presented when applicable. The book serves as an excellent philosophical and historical companion to any present-day text in data analysis, robust statistics, data mining, statistical learning, or computational statistics.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Huber, Peter J.},
	month = jan,
	year = {2012},
	note = {Google-Books-ID: 6OSvDBE0rCIC},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@article{buja_conversation_2008,
	title = {A {Conversation} with {Peter} {Huber}},
	volume = {23},
	issn = {0883-4237},
	url = {http://arxiv.org/abs/0808.0777},
	doi = {10.1214/07-STS251},
	abstract = {Peter J. Huber was born on March 25, 1934, in Wohlen, a small town in the Swiss countryside. He obtained a diploma in mathematics in 1958 and a Ph.D. in mathematics in 1961, both from ETH Zurich. His thesis was in pure mathematics, but he then decided to go into statistics. He spent 1961--1963 as a postdoc at the statistics department in Berkeley where he wrote his first and most famous paper on robust statistics, ``Robust Estimation of a Location Parameter.'' After a position as a visiting professor at Cornell University, he became a full professor at ETH Zurich. He worked at ETH until 1978, interspersed by visiting positions at Cornell, Yale, Princeton and Harvard. After leaving ETH, he held professor positions at Harvard University 1978--1988, at MIT 1988--1992, and finally at the University of Bayreuth from 1992 until his retirement in 1999. He now lives in Klosters, a village in the Grisons in the Swiss Alps. Peter Huber has published four books and over 70 papers on statistics and data analysis. In addition, he has written more than a dozen papers and two books on Babylonian mathematics, astronomy and history. In 1972, he delivered the Wald lectures. He is a fellow of the IMS, of the American Association for the Advancement of Science, and of the American Academy of Arts and Sciences. In 1988 he received a Humboldt Award and in 1994 an honorary doctorate from the University of Neuch{\textbackslash}{\textasciicircum}\{a\}tel. In addition to his fundamental results in robust statistics, Peter Huber made important contributions to computational statistics, strategies in data analysis, and applications of statistics in fields such as crystallography, EEGs, and human growth curves.},
	number = {1},
	urldate = {2020-07-16},
	journal = {Statistical Science},
	author = {Buja, Andreas and Künsch, Hans R.},
	month = feb,
	year = {2008},
	note = {arXiv: 0808.0777},
	keywords = {Statistics - Methodology},
	pages = {120--135},
	annote = {Comment: Published in at http://dx.doi.org/10.1214/07-STS251 the Statistical Science (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/GK6DMPQ8/Buja and Künsch - 2008 - A Conversation with Peter Huber.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/XUSBBZDJ/0808.html:text/html},
}

@article{borne_revolution_2009,
	title = {The {Revolution} in {Astronomy} {Education}: {Data} {Science} for the {Masses}},
	shorttitle = {The {Revolution} in {Astronomy} {Education}},
	url = {http://arxiv.org/abs/0909.3895},
	abstract = {As our capacity to study ever-expanding domains of our science has increased (including the time domain, non-electromagnetic phenomena, magnetized plasmas, and numerous sky surveys in multiple wavebands with broad spatial coverage and unprecedented depths), so have the horizons of our understanding of the Universe been similarly expanding. This expansion is coupled to the exponential data deluge from multiple sky surveys, which have grown from gigabytes into terabytes during the past decade, and will grow from terabytes into Petabytes (even hundreds of Petabytes) in the next decade. With this increased vastness of information, there is a growing gap between our awareness of that information and our understanding of it. Training the next generation in the fine art of deriving intelligent understanding from data is needed for the success of sciences, communities, projects, agencies, businesses, and economies. This is true for both specialists (scientists) and non-specialists (everyone else: the public, educators and students, workforce). Specialists must learn and apply new data science research techniques in order to advance our understanding of the Universe. Non-specialists require information literacy skills as productive members of the 21st century workforce, integrating foundational skills for lifelong learning in a world increasingly dominated by data. We address the impact of the emerging discipline of data science on astronomy education within two contexts: formal education and lifelong learners.},
	urldate = {2020-07-16},
	journal = {arXiv:0909.3895 [astro-ph, physics:physics]},
	author = {Borne, Kirk D. and Jacoby, Suzanne and Carney, K. and Connolly, A. and Eastman, T. and Raddick, M. J. and Tyson, J. A. and Wallin, J.},
	month = sep,
	year = {2009},
	note = {arXiv: 0909.3895},
	keywords = {Computer Science - Digital Libraries, Computer Science - Information Retrieval, Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Databases, Physics - Physics Education},
	annote = {Impedance: "With this increased vastness of information, there is a growing gap between our awareness of that information and our understanding of it."},
	file = {arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/D26YNV7E/0909.html:text/html;Borne et al. - 2009 - The Revolution in Astronomy Education Data Scienc.pdf:/Users/rca2t1/Dropbox/Zotero/storage/44C8QS3Y/Borne et al. - 2009 - The Revolution in Astronomy Education Data Scienc.pdf:application/pdf},
}

@article{graham_art_2012,
	title = {The {Art} of {Data} {Science}},
	url = {http://arxiv.org/abs/1106.3305},
	doi = {10.1007/978-1-4614-3323-1_4},
	abstract = {To flourish in the new data-intensive environment of 21st century science, we need to evolve new skills. These can be expressed in terms of the systemized framework that formed the basis of mediaeval education - the trivium (logic, grammar, and rhetoric) and quadrivium (arithmetic, geometry, music, and astronomy). However, rather than focusing on number, data is the new keystone. We need to understand what rules it obeys, how it is symbolized and communicated and what its relationship to physical space and time is. In this paper, we will review this understanding in terms of the technologies and processes that it requires. We contend that, at least, an appreciation of all these aspects is crucial to enable us to extract scientific information and knowledge from the data sets which threaten to engulf and overwhelm us.},
	urldate = {2020-07-16},
	journal = {arXiv:1106.3305 [astro-ph]},
	author = {Graham, Matthew J.},
	year = {2012},
	note = {arXiv: 1106.3305},
	keywords = {Computer Science - Digital Libraries, Astrophysics - Instrumentation and Methods for Astrophysics},
	pages = {47--59},
	annote = {Comment: 12 pages, invited talk at Astrostatistics and Data Mining in Large Astronomical Databases workshop, La Palma, Spain, 30 May - 3 June 2011, to appear in Springer Series on Astrostatistics},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/C36CQRRR/Graham - 2012 - The Art of Data Science.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/XINY8YB9/1106.html:text/html},
}

@article{bergstra_informaticology_2012,
	title = {Informaticology: combining {Computer} {Science}, {Data} {Science}, and {Fiction} {Science}},
	shorttitle = {Informaticology},
	url = {http://arxiv.org/abs/1210.6636},
	abstract = {Motivated by an intention to remedy current complications with Dutch terminology concerning informatics, the term informaticology is positioned to denote an academic counterpart of informatics where informatics is conceived of as a container for a coherent family of practical disciplines ranging from computer engineering and software engineering to network technology, data center management, information technology, and information management in a broad sense. Informaticology escapes from the limitations of instrumental objectives and the perspective of usage that both restrict the scope of informatics. That is achieved by including fiction science in informaticology and by ranking fiction science on equal terms with computer science and data science, and framing (the study of) game design, evelopment, assessment and distribution, ranging from serious gaming to entertainment gaming, as a chapter of fiction science. A suggestion for the scope of fiction science is specified in some detail. In order to illustrate the coherence of informaticology thus conceived, a potential application of fiction to the ontology of instruction sequences and to software quality assessment is sketched, thereby highlighting a possible role of fiction (science) within informaticology but outside gaming.},
	urldate = {2020-07-16},
	journal = {arXiv:1210.6636 [cs]},
	author = {Bergstra, Jan A.},
	month = oct,
	year = {2012},
	note = {arXiv: 1210.6636},
	keywords = {Computer Science - Software Engineering},
	annote = {


"Data Science (DS). Grid, cloud, big data, data visualization, high speed networking, information systems, information theory, information management, information science, ontology (ontologies), anonymity (from the data perspective), machine learning, e-science." (p. 6)


},
	file = {arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WC8YJBGB/1210.html:text/html;Bergstra - 2012 - Informaticology combining Computer Science, Data .pdf:/Users/rca2t1/Dropbox/Zotero/storage/7DSGDEEQ/Bergstra - 2012 - Informaticology combining Computer Science, Data .pdf:application/pdf},
}

@article{parzen_lp_2013,
	title = {{LP} {Mixed} {Data} {Science} : {Outline} of {Theory}},
	shorttitle = {{LP} {Mixed} {Data} {Science}},
	url = {http://arxiv.org/abs/1311.0562},
	abstract = {This article presents the theoretical foundation of a new frontier of research-`LP Mixed Data Science'-that simultaneously extends and integrates the practice of traditional and novel statistical methods for nonparametric exploratory data modeling, and is applicable to the teaching and training of statistics. Statistics journals have great difficulty accepting papers unlike those previously published. For statisticians with new big ideas a practical strategy is to publish them in many small applied studies which enables one to provide references to work of others. This essay outlines the many concepts, new theory, and important algorithms of our new culture of statistical science called LP MIXED DATA SCIENCE. It provides comprehensive solutions to problems of data analysis and nonparametric modeling of many variables that are continuous or discrete, which does not yet have a large literature. It develops a new modeling approach to nonparametric estimation of the multivariate copula density. We discuss the theory which we believe is very elegant (and can provide a framework for United Statistical Algorithms, for traditional Small Data methods and Big Data methods).},
	urldate = {2020-07-16},
	journal = {arXiv:1311.0562 [math, stat]},
	author = {Parzen, Emanuel and Mukhopadhyay, Subhadeep},
	month = nov,
	year = {2013},
	note = {arXiv: 1311.0562},
	keywords = {Statistics - Methodology, Mathematics - Statistics Theory},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/KKBUQBLV/Parzen and Mukhopadhyay - 2013 - LP Mixed Data Science  Outline of Theory.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/PGU6DAD3/1311.html:text/html},
}

@article{horton_teaching_2014,
	title = {Teaching precursors to data science in introductory and second courses in statistics},
	url = {http://arxiv.org/abs/1401.3269},
	abstract = {Statistics students need to develop the capacity to make sense of the staggering amount of information collected in our increasingly data-centered world. Data science is an important part of modern statistics, but our introductory and second statistics courses often neglect this fact. This paper discusses ways to provide a practical foundation for students to learn to "compute with data" as defined by Nolan and Temple Lang (2010), as well as develop "data habits of mind" (Finzer, 2013). We describe how introductory and second courses can integrate two key precursors to data science: the use of reproducible analysis tools and access to large databases. By introducing students to commonplace tools for data management, visualization, and reproducible analysis in data science and applying these to real-world scenarios, we prepare them to think statistically in the era of big data.},
	urldate = {2020-07-16},
	journal = {arXiv:1401.3269 [cs, stat]},
	author = {Horton, Nicholas J. and Baumer, Benjamin S. and Wickham, Hadley},
	month = jan,
	year = {2014},
	note = {arXiv: 1401.3269},
	keywords = {Statistics - Computation, Computer Science - Computers and Society, 62-07, Statistics - Other Statistics},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/3IRG76BA/Horton et al. - 2014 - Teaching precursors to data science in introductor.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/R8QFBU8C/1401.html:text/html},
}

@article{davidian_arent_2013,
	title = {Aren't we data science?},
	issn = {0163-9617},
	url = {https://dialnet.unirioja.es/servlet/articulo?codigo=4331554},
	abstract = {Autoría: Marie Davidian.
Localización: AMSTAT news: the membership magazine of the American Statistical Association. Nº. 433, 2013.
Artículo de Revista en Dialnet.},
	language = {eng},
	number = {433},
	urldate = {2020-07-16},
	journal = {AMSTAT news: the membership magazine of the American Statistical Association},
	author = {Davidian, Marie},
	year = {2013},
	note = {Publisher: American Statistical Association
Section: AMSTAT news: the membership magazine of the American Statistical Association},
	pages = {3},
	file = {Davidian - 2013 - Aren't we data science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2AMMMS3K/Davidian - 2013 - Aren't we data science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RII6JX9U/articulo.html:text/html},
}

@misc{noauthor_membership_nodate,
	title = {Membership {Information}},
	url = {https://datascienceconsortium.org/membership-information/},
	abstract = {Membership Information Membership in the National Consortium for Data Science is open to organizations in the business, academic, government and nonprofit sectors. Becoming a member gives your organization opportunities to: Promote for a national strategy focusing on data science and the challenges of data science. Collaborate with other members to address key challenges that span …},
	language = {en-US},
	urldate = {2020-07-16},
	journal = {National Consortium for Data Science},
	note = {Library Catalog: datascienceconsortium.org},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/C7AIP97D/membership-information.html:text/html},
}

@article{muna_new_2014,
	title = {A {New} {Framework} for a {Model}-{Based} {Data} {Science} {Computational} {Platform}},
	url = {http://arxiv.org/abs/1402.5932},
	abstract = {Astronomy produces extremely large data sets from ground-based telescopes, space missions, and simulation. The volume and complexity of these rich data sets require new approaches and advanced tools to understand the information contained therein. No one can load this data on their own computer, most cannot even keep it at their institution, and worse, no platform exists that allows one to evaluate their models across the whole of the data. Simply having an extremely large volume of data available in one place is not sufficient; one must be able to make valid, rigorous, scientific comparisons across very different data sets from very different instrumentation. We propose a framework to directly address this which has the following components: a model-based computational platform, streamlined access to large volumes of data, and an educational and social platform for both researchers and the public.},
	urldate = {2020-07-16},
	journal = {arXiv:1402.5932 [astro-ph]},
	author = {Muna, Demitri and Huff, Eric},
	month = feb,
	year = {2014},
	note = {arXiv: 1402.5932},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	annote = {Comment: submitted to Astronomy and Computing},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/9TAPH2FG/Muna and Huff - 2014 - A New Framework for a Model-Based Data Science Com.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RCXRTE9K/1402.html:text/html},
}

@article{chawla_mechanism_2014,
	title = {Mechanism {Design} for {Data} {Science}},
	url = {http://arxiv.org/abs/1404.5971},
	abstract = {Good economic mechanisms depend on the preferences of participants in the mechanism. For example, the revenue-optimal auction for selling an item is parameterized by a reserve price, and the appropriate reserve price depends on how much the bidders are willing to pay. A mechanism designer can potentially learn about the participants' preferences by observing historical data from the mechanism; the designer could then update the mechanism in response to learned preferences to improve its performance. The challenge of such an approach is that the data corresponds to the actions of the participants and not their preferences. Preferences can potentially be inferred from actions but the degree of inference possible depends on the mechanism. In the optimal auction example, it is impossible to learn anything about preferences of bidders who are not willing to pay the reserve price. These bidders will not cast bids in the auction and, from historical bid data, the auctioneer could never learn that lowering the reserve price would give a higher revenue (even if it would). To address this impossibility, the auctioneer could sacrifice revenue optimality in the initial auction to obtain better inference properties so that the auction's parameters can be adapted to changing preferences in the future. This paper develops the theory for optimal mechanism design subject to good inferability.},
	urldate = {2020-07-16},
	journal = {arXiv:1404.5971 [cs]},
	author = {Chawla, Shuchi and Hartline, Jason and Nekipelov, Denis},
	month = jun,
	year = {2014},
	note = {arXiv: 1404.5971},
	keywords = {Computer Science - Computer Science and Game Theory, J.4},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/IJSWQS7T/Chawla et al. - 2014 - Mechanism Design for Data Science.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NFYHEFGT/1404.html:text/html},
}

@article{zhu_defining_2015,
	title = {Defining {Data} {Science}},
	url = {http://arxiv.org/abs/1501.05039},
	abstract = {Data science is gaining more and more and widespread attention, but no consensus viewpoint on what data science is has emerged. As a new science, its objects of study and scientific issues should not be covered by established sciences. Data in cyberspace have formed what we call datanature. In the present paper, data science is defined as the science of exploring datanature.},
	urldate = {2020-07-16},
	journal = {arXiv:1501.05039 [cs]},
	author = {Zhu, Yangyong and Xiong, Yun},
	month = jan,
	year = {2015},
	note = {arXiv: 1501.05039},
	keywords = {Computer Science - Computers and Society, Computer Science - Databases},
	annote = {"datanature"},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/6YYDM5XL/Zhu and Xiong - 2015 - Defining Data Science.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4L54NBVW/1501.html:text/html},
}

@article{horton_setting_2015,
	title = {Setting the {Stage} for {Data} {Science}: {Integration} of {Data} {Management} {Skills} in {Introductory} and {Second} {Courses} in {Statistics}},
	shorttitle = {Setting the {Stage} for {Data} {Science}},
	url = {http://arxiv.org/abs/1502.00318},
	abstract = {Many have argued that statistics students need additional facility to express statistical computations. By introducing students to commonplace tools for data management, visualization, and reproducible analysis in data science and applying these to real-world scenarios, we prepare them to think statistically. In an era of increasingly big data, it is imperative that students develop data-related capacities, beginning with the introductory course. We believe that the integration of these precursors to data science into our curricula-early and often-will help statisticians be part of the dialogue regarding "Big Data" and "Big Questions".},
	urldate = {2020-07-16},
	journal = {arXiv:1502.00318 [cs, stat]},
	author = {Horton, Nicholas J. and Baumer, Benjamin S. and Wickham, Hadley},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.00318},
	keywords = {Statistics - Computation, Computer Science - Computers and Society, Statistics - Other Statistics, 62-01},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/2ZX7N5EJ/Horton et al. - 2015 - Setting the stage for data science integration of.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CEWK73GD/1502.html:text/html},
}

@article{baumer_data_2015,
	title = {A {Data} {Science} {Course} for {Undergraduates}: {Thinking} with {Data}},
	shorttitle = {A {Data} {Science} {Course} for {Undergraduates}},
	url = {http://arxiv.org/abs/1503.05570},
	abstract = {Data science is an emerging interdisciplinary field that combines elements of mathematics, statistics, computer science, and knowledge in a particular application domain for the purpose of extracting meaningful information from the increasingly sophisticated array of data available in many settings. These data tend to be non-traditional, in the sense that they are often live, large, complex, and/or messy. A first course in statistics at the undergraduate level typically introduces students with a variety of techniques to analyze small, neat, and clean data sets. However, whether they pursue more formal training in statistics or not, many of these students will end up working with data that is considerably more complex, and will need facility with statistical computing techniques. More importantly, these students require a framework for thinking structurally about data. We describe an undergraduate course in a liberal arts environment that provides students with the tools necessary to apply data science. The course emphasizes modern, practical, and useful skills that cover the full data analysis spectrum, from asking an interesting question to acquiring, managing, manipulating, processing, querying, analyzing, and visualizing data, as well communicating findings in written, graphical, and oral forms.},
	urldate = {2020-07-16},
	journal = {arXiv:1503.05570 [cs, stat]},
	author = {Baumer, Ben},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.05570},
	keywords = {Statistics - Computation, Computer Science - Computers and Society, Statistics - Other Statistics, 62-01},
	annote = {Comment: 21 pages total including supplementary materials},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/BAB9N8WC/Baumer - 2015 - A Data Science Course for Undergraduates Thinking.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JRA9HK5R/1503.html:text/html},
}

@article{osman_data_2015,
	title = {Data {Science} as a {New} {Frontier} for {Design}},
	url = {http://arxiv.org/abs/1503.06201},
	abstract = {The purpose of this paper is to contribute to the challenge of transferring know-how, theories and methods from design research to the design processes in information science and technologies. More specifically, we shall consider a domain, namely data-science, that is becoming rapidly a globally invested research and development axis with strong imperatives for innovation given the data deluge we are currently facing. We argue that, in order to rise to the data-related challenges that the society is facing, data-science initiatives should ensure a renewal of traditional research methodologies that are still largely based on trial-error processes depending on the talent and insights of a single (or a restricted group of) researchers. It is our claim that design theories and methods can provide, at least to some extent, the much-needed framework. We will use a worldwide data-science challenge organized to study a technical problem in physics, namely the detection of Higgs boson, as a use case to demonstrate some of the ways in which design theory and methods can help in analyzing and shaping the innovation dynamics in such projects.},
	urldate = {2020-07-16},
	journal = {arXiv:1503.06201 [cs, stat]},
	author = {Osman, Akin and Mines, Kazakçi},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.06201},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Other Statistics},
	annote = {Comment: International Conference on Engineering Design, Jul 2015, Milan, Italy},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/ZCDLEXBY/Osman and Mines - 2015 - Data Science as a New Frontier for Design.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/SV6ZDIN5/1503.html:text/html},
}

@article{situngkir_indonesia_2015,
	title = {Indonesia embraces the {Data} {Science}},
	url = {http://arxiv.org/abs/1508.02387},
	abstract = {The information era is the time when information is not only largely generated, but also vastly processed in order to extract and generated more information. The complex nature of modern living is represented by the various kind of data. Data can be in the forms of signals, images, texts, or manifolds resembling the horizon of observation. The task of the emerging data sciences are to extract information from the data, for people gain new insights of the complex world. The insights may came from the new way of the data representation, be it a visualizations, mapping, or other. The insights may also come from the implementation of mathematical analysis and or computational processing giving new insights of what the states of the nature represented by the data. Both ways implement the methodologies reducing the dimensionality of the data. The relations between the two functions, representation and analysis are the heart of how information in data is transformed mathematically and computationally into new information. The paper discusses some practices, along with various data coming from the social life in Indonesia to gain new insights about Indonesia in the emerging data sciences. The data sciences in Indonesia has made Indonesian Data Cartograms, Indonesian Celebrity Sentiment Mapping, Ethno-Clustering Maps, social media community detection, and a lot more to come, become possible. All of these are depicted as the exemplifications on how Data Science has become integral part of the technology bringing data closer to people.},
	urldate = {2020-07-16},
	journal = {arXiv:1508.02387 [cs]},
	author = {Situngkir, Hokky},
	month = aug,
	year = {2015},
	note = {arXiv: 1508.02387},
	keywords = {Computer Science - Computers and Society},
	annote = {"The relations between the two functions, representation and analysis are the heart of how information in data is transformed mathematically and computationally into new information."
Comment: Paper presented in South East Asian Mathematical Society (SEAMS) 7th Conference, 10 pages, 7 figures},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/U4PPQED8/Situngkir - 2015 - Indonesia embraces the Data Science.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/H65YZHFY/1508.html:text/html},
}

@article{kearns_proposed_1971,
	title = {Proposed {SEC} {Rules} for {Private} {Offerings}: {The} {Impact} on {Venture} {Capital} {Financing} {Note}},
	volume = {5},
	shorttitle = {Proposed {SEC} {Rules} for {Private} {Offerings}},
	url = {https://heinonline.org/HOL/P?h=hein.journals/umijlr5&i=131},
	language = {eng},
	number = {1},
	urldate = {2020-07-16},
	journal = {University of Michigan Journal of Law Reform},
	author = {Kearns, Gregory A.},
	year = {1971},
	pages = {122--144},
	annote = {Data Science Ventures},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/65RN9KDL/Kearns - 1971 - Proposed SEC Rules for Private Offerings The Impa.pdf:application/pdf},
}

@book{young_forbes_1998,
	title = {Forbes {Greatest} {Technology} {Stories}: {Inspiring} {Tales} of the {Entrepreneurs} and {Inventors} {Who} {Revolutionized} {Modern} {Business}},
	isbn = {978-0-471-24374-8},
	shorttitle = {Forbes {Greatest} {Technology} {Stories}},
	abstract = {Here is the fascinating story of the making of the high-tech business revolution and the birth of the Digital Age. Journalist Jeffrey Young chronicles six decades of unbridled technological innovation, taking you inside today's business empires and introducing you to the dreamers, the schemers, the entrepreneurs, and the inventors who built them, including: * Millionaire-playboy turned visionary-CEO Thomas Watson, Jr.-how he helped pioneer the business computing industry in the early 1950s and made IBM its undisputed master for the next three decades *  Fast-talking hippie-entrepreneur Steve Jobs and engineering genius Steve Wozniak-how they went from penniless "wireheads" to high-tech multimillionaires overnight *  Bill Gates-whose talent for turning other people's creative innovations into his own marketplace success was at the heart of Microsoft's brilliant strategy-a tactic Gates perfected at a very tender age *  How a handful of visionaries turned a Cold War communications system into the global phenomenon called the Internet  Packed with all the excitement of scientific discovery and nail-biting suspense of entrepreneurial brinksmanship, Forbes Greatest Technology Stories is must reading for every business professional.  Forbes (r) is a registered trademark of Forbes Inc. Its use is pursuant to a license agreement with forbes Inc.},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Young, Jeffrey S. and Facs, MD, Jeffrey S. Young and Staff, Inc, Forbes},
	month = sep,
	year = {1998},
	note = {Google-Books-ID: zeKnJilSyx8C},
	keywords = {Business \& Economics / Management, Business \& Economics / Entrepreneurship, Business \& Economics / Industries / General, Business \& Economics / Skills},
	annote = {Reference to Data Science Ventures
 },
}

@misc{mort_collins_ventures_bio_nodate,
	title = {Bio},
	url = {http://www.mcollinsventures.com/bio/},
	language = {en-US},
	urldate = {2020-07-16},
	journal = {MCollins Ventures},
	author = {{Mort Collins Ventures}},
	note = {Library Catalog: www.mcollinsventures.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/R4X3E8L7/bio.html:text/html},
}

@article{kettenring_birth_1997,
	title = {The birth, life, and death of statistical department. {President}'s {Corner}},
	volume = {245},
	url = {https://ci.nii.ac.jp/naid/10010480745/},
	urldate = {2020-07-16},
	journal = {AMSTAT NEWS},
	author = {Kettenring, Jon R.},
	year = {1997},
	note = {Publisher: Amer. Statist. Assoc.},
	pages = {9--10},
	file = {The birth, life, and death of statistical department. President's Corner Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/LRNVDT5S/10010480745.html:text/html},
}

@inproceedings{schutt_doing_2013,
	title = {Doing {Data} {Science}: {Straight} {Talk} from the {Frontline}},
	shorttitle = {Doing {Data} {Science}},
	abstract = {Now that people are aware that data can make the difference in an election or a business model, data science as an occupation is gaining ground. But how can you get started working in a wide-ranging, interdisciplinary field thats so clouded in hype? This insightful book, based on Columbia Universitys Introduction to Data Science class, tells you what you need to know. In many of these chapter-long lectures, data scientists from companies such as Google, Microsoft, and eBay share new algorithms, methods, and models by presenting case studies and the code they use. If youre familiar with linear algebra, probability, and statistics, and have programming experience, this book is an ideal introduction to data science. Topics include:Statistical inference, exploratory data analysis, and the data science process Algorithms Spam filters, Naive Bayes, and data wrangling Logistic regression Financial modeling Recommendation engines and causality Data visualization Social networks and data journalism Data engineering, MapReduce, Pregel, and Hadoop Doing Data Science is collaboration between course instructor Rachel Schutt, Senior VP of Data Science at News Corp, and data science consultant Cathy ONeil, a senior data scientist at Johnson Research Labs, who attended and blogged about the course.},
	author = {Schutt, Rachel and O'Neil, Cathy},
	year = {2013},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/UVQIQQHE/Schutt and O'Neil - 2013 - Doing Data Science Straight Talk from the Frontli.pdf:application/pdf},
}

@book{blum_foundations_2020,
	address = {Cambridge},
	title = {Foundations of {Data} {Science}},
	isbn = {978-1-108-48506-7},
	url = {https://www.cambridge.org/core/books/foundations-of-data-science/6A43CE830DE83BED6CC5171E62B0AA9E},
	abstract = {This book provides an introduction to the mathematical and algorithmic foundations of data science, including machine learning, high-dimensional geometry, and analysis of large networks. Topics include the counterintuitive nature of data in high dimensions, important linear algebraic techniques such as singular value decomposition, the theory of random walks and Markov chains, the fundamentals of and important algorithms for machine learning, algorithms and analysis for clustering, probabilistic models for large networks, representation learning including topic modelling and non-negative matrix factorization, wavelets and compressed sensing. Important probabilistic techniques are developed including the law of large numbers, tail inequalities, analysis of random projections, generalization guarantees in machine learning, and moment methods for analysis of phase transitions in large random graphs. Additionally, important structural and complexity measures are discussed such as matrix norms and VC-dimension. This book is suitable for both undergraduate and graduate courses in the design and analysis of algorithms for data.},
	urldate = {2020-07-17},
	publisher = {Cambridge University Press},
	author = {Blum, Avrim and Hopcroft, John and Kannan, Ravindran},
	year = {2020},
	doi = {10.1017/9781108755528},
	annote = {


"While traditional areas of computer science remain highly important, increasingly re- searchers of the future will be involved with using computers to understand and extract usable information from massive data arising in applications, not just how to make com- puters useful on specific well-defined problems."


},
	file = {Blum et al. - 2020 - Foundations of Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HEM3BHV6/Blum et al. - 2020 - Foundations of Data Science.pdf:application/pdf;Blum et al. - 2020 - Foundations of Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2IPTVQIJ/Blum et al. - 2019 - Foundations of Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Z85WB8W7/6A43CE830DE83BED6CC5171E62B0AA9E.html:text/html},
}

@incollection{hayashi_evaluation_2000,
	address = {Berlin},
	title = {Evaluation of {Data} {Quality} and {Data} {Analysis}},
	isbn = {978-3-540-67521-1},
	abstract = {The practical evaluation of data quality is discussed. Such evaluations are essential if we intend to carry out useful data analyses. Here we treat this problem in the context of cross-societal (comparative social) surveys.},
	language = {English},
	booktitle = {Data {Analysis}, {Classification}, and {Related} {Methods}},
	publisher = {Springer-Verlag Berlin},
	author = {Hayashi, C.},
	editor = {Kiers, H. a. L. and Rasson, J. P. and Gronen, P. J. F. and Schader, M.},
	year = {2000},
	note = {ISSN: 1431-8814
WOS:000166471700053},
	pages = {335--340},
}

@book{hayashi_questionnaire_2002,
	address = {Tokyo},
	title = {Questionnaire {Construction}, {Data} {Collection} and {Data} {Analysis}: {An} {Approach} by the {Idea} of {Data} {Science}},
	isbn = {978-4-431-70338-9},
	shorttitle = {Questionnaire {Construction}, {Data} {Collection} and {Data} {Analysis}},
	abstract = {Data design, data collection and data quality evaluation are crucial to data analysis if we are to draw out useful relevant information. Analysis of low-information data never bears fruit; however, data analytic methods can be refined. In spite of the importance of this issue in actual data mining and data analysis, I am forced to ask why these problems cannot be discussed at its most essential level. Perhaps it is a matter of the laborious practical work involved or the otherwise plodding pace of research. Indeed, these problems are rarely addressed because in academic circles it is regarded as unsophisticated. In the present paper, I dare to take up these problems, regarding it as one very important to data science.},
	language = {English},
	publisher = {Springer-Verlag Tokyo},
	author = {Hayashi, C.},
	editor = {Nishisato, S. and Babe, Y. and Bozdogan, H. and Kanefuji, K.},
	year = {2002},
	note = {Pages: 13-24
Publication Title: Measurement and Multivariate Analysis
WOS:000175725900002},
}

@incollection{hennig_how_2003,
	address = {Berlin},
	title = {How {Wrong} {Models} {Become} {Useful} - and {Correct} {Models} {Become} {Dangerous}},
	isbn = {978-3-540-40354-8},
	abstract = {The conceptual background of statistics and data analysis is considered from the viewpoint of constructivist philosophy. The relation of formal models to observable reality is discussed as well as the role of model assumptions and especially probability models in data analysis. I argue that approximate correctness of models is an ill-posed problem. The relation of model assumptions to observer-independent reality can never be assessed objectively. Instead, formal models axe useful to learn about the derived statistical methods and to enable clear understanding between different observers. Some illustrations axe given.},
	language = {English},
	booktitle = {Between {Data} {Science} and {Applied} {Data} {Analysis}},
	publisher = {Springer-Verlag Berlin},
	author = {Hennig, C.},
	editor = {Schader, M. and Gaul, W. and Vichi, M.},
	year = {2003},
	note = {ISSN: 1431-8814
WOS:000185702600027},
	pages = {235--243},
	file = {Hennig - 2003 - How Wrong Models Become Useful - and Correct Model.pdf:/Users/rca2t1/Dropbox/Zotero/storage/FJ8JABSZ/Hennig - 2003 - How Wrong Models Become Useful - and Correct Model.pdf:application/pdf},
}

@misc{noauthor_data_nodate-3,
	title = {Data {Science} and {Advanced} {Analytics}},
	url = {https://www.dsaa.co/},
	abstract = {Data Science and Advanced Analytics},
	urldate = {2020-07-17},
	journal = {Data Science and Advanced Analytics},
	note = {Library Catalog: dsaa.co},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/XX9864LT/dsaa.co.html:text/html},
}

@article{mcnamara_greater_2017,
	title = {Greater {Data} {Science} at {Baccalaureate} {Institutions}},
	url = {http://arxiv.org/abs/1710.08728},
	abstract = {Donoho's JCGS (in press) paper is a spirited call to action for statisticians, who he points out are losing ground in the field of data science by refusing to accept that data science is its own domain. (Or, at least, a domain that is becoming distinctly defined.) He calls on writings by John Tukey, Bill Cleveland, and Leo Breiman, among others, to remind us that statisticians have been dealing with data science for years, and encourages acceptance of the direction of the field while also ensuring that statistics is tightly integrated. As faculty at baccalaureate institutions (where the growth of undergraduate statistics programs has been dramatic), we are keen to ensure statistics has a place in data science and data science education. In his paper, Donoho is primarily focused on graduate education. At our undergraduate institutions, we are considering many of the same questions.},
	urldate = {2020-07-17},
	journal = {arXiv:1710.08728 [stat]},
	author = {McNamara, Amelia and Horton, Nicholas J. and Baumer, Benjamin S.},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.08728},
	keywords = {Statistics - Machine Learning, Statistics - Other Statistics},
	annote = {Comment: in press response to Donoho paper in Journal of Computational Graphics and Statistics},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/TSFFH7QI/McNamara et al. - 2017 - Greater data science at baccalaureate institutions.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ZZEJPAGB/1710.html:text/html},
}

@article{hardin_data_2015,
	title = {Data {Science} in {Statistics} {Curricula}: {Preparing} {Students} to "{Think} with {Data}"},
	shorttitle = {Data {Science} in {Statistics} {Curricula}},
	url = {http://arxiv.org/abs/1410.3127},
	abstract = {A growing number of students are completing undergraduate degrees in statistics and entering the workforce as data analysts. In these positions, they are expected to understand how to utilize databases and other data warehouses, scrape data from Internet sources, program solutions to complex problems in multiple languages, and think algorithmically as well as statistically. These data science topics have not traditionally been a major component of undergraduate programs in statistics. Consequently, a curricular shift is needed to address additional learning outcomes. The goal of this paper is to motivate the importance of data science proficiency and to provide examples and resources for instructors to implement data science in their own statistics curricula. We provide case studies from seven institutions. These varied approaches to teaching data science demonstrate curricular innovations to address new needs. Also included here are examples of assignments designed for courses that foster engagement of undergraduates with data and data science.},
	urldate = {2020-07-18},
	journal = {arXiv:1410.3127 [stat]},
	author = {Hardin, Johanna and Hoerl, Roger and Horton, Nicholas J. and Nolan, Deborah},
	month = aug,
	year = {2015},
	note = {arXiv: 1410.3127},
	keywords = {Statistics - Other Statistics},
	file = {arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Z4Z4IFVL/1410.html:text/html;Hardin et al. - 2015 - Data Science in Statistics Curricula Preparing St.pdf:/Users/rca2t1/Dropbox/Zotero/storage/VVXPZY3N/Hardin et al. - 2015 - Data Science in Statistics Curricula Preparing St.pdf:application/pdf},
}

@techreport{johnzstone_data_2014,
	title = {Data {Science} at {NSF}: {Report} of {StatSNSF} commi3ee: {Revisions} {Since} {January} {MPSAC}},
	author = {Johnzstone, Iain and Roberts, Fred},
	month = apr,
	year = {2014},
	annote = {



“Data Science: the science of planning for, acquisition, management, analysis of, and inference from data” 



},
	file = {Johnzstone and Roberts - 2014 - Data Science at NSF Report of StatSNSF commi3ee .pdf:/Users/rca2t1/Dropbox/Zotero/storage/QMQV5XWE/Johnzstone and Roberts - 2014 - Data Science at NSF Report of StatSNSF commi3ee .pdf:application/pdf},
}

@article{saltz_predicting_2017,
	title = {Predicting {Data} {Science} {Sociotechnical} {Execution} {Challenges} by {Categorizing} {Data} {Science} {Projects}},
	volume = {68},
	issn = {2330-1635},
	doi = {10.1002/asi.23873},
	abstract = {The challenge in executing a data science project is more than just identifying the best algorithm and tool set to use. Additional sociotechnical challenges include items such as how to define the project goals and how to ensure the project is effectively managed. This paper reports on a set of case studies where researchers were embedded within data science teams and where the researcher observations and analysis was focused on the attributes that can help describe data science projects and the challenges faced by the teams executing these projects, as opposed to the algorithms and technologies that were used to perform the analytics. Based on our case studies, we identified 14 characteristics that can help describe a data science project. We then used these characteristics to create a model that defines two key dimensions of the project. Finally, by clustering the projects within these two dimensions, we identified four types of data science projects, and based on the type of project, we identified some of the sociotechnical challenges that project teams should expect to encounter when executing data science projects.},
	language = {English},
	number = {12},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Saltz, Jeffrey and Shamshurin, Ivan and Connors, Colin},
	month = dec,
	year = {2017},
	note = {Place: Hoboken
Publisher: Wiley
WOS:000414718000003},
	keywords = {big data},
	pages = {2720--2728},
	file = {Saltz et al. - 2017 - Predicting Data Science Sociotechnical Execution C.pdf:/Users/rca2t1/Dropbox/Zotero/storage/T4H63JQP/Saltz et al. - 2017 - Predicting Data Science Sociotechnical Execution C.pdf:application/pdf},
}

@inproceedings{saltz_exploring_2015,
	title = {Exploring the process of doing data science via an ethnographic study of a media advertising company},
	doi = {10.1109/BigData.2015.7363992},
	abstract = {This paper presents the results of an ethnographic study focused on how data science projects were conducted within a global media advertising company. Observations, via embedding a researcher within the team, as well as more structured interviews and surveys, are documented. Recommendations to improve the current data science methodology within the company are also discussed. Overall, there had been little focus on the team's process methodology and the suggested process improvements would result in the company's data science projects having less risk and shorter timelines. Other big data teams might also benefit from reviewing and refining their work processes, but more work needs to be done to validate this assumption.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Saltz, Jeffrey S. and Shamshurin, Ivan},
	month = oct,
	year = {2015},
	keywords = {Software, advertising, Context, Big data, Big Data, Big Data teams, Companies, company data science projects, Data Science, ethnographic study, global media advertising company, media advertising company, process improvements, Process Methodology, team process methodology},
	pages = {2098--2105},
	file = {IEEE Xplore Abstract Record:/Users/rca2t1/Dropbox/Zotero/storage/4UXZP9HW/7363992.html:text/html;IEEE Xplore Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/IIRAUHNY/Saltz and Shamshurin - 2015 - Exploring the process of doing data science via an.pdf:application/pdf},
}

@inproceedings{gil_semantic_2015,
	address = {Berlin, Heidelberg},
	title = {A {Semantic}, {Task}-{Centered} {Collaborative} {Framework} for {Science}},
	isbn = {978-3-319-25638-2},
	url = {https://doi.org/10.1007/978-3-319-25639-9_11},
	doi = {10.1007/978-3-319-25639-9_11},
	abstract = {This paper gives an overview of the Organic Data Science framework, a new approach for scientific collaboration that opens the science process and exposes information about shared tasks, participants, and other relevant entities. The framework enables scientists to formulate new tasks and contribute to tasks posed by others. The framework is currently in use by a science community studying the age of water, and is beginning to be used by others.},
	urldate = {2020-07-18},
	booktitle = {Revised {Selected} {Papers} of the {ESWC} 2015 {Satellite} {Events} on {The} {Semantic} {Web}: {ESWC} 2015 {Satellite} {Events} - {Volume} 9341},
	publisher = {Springer-Verlag},
	author = {Gil, Yolanda and Michel, Felix and Ratnakar, Varun and Hauder, Matheus},
	month = may,
	year = {2015},
	keywords = {Collaborative web platforms, Organic data science, Semantic wiki},
	pages = {58--61},
	file = {Gil et al. - 2015 - A Semantic, Task-Centered Collaborative Framework .pdf:/Users/rca2t1/Dropbox/Zotero/storage/DB9QR4JT/Gil et al. - 2015 - A Semantic, Task-Centered Collaborative Framework .pdf:application/pdf},
}

@inproceedings{saltz_framework_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Business} {Information} {Processing}},
	title = {A {Framework} for {Describing} {Big} {Data} {Projects}},
	isbn = {978-3-319-52464-1},
	doi = {10.1007/978-3-319-52464-1_17},
	abstract = {With the ability to collect, store and analyze an ever-growing diversity of data generated with ever-increasing frequency, Big Data is a rapidly growing field. While tremendous strides have been made in the algorithms and technologies that are used to perform the analytics, much less has been done to determine how the team should work together to do a Big Data project. Our research reports on a set of case studies, where researchers were embedded within Big Data teams. Since project methodologies will likely depend on the attributes of a Big Data effort, we focus our analysis on defining a framework to describe a Big Data project. We then use this framework to describe the organizations we studied and some of the socio-technical challenges linked to these newly defined project characteristics.},
	language = {en},
	booktitle = {Business {Information} {Systems} {Workshops}},
	publisher = {Springer International Publishing},
	author = {Saltz, Jeffrey and Shamshurin, Ivan and Connors, Colin},
	editor = {Abramowicz, Witold and Alt, Rainer and Franczyk, Bogdan},
	year = {2017},
	keywords = {Data science, Big data, Process methodology, Project management},
	pages = {183--195},
}

@misc{noauthor_data_nodate-4,
	title = {Data {Sciences}},
	url = {http://203.170.84.89/~idawis33/datasciences/?page_id=2112&&category=Foundations&category=Foundations&&paged=8},
	urldate = {2020-07-18},
	journal = {DataSciences.org},
	file = {Data Sciences:/Users/rca2t1/Dropbox/Zotero/storage/SZ77THWB/datasciences.html:text/html},
}

@misc{noauthor_francis_nodate,
	title = {{FRANCIS} {J} {SMITH} {OBE} {MRIA}},
	url = {http://www.cs.qub.ac.uk/~FJ.Smith/SmithCV.htm},
	urldate = {2020-07-18},
	file = {FRANCIS J SMITH OBE MRIA:/Users/rca2t1/Dropbox/Zotero/storage/9BBNVMKJ/SmithCV.html:text/html},
}

@misc{noauthor_4_nodate,
	title = {(4) ({PDF}) {Zipf} and {Type}-{Token} rules for the {English}, {Spanish}, {Irish} and {Latin} languages},
	url = {https://www.researchgate.net/publication/228794781_Zipf_and_Type-Token_rules_for_the_English_Spanish_Irish_and_Latin_languages},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2020-07-18},
	journal = {ResearchGate},
	note = {Library Catalog: www.researchgate.net},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/FKV9B8II/228794781_Zipf_and_Type-Token_rules_for_the_English_Spanish_Irish_and_Latin_languages.html:text/html},
}

@article{oneill_polynomial_1969,
	title = {Polynomial {Curve} {Fitting} {When} {Abscissas} and {Ordinates} are both {Subject} to {Error}},
	volume = {12},
	doi = {10.1093/comjnl/12.1.52},
	number = {1},
	journal = {Comput. J.},
	author = {O'Neill, M. and Sinclair, I. G. and Smith, Francis Jack},
	year = {1969},
	pages = {52--56},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/2ANVI7QX/O'Neill et al. - 1969 - Polynomial Curve Fitting When Abscissas and Ordina.pdf:application/pdf},
}

@article{ohara_evaluation_1969,
	title = {The evaluation of definite integrals by interval subdivision},
	volume = {12},
	doi = {10.1093/comjnl/12.2.179},
	number = {2},
	journal = {Comput. J.},
	author = {O'Hara, H. and Smith, Francis Jack},
	year = {1969},
	pages = {179--182},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/BRAFTXQS/O'Hara and Smith - 1969 - The evaluation of definite integrals by interval s.pdf:application/pdf},
}

@article{ohara_error_1968,
	title = {Error {Estimation} in the {Clenshaw}-{Curtis} {Quadrature} {Formula}},
	volume = {11},
	doi = {10.1093/comjnl/11.2.213},
	number = {2},
	journal = {Comput. J.},
	author = {O'Hara, H. and Smith, Francis Jack},
	year = {1968},
	pages = {213--219},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/686GKYWV/O'Hara and Smith - 1968 - Error Estimation in the Clenshaw-Curtis Quadrature.pdf:application/pdf},
}

@article{bell_petascale_2007,
	title = {Petascale {Computational} {Systems}},
	url = {http://arxiv.org/abs/cs/0701165},
	abstract = {Computational science is changing to be data intensive. Super-Computers must be balanced systems; not just CPU farms but also petascale IO and networking arrays. Anyone building CyberInfrastructure should allocate resources to support a balanced Tier-1 through Tier-3 design.},
	urldate = {2020-07-19},
	journal = {arXiv:cs/0701165},
	author = {Bell, Gordon and Gray, Jim and Szalay, Alex},
	month = jan,
	year = {2007},
	note = {arXiv: cs/0701165},
	keywords = {Computer Science - Databases, Computer Science - Hardware Architecture},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/GK2EE4EB/Bell et al. - 2007 - Petascale Computational Systems.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RLKE85G4/0701165.html:text/html},
}

@book{shapiro_towards_2006,
	title = {Towards 2020 {Science}},
	url = {https://www.microsoft.com/en-us/research/publication/towards-2020-science-2/},
	abstract = {The Centre for Technology Management joined 'Towards 2020 Science', an international expert group of distinguished scientists, to facilitate a workshop that was held to debate and consider the role and future of science over the next 14 years. The expert group met for an intense three day workshop, held in Venice during the summer of 2005, to support the development of a new vision and roadmap outlining the evolution, challenges and potential of computational science in the next decade and beyond. The aim behind the workshop was to stimulate debate across and within disciplines; focus the research agenda for computational science, and encourage collaboration between academia, industry and government. The findings and conclusions from this workshop and a further four months of analysis, discussion and debate within the group has been published in and the form of a roadmap that shows a vision of science towards 2020 and the role that computer science can and will play in achieving this vision.},
	publisher = {Microsoft},
	author = {Shapiro, Ehud and Rison, Stuart and Phillips, Andrew and Herbert, Andrew and Editors and Emmott, Stephen},
	month = mar,
	year = {2006},
}

@article{lyon_dealing_2007,
	title = {Dealing with {Data}: {Roles}, {Rights}, {Responsibilities} and {Relationships}. {Consultancy} {Report}.},
	shorttitle = {Dealing with {Data}},
	url = {https://researchportal.bath.ac.uk/en/publications/dealing-with-data-roles-rights-responsibilities-and-relationships},
	language = {English},
	urldate = {2020-07-19},
	author = {Lyon, L.},
	month = jun,
	year = {2007},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/SX8HDFYD/Lyon - 2007 - Dealing with Data Roles, Rights, Responsibilities.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/8RIGLVVT/dealing-with-data-roles-rights-responsibilities-and-relationships.html:text/html},
}

@book{noauthor_nasa_1962,
	title = {{NASA} {SP}.},
	language = {en},
	publisher = {Scientific and Technical Information Office, National Aeronautics and Space Administration},
	year = {1962},
}

@book{administration_nasa_1961,
	title = {{NASA} {EP}.},
	language = {en},
	publisher = {National Aeronautics and Space Administration.},
	author = {Administration, United States National Aeronautics {and} Space},
	year = {1961},
	note = {Google-Books-ID: 3s0fAAAAIAAJ},
}

@book{control_conference_1964,
	title = {Conference {Papers}},
	abstract = {1949 "Abstracts of papers, third annual convention in conjunction with the third New England Quality Control Conference."},
	language = {en},
	author = {Control, American Society for Quality},
	year = {1964},
	note = {Google-Books-ID: BzyaAAAAIAAJ},
}

@book{noauthor_industrial_1962,
	title = {Industrial {Research}},
	language = {en},
	publisher = {Magazine Division, Dun-Donnelley Publishing Company},
	year = {1962},
	note = {Google-Books-ID: Wyi4lGNMBXUC},
}

@book{noauthor_electronic_1961,
	title = {Electronic {Age}: {Research}, {Manufacturing}, {Communications}, {Broadcasting}, {Television}},
	shorttitle = {Electronic {Age}},
	language = {en},
	publisher = {Radio Corporation of America.},
	year = {1961},
	note = {Google-Books-ID: cHc1AQAAIAAJ},
	annote = {"Data Deluge from Space"},
}

@book{noauthor_sci-tech_1963,
	title = {Sci-tech {News}},
	language = {en},
	publisher = {Sci-Tech News},
	year = {1963},
	note = {Google-Books-ID: MVfpAAAAMAAJ},
}

@article{anderson_end_2008,
	title = {The {End} of {Theory}: {The} {Data} {Deluge} {Makes} the {Scientific} {Method} {Obsolete}},
	issn = {1059-1028},
	shorttitle = {The {End} of {Theory}},
	url = {https://www.wired.com/2008/06/pb-theory/},
	abstract = {Illustration: Marian Bantjes “All models are wrong, but some are useful.” So proclaimed statistician George Box 30 years ago, and he was right. But what choice did we have? Only models, from cosmological equations to theories of human behavior, seemed to be able to consistently, if imperfectly, explain the world around us. Until now. Today companies {\textbackslash}[…{\textbackslash}]},
	urldate = {2020-07-19},
	journal = {Wired},
	author = {Anderson, Chris},
	month = jun,
	year = {2008},
	keywords = {Discoveries, magazine-16.07},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RAEKLBPE/pb-theory.html:text/html},
}

@book{noauthor_proceedings_1965,
	title = {Proceedings of 1st {Ad}-{Hoc} {Forum} of {Scientific} and {Technical} {Information} {Analysis} {Center} {Managers}, {Directors}, and {Professional} {Analysts}, {Held} at {Battelle} {Memorial} {Institute}, {Columbus}, {Ohio}, {November} 9-11, 1965},
	language = {en},
	publisher = {U.S. Atomic Energy Commission, Division of Technical Information},
	year = {1965},
	note = {Google-Books-ID: nNG\_8YFInMYC},
}

@book{operations_interagency_1963,
	title = {Interagency {Coordination} of {Information}: {Hearings} ... 87-2},
	shorttitle = {Interagency {Coordination} of {Information}},
	language = {en},
	author = {Operations, United States Congress Senate Government},
	year = {1963},
	note = {Google-Books-ID: RcZMjATSyiMC},
}

@book{noauthor_scientific_1963,
	title = {Scientific {Information} {Notes}},
	language = {en},
	publisher = {National Science Foundation.},
	month = apr,
	year = {1963},
	note = {Google-Books-ID: GSprMTzzax8C},
}

@book{state_department_1962,
	title = {Department of {State} {News} {Letter}},
	language = {en},
	publisher = {Bureau of Administration},
	author = {State, United States Department of},
	year = {1962},
	note = {Google-Books-ID: cNJIAQAAMAAJ},
}

@book{henderson_cooperation_1966,
	title = {Cooperation, {Convertibility}, and {Compatibility} {Among} {Information} {Systems}: {A} {Literature} {Review}},
	shorttitle = {Cooperation, {Convertibility}, and {Compatibility} {Among} {Information} {Systems}},
	language = {en},
	publisher = {U.S. Department of Commerce, National Bureau of Standards},
	author = {Henderson, Madeline M.},
	year = {1966},
	note = {Google-Books-ID: h62fMnaMx6YC},
}

@book{noauthor_report_1964,
	title = {Report},
	language = {en},
	year = {1964},
	note = {Google-Books-ID: T9SjJtvL1jUC},
}

@book{noauthor_advances_1962,
	title = {Advances in {Computers}},
	isbn = {978-0-08-056635-1},
	abstract = {Advances in Computers},
	language = {en},
	publisher = {Academic Press},
	month = jan,
	year = {1962},
	note = {Google-Books-ID: leYlwtgF0xsC},
	keywords = {Computers / Software Development \& Engineering / General},
}

@article{fremont-smith_interdisciplinary_1961,
	title = {The {Interdisciplinary} {Conference}},
	volume = {11},
	issn = {0096-7645},
	url = {https://www.jstor.org/stable/1292675},
	doi = {10.2307/1292675},
	number = {2},
	urldate = {2020-07-19},
	journal = {AIBS Bulletin},
	author = {Fremont-Smith, Frank},
	year = {1961},
	note = {Publisher: [Oxford University Press, American Institute of Biological Sciences]},
	pages = {17--32},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/N9W4IQMC/Fremont-Smith - 1961 - The Interdisciplinary Conference.pdf:application/pdf},
}

@article{wilds_information_1961,
	title = {Information {Retrieval}},
	volume = {24},
	issn = {0360-9081},
	url = {https://www.jstor.org/stable/40290892},
	number = {3},
	urldate = {2020-07-19},
	journal = {The American Archivist},
	author = {Wilds, Thomas},
	year = {1961},
	note = {Publisher: Society of American Archivists},
	pages = {269--282},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/T244F3JT/Wilds - 1961 - Information Retrieval.pdf:application/pdf},
}

@article{eldridge_computer_1963,
	title = {The {Computer} as a {Tool} for {Legal} {Research}},
	volume = {28},
	issn = {0023-9186},
	url = {https://www.jstor.org/stable/1190725},
	doi = {10.2307/1190725},
	number = {1},
	urldate = {2020-07-19},
	journal = {Law and Contemporary Problems},
	author = {Eldridge, William B. and Dennis, Sally F.},
	year = {1963},
	note = {Publisher: Duke University School of Law},
	pages = {78--99},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/U2IEIXA2/Eldridge and Dennis - 1963 - The Computer as a Tool for Legal Research.pdf:application/pdf},
}

@book{noauthor_scientific_1959,
	title = {Scientific {Information} {Notes}},
	language = {en},
	publisher = {National Science Foundation},
	year = {1959},
	note = {Google-Books-ID: A5tUAAAAMAAJ},
}

@book{noauthor_publication_1951,
	title = {Publication},
	language = {en},
	publisher = {National Academy of Sciences, National Research Council},
	year = {1951},
}

@book{alpha_yearbook_1952,
	title = {Yearbook},
	language = {en},
	author = {Alpha, Kappa Tau},
	year = {1952},
	note = {Google-Books-ID: 7BI2AAAAIAAJ},
}

@article{dhar_data_2013,
	title = {Data science and prediction},
	volume = {56},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/2500499},
	doi = {10.1145/2500499},
	abstract = {Big data promises automated actionable knowledge creation and predictive models for use by both humans and computers.},
	number = {12},
	urldate = {2020-07-21},
	journal = {Communications of the ACM},
	author = {Dhar, Vasant},
	month = dec,
	year = {2013},
	pages = {64--73},
	annote = {A priori reasoning ... e.g. "The word science implies ..."},
	file = {Dhar - 2013 - Data science and prediction.pdf:/Users/rca2t1/Dropbox/Zotero/storage/IULJY4JV/Dhar - 2013 - Data science and prediction.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6XICQ627/fulltext.html:text/html},
}

@inproceedings{zhu_data_2009,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Data {Explosion}, {Data} {Nature} and {Dataology}},
	isbn = {978-3-642-04954-5},
	doi = {10.1007/978-3-642-04954-5_25},
	abstract = {The essence of computer applications is to store things in the real world into computer systems in the form of data, i.e., it is a process of producing data. Some data are the records related to culture and society, and others are the descriptions of phenomena of universe and life. The large scale of data is rapidly generated and stored in computer systems, which is called data explosion. Data explosion forms data nature in computer systems. To explore data nature, new theories and methods are required. In this paper, we present the concept of data nature and introduce the problems arising from data nature, and then we define a new discipline named dataology (also called data science or science of data), which is an umbrella of theories, methods and technologies for studying data nature. The research issues and framework of dataology are proposed.},
	language = {en},
	booktitle = {Brain {Informatics}},
	publisher = {Springer},
	author = {Zhu, Yangyong and Zhong, Ning and Xiong, Yun},
	editor = {Zhong, Ning and Li, Kuncheng and Lu, Shengfu and Chen, Lin},
	year = {2009},
	keywords = {Brain Data, Cloud Computing, Data Nature, Internet Data, Real Nature},
	pages = {147--158},
	file = {Zhu et al. - 2009 - Data Explosion, Data Nature and Dataology.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3BLDTQF3/Zhu et al. - 2009 - Data Explosion, Data Nature and Dataology.pdf:application/pdf},
}

@book{loukides_what_2011-1,
	title = {What {Is} {Data} {Science}?},
	isbn = {978-1-4493-3609-7},
	abstract = {We've all heard it: according to Hal Varian, statistics is the next sexy job. Five years ago, in What is Web 2.0, Tim O'Reilly said that "data is the next Intel Inside." But what does that statement mean? Why do we suddenly care about statistics and about data? This report examines the many sides of data science -- the technologies, the companies and the unique skill sets.The web is full of "data-driven apps." Almost any e-commerce application is a data-driven application. There's a database behind a web front end, and middleware that talks to a number of other databases and data services (credit card processing companies, banks, and so on). But merely using data isn't really what we mean by "data science." A data application acquires its value from the data itself, and creates more data as a result. It's not just an application with data; it's a data product. Data science enables the creation of data products.},
	language = {en},
	publisher = {"O'Reilly Media, Inc."},
	author = {Loukides, Mike},
	month = apr,
	year = {2011},
	keywords = {Computers / Data Modeling \& Design},
}

@book{segaran_beautiful_2009,
	title = {Beautiful {Data}: {The} {Stories} {Behind} {Elegant} {Data} {Solutions}},
	isbn = {978-1-4493-7929-2},
	shorttitle = {Beautiful {Data}},
	abstract = {In this insightful book, you'll learn from the best data practitioners in the field just how wide-ranging -- and beautiful -- working with data can be. Join 39 contributors as they explain how they developed simple and elegant solutions on projects ranging from the Mars lander to a Radiohead video.With Beautiful Data, you will:Explore the opportunities and challenges involved in working with the vast number of datasets made available by the WebLearn how to visualize trends in urban crime, using maps and data mashupsDiscover the challenges of designing a data processing system that works within the constraints of space travelLearn how crowdsourcing and transparency have combined to advance the state of drug researchUnderstand how new data can automatically trigger alerts when it matches or overlaps pre-existing dataLearn about the massive infrastructure required to create, capture, and process DNA dataThat's only small sample of what you'll find in Beautiful Data. For anyone who handles data, this is a truly fascinating book. Contributors include:Nathan YauJonathan Follett and Matt HolmJ.M. HughesRaghu Ramakrishnan, Brian Cooper, and Utkarsh SrivastavaJeff HammerbacherJason Dykes and Jo WoodJeff Jonas and Lisa SokolJud ValeskiAlon Halevy and Jayant MadhavanAaron Koblin with Valdean KlumpMichal MigurskiJeff HeerCoco KrummePeter NorvigMatt Wood and Ben BlackburneJean-Claude Bradley, Rajarshi Guha, Andrew Lang, Pierre Lindenbaum, Cameron Neylon, Antony Williams, and Egon WillighagenLukas Biewald and Brendan O'ConnorHadley Wickham, Deborah Swayne, and David PooleAndrew Gelman, Jonathan P. Kastellec, and Yair GhitzaToby Segaran},
	language = {en},
	publisher = {"O'Reilly Media, Inc."},
	author = {Segaran, Toby and Hammerbacher, Jeff},
	month = jul,
	year = {2009},
	note = {Google-Books-ID: zxNglqU1FKgC},
	keywords = {Computers / General, Computers / Databases / Data Mining, Business \& Economics / General, Computers / Data Modeling \& Design, Computers / Desktop Applications / General},
	file = {Segaran and Hammerbacher - 2009 - Beautiful Data The Stories Behind Elegant Data So.pdf:/Users/rca2t1/Dropbox/Zotero/storage/IXWDM85K/Segaran and Hammerbacher - 2009 - Beautiful Data The Stories Behind Elegant Data So.pdf:application/pdf},
}

@incollection{hammerbacher_information_2009,
	title = {Information {Platforms} and the {Rise} of the {Data} {Scientist}},
	booktitle = {Beautiful {Data}: {The} {Stories} {Behind} {Elegant} {Data} {Solutions}},
	publisher = {O'Reilly Media Sebastopol, CA},
	author = {Hammerbacher, Jeff},
	year = {2009},
	pages = {73--84},
	file = {Hammerbacher - 2009 - Information Platforms and the Rise of the Data Sci.pdf:/Users/rca2t1/Dropbox/Zotero/storage/4CR9ZXIR/Hammerbacher - 2009 - Information Platforms and the Rise of the Data Sci.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QGPVI5X8/books.html:text/html},
}

@book{massa_visual_1964,
	title = {Visual {Data} {Transmission}},
	abstract = {Statistical coding and visual fidelity criterion approaches to the television bandwidth reduction problem are described and contrasted. A review of techniques based on both approaches is presented. A brief discussion of television signal properties and several television user applications is included. Emphasis is placed on bandwidth and/or power reduction through consideration and utilization of human visual summation properties. A class of reduced rate systems with random-scanning, noninformation bearing masks, and amplitude weighting are presented and discussed. (Author).},
	language = {en},
	publisher = {Air Force Cambridge Research Laboratories, Office of Aerospace Research, United States Air Force},
	author = {Massa, Ronald J.},
	year = {1964},
	note = {Google-Books-ID: YbV4iF0ugRUC},
}

@book{noauthor_data_1966,
	title = {Data and {Control}},
	language = {en},
	publisher = {Business Publications.},
	year = {1966},
	note = {Google-Books-ID: Dl0hAAAAMAAJ},
}

@misc{noauthor_data_nodate-5,
	title = {Data {Sciences} {Ltd} - {Company} {Profile} and {News}},
	url = {https://www.bloomberg.com/profile/company/2632618Z:LN},
	abstract = {Company profile page for Data Sciences Ltd including stock price, company news, press releases, executives, board members, and contact information},
	language = {en},
	urldate = {2020-07-22},
	journal = {Bloomberg.com},
	note = {Library Catalog: www.bloomberg.com},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WPNHXMNC/2632618ZLN.html:text/html},
}

@book{gama_learning_2007,
	title = {Learning from {Data} {Streams}: {Processing} {Techniques} in {Sensor} {Networks}},
	isbn = {978-3-540-73678-3},
	shorttitle = {Learning from {Data} {Streams}},
	abstract = {Sensor networks consist of distributed autonomous devices that cooperatively monitor an environment. Sensors are equipped with capacities to store information in memory, process this information and communicate with their neighbors. Processing data streams generated from wireless sensor networks has raised new research challenges over the last few years due to the huge numbers of data streams to be managed continuously and at a very high rate. The book provides the reader with a comprehensive overview of stream data processing, including famous prototype implementations like the Nile system and the TinyOS operating system. The set of chapters covers the state-of-art in data stream mining approaches using clustering, predictive learning, and tensor analysis techniques, and applying them to applications in security, the natural sciences, and education. This research monograph delivers to researchers and graduate students the state of the art in data stream processing in sensor networks. The huge bibliography offers an excellent starting point for further reading and future research.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Gama, João and Gaber, Mohamed Medhat},
	month = oct,
	year = {2007},
	keywords = {Computers / Information Technology, Computers / Intelligence (AI) \& Semantics, Technology \& Engineering / Telecommunications, Computers / Networking / Hardware, Computers / System Administration / Storage \& Retrieval, Technology \& Engineering / Electronics / General, Technology \& Engineering / Imaging Systems},
	annote = {"data mining and other data sciences"
"Here we discuss the broad  requirements in three emerging and overlapping areas that are relevant for disparate data exploitation, over an above traditional data fusion: data sciences, computational sciences, and decision sciences." (190)
See Section 12.13.1 ... Refers to "traditional data sciences."},
}

@book{yu_computational_2016,
	title = {Computational {Intelligent} {Data} {Analysis} for {Sustainable} {Development}},
	isbn = {978-1-4398-9595-5},
	abstract = {Going beyond performing simple analyses, researchers involved in the highly dynamic field of computational intelligent data analysis design algorithms that solve increasingly complex data problems in changing environments, including economic, environmental, and social data. Computational Intelligent Data Analysis for Sustainable Development present},
	language = {en},
	publisher = {CRC Press},
	author = {Yu, Ting and Chawla, Nitesh and Simoff, Simeon},
	month = apr,
	year = {2016},
	note = {Google-Books-ID: AGXNBQAAQBAJ},
	keywords = {Computers / Databases / Data Mining, Nature / Environmental Conservation \& Protection, Business \& Economics / Statistics, Computers / Programming / Games},
}

@book{phillips_digital_2013,
	title = {Digital {Analytics} {Primer}},
	isbn = {978-0-13-355210-2},
	abstract = {Learn the concepts and methods for creating economic and business value with digital analytics, mobile analytics, web analytics, and market research and social media data. In  Digital Analytics Primer , pioneering expert Judah Phillips introduces the concepts, terms, and methods that comprise the science and art of digital analysis for web, site, social, video, and other types of quantitative and qualitative data. Business readers—from new practitioners to experienced executives—who want to understand how digital analytics can be used to reduce costs and increase profitable revenue throughout the business should read this book. Phillips delivers a comprehensive review of the core concepts, vocabulary, and frameworks, including analytical methods and tools that can help you successfully integrate analytical processes, technology, and people into all aspects of business operations. This unbiased and product-independent primer draws from the author's extensive experience doing and managing analytics in this field.},
	language = {en},
	publisher = {FT Press},
	author = {Phillips, Judah},
	month = oct,
	year = {2013},
	note = {Google-Books-ID: ZX1eAQAAQBAJ},
	keywords = {Computers / Databases / Data Mining, Business \& Economics / Production \& Operations Management, Computers / Web / Social Media, Business \& Economics / Statistics},
	annote = {Defines data scientist on page 13.},
}

@book{morganroth_cardiac_2007,
	title = {Cardiac {Safety} of {Noncardiac} {Drugs}: {Practical} {Guidelines} for {Clinical} {Research} and {Drug} {Development}},
	isbn = {978-1-59259-884-7},
	shorttitle = {Cardiac {Safety} of {Noncardiac} {Drugs}},
	abstract = {Although it is relatively easy to determine the efficacy of a new drug, it is difficult to establish its safety when administered to millions of patients with multifaceted diseases, co-morbidities, sensitivities, and multiple drug use. In Cardiac Safety of Noncardiac Drugs: Practical Guidelines for Clinical Research and Drug Development, basic and clinical researchers from industry and academia detail the preclinical, clinical, and regulatory principles currently used to assess the cardiac safety of new drugs from their effects on the electrocardiogram (ECG). The authors explain the parameters of cardiac safety at all stages of clinical research and drug development, including both the preclinical and pharmacogenomic aspects generally and the clinical methodologies and technical aspects for investigational drugs based on cardiac repolarization, as defined by the duration of the QTc interval. Additional chapters comprehensively review the application of electrocardiology in clinical research, demonstrating the fundamentals of ECG interpretation in clinical trials, the statistical analysis plans for ECG data obtained in formal clinical trials, and the practical interpretation of the results. Highlights include practical guidance on how to conduct a thorough ECG Trial in New Drug Development, how to use new ECG and web-based technology in clinical research, and how to follow the new FDA requirements for ECG submissions. Authoritative and up-to-date, Cardiac Safety of Noncardiac Drugs: Practical Guidelines for Clinical Research and Drug Development offers clinical researchers in industry and academia expert practical advice on establishing their product's cardiac safety, predicting regulatory actions, and getting it successfully to market.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Morganroth, Joel and Gussak, Ihor},
	month = oct,
	year = {2007},
	note = {Google-Books-ID: NUS862kcS2oC},
	keywords = {Medical / Pharmacology, Medical / Pharmacy},
}

@article{noauthor_new_1992,
	title = {New {Scientist}},
	language = {en},
	year = {1992},
	note = {Google-Books-ID: EywVAQAAMAAJ},
	annote = {"Clinical Data Scientist"},
}

@article{noauthor_new_2001,
	title = {New {Scientist}},
	language = {en},
	year = {2001},
	note = {Google-Books-ID: vAsVAQAAMAAJ},
	annote = {Data Scientist, Center for Ecology and Hydrology},
}

@article{noauthor_new_1999,
	title = {New {Scientist}},
	language = {en},
	year = {1999},
	note = {Google-Books-ID: bBvxAAAAMAAJ},
	annote = {"A post for a data scientist ..."},
}

@article{noauthor_new_1996,
	title = {New {Scientist}},
	language = {en},
	year = {1996},
	note = {Google-Books-ID: wwUVAQAAMAAJ},
	annote = {"Senior Data Scientist," "Medical Data Scientist"},
}

@article{noauthor_new_1995,
	title = {New {Scientist}},
	language = {en},
	year = {1995},
	note = {Google-Books-ID: 6fjwAAAAMAAJ},
	annote = {"We are looking for a Data Scientist to join the Coding Dictionary Team" },
}

@article{noauthor_new_2001-1,
	title = {New {Scientist}},
	language = {en},
	year = {2001},
	note = {Google-Books-ID: YjHxAAAAMAAJ},
	annote = {Marine Data Scientist},
}

@misc{noauthor_weather_1995,
	title = {Weather {Is} {Now} {Being} {Predicted} a {Year} in {Advance}},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=45f13826-d7e8-4bd1-9495-2b18b206483a&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A3SHH-XB80-009C-B08R-00000-00&pdcontentcomponentid=166768&pdteaserkey=sr7&pditab=allpods&ecomp=gb63k&earg=sr7&prid=74571388-cc9e-4c14-b9ef-114d51287542},
	urldate = {2020-07-22},
	month = feb,
	year = {1995},
	annote = {OSGOOD: 'Forecasting of any kind is always difficult,' the data scientist, Niels Boer, once said, 'especially when it's about the future.' The OSGOOD FILE. Charles Osgood on the CBS Radio Network.WEATHER IS NOW BEING PREDICTED A YEAR IN ADVANCE},
	file = {WEATHER IS NOW BEING PREDICTED A YEAR IN ADVANCE:/Users/rca2t1/Dropbox/Zotero/storage/39R2PJA6/document.html:text/html},
}

@misc{noauthor_time_2005,
	title = {Time and {Tide} {Wait} for {No} {One}; the {Boxing} {Day} {Tsunami} {That} {Claimed} {Hundreds} of {Thousand} of {Lives} {Was}},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=737d0e5d-cd4d-47ac-9a3b-09c28d9ac5aa&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4GJT-XF20-0159-W3NS-00000-00&pdcontentcomponentid=245286&pdteaserkey=sr18&pditab=allpods&ecomp=gb63k&earg=sr18&prid=72d6b779-5fc4-48ba-a776-47023a9b4224},
	urldate = {2020-07-22},
	month = jul,
	year = {2005},
	annote = {It has already produced one very encouraging result as data scientist Phil Knight explains.TIME AND TIDE WAIT FOR NO ONE; THE BOXING DAY TSUNAMI THAT CLAIMED HUNDREDS OF THOUSAND OF LIVES WAS},
	file = {TIME AND TIDE WAIT FOR NO ONE\; THE BOXING DAY TSUNAMI THAT CLAIMED HUNDREDS OF THOUSAND OF LIVES WAS:/Users/rca2t1/Dropbox/Zotero/storage/YXGIS57V/document.html:text/html},
}

@misc{noauthor_pharmanet_2006,
	title = {{PharmaNet} {Professionals} {Addressing} {Challenges} of {Biopharmaceutical} {Research} \& {Development} {During} {Drug} {Information} {Association} {Meeting} in {Philadelphia}},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=f2ea6a81-ecff-4db9-b6dc-23299202aa72&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4K75-TVW0-TW8C-J2J7-00000-00&pdcontentcomponentid=7924&pdteaserkey=sr20&pditab=allpods&ecomp=gb63k&earg=sr20&prid=8420657d-9905-49d3-ac82-3e36a8870263},
	urldate = {2020-07-22},
	month = jun,
	year = {2006},
	annote = {Jim Downhower, MSE, senior director, IT development - Mr. Downhower has more than 15 years of experience with computer systems, including 9 years in clinical-development information technology (IT), and Kim Sanford, director, clinical data management with more than 15 years of clinical experience, including positions as CRF data scientist, senior clinical data analyst, and several positions of increasing responsibility in clinical data management, are scheduled to co-present at a session entitled, "Hybrid Data Capture Strategies."PharmaNet Professionals Addressing Challenges of Biopharmaceutical Research \& Development During Drug Information Association Meeting in Philadelphia },
	file = {PharmaNet Professionals Addressing Challenges of Biopharmaceutical Research & Development During Drug Information Association Meeting in Philadelphia:/Users/rca2t1/Dropbox/Zotero/storage/AXHRV8VZ/document.html:text/html},
}

@article{harmon_something_2007,
	title = {Something seedy is up when it comes to {BYU}},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=9baeb68b-cede-40c7-b517-447b0532d0e3&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4N91-M3V0-TWHW-6263-00000-00&pdcontentcomponentid=164282&pdteaserkey=sr24&pditab=allpods&ecomp=gb63k&earg=sr24&prid=8420657d-9905-49d3-ac82-3e36a8870263},
	urldate = {2020-07-22},
	journal = {Deseret Morning News},
	author = {Harmon, Dick},
	month = mar,
	year = {2007},
	annote = {According to an analysis by data scientist Paul Pocock, using the RPI as a basis for "expected seed," he took 54 teams who had made at least four tournament appearances in the last nine years and figured how much their actual seed differed from their expected seed with RPI.Something seedy is up when it comes to BYU},
	file = {Something seedy is up when it comes to BYU:/Users/rca2t1/Dropbox/Zotero/storage/XI2KGZYF/document.html:text/html},
}

@article{vette_data_1970,
	title = {Data management at the {National} {Space} {Science} {Data} {Center}},
	volume = {7},
	copyright = {Copyright American Institute of Aeronautics and Astronautics Oct 1970},
	issn = {00224650},
	url = {https://search.proquest.com/docview/2311273914/FF269B0B2D064F91PQ/12},
	doi = {http://dx.doi.org/10.2514/3.30140},
	language = {English},
	number = {10},
	urldate = {2020-07-22},
	journal = {Journal of Spacecraft and Rockets; Reston},
	author = {VETTE, J. I. and Karlow, N.},
	month = oct,
	year = {1970},
	note = {Num Pages: 1234-1240
Place: Reston, United States, Reston
Publisher: American Institute of Aeronautics and Astronautics},
	keywords = {Aeronautics And Space Flight, Data centers, Data management},
	pages = {1234--1240},
	annote = {"Space data scientist"},
	file = {Submitted Version:/Users/rca2t1/Dropbox/Zotero/storage/9VB2RL25/VETTE and Karlow - 1970 - Data management at the National Space Science Data.pdf:application/pdf},
}

@article{bryce_curriculum_2001-1,
	title = {Curriculum {Guidelines} for {Bachelor} of {Science} {Degrees} in {Statistical} {Science}},
	volume = {55},
	url = {https://search.proquest.com/docview/228524229/fulltext/FF269B0B2D064F91PQ/39?accountid=14678},
	abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
	language = {en},
	number = {1},
	urldate = {2020-07-22},
	journal = {American Statistician},
	author = {Bryce, G. Rex and Gould, Robert and Notz, William I. and Peck, Roxy L.},
	month = feb,
	year = {2001},
	pages = {7--13},
	annote = {Second, what are possible career paths for an individual with an undergraduate degree in statistical science? Such an individual may seek employment upon completion of the degree or may pursue graduate study. Those seeking employment may be required to do a variety of tasks such as standard statistical analyses, statistical programming, or data management. Any undergraduate curriculum should recognize the existence of different career paths and, where possible, offer multiple tracks. For example, a special track for "data scientists" placing greater emphasis on computing skills, recognizing a growing demand for graduates with these skills, might be worth considering.},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6VST26X5/39.html:text/html},
}

@article{simberloff_long-lived_2005,
	title = {Long-{Lived} {Digital} {Data} {Collections}: {Enabling} {Research} and {Education} in the 21st {Century}},
	shorttitle = {Long-{Lived} {Digital} {Data} {Collections}},
	journal = {National Science Foundation},
	author = {Simberloff, Daniel and Barish, B. C. and Droegemeier, K. K. and Etter, D. and Fedoroff, N. and Ford, K. and Lanzerotti, L. and Leshner, A. and Lubchenco, J. and Rossmann, M.},
	year = {2005},
	file = {Simberloff et al. - 2005 - Long-lived digital data collections enabling rese.pdf:/Users/rca2t1/Dropbox/Zotero/storage/CF8LIBKB/Simberloff et al. - 2005 - Long-lived digital data collections enabling rese.pdf:application/pdf},
}

@article{chynoweth_communication_2008,
	address = {London, England},
	title = {Communication is key for programmers},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=e0aaeba2-6f62-410b-bc54-a11d5f8f5253&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4SFX-GS40-TX38-S09K-00000-00&pdcontentcomponentid=10939&pdteaserkey=sr30&pditab=allpods&ecomp=gb63k&earg=sr30&prid=19e1f7de-2617-49de-93da-706f9a17e95e},
	urldate = {2020-07-22},
	journal = {The Times},
	author = {Chynoweth, Carly},
	month = may,
	year = {2008},
	annote = {Nathan Cunningham, 36, data scientist, British Antarctic Survey
"When I am on the ship I am part of a team of scientists collecting data about everything from the biomass in the ocean to the weather patterns. Because we can work only for a short while in the southern summer, we have to make the most of all the time available, which means working 12-hour shifts, seven days a week. Our monitoring equipment is always on and sends us 180 pieces of information every second. My role is to make sure that each person can find the exact data that they want among all this, so I write programs to help them to do this. Another one of my field responsibilities is getting the information that we collect back to Cambridge via satellite link so that other researchers can use the data."
--{\textgreater} VERY SIMILAR TO WHAT FB DATA SCIENTISTS DO
    },
	file = {Communication is key for programmers:/Users/rca2t1/Dropbox/Zotero/storage/C4J5H556/document.html:text/html},
}

@article{targeted_news_service_data_2008,
	address = {Troy, New York},
	title = {Data {Scientist} {Joins} {Rensselaer} {Tetherless} {World} {Research} {Constellation}},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=854408e9-c5a7-4f17-a0fb-7b790a719e8f&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4VD9-W4P0-TYCS-10KJ-00000-00&pdcontentcomponentid=299219&pdteaserkey=sr32&pditab=allpods&ecomp=gb63k&earg=sr32&prid=19e1f7de-2617-49de-93da-706f9a17e95e},
	urldate = {2020-07-22},
	journal = {Targeted News Service},
	author = {{Targeted News Service}},
	month = nov,
	year = {2008},
	annote = {Peter Fox},
	file = {Data Scientist Joins Rensselaer Tetherless World Research Constellation:/Users/rca2t1/Dropbox/Zotero/storage/6V6G7QVA/document.html:text/html},
}

@article{choudhury_case_2008,
	title = {Case {Study} in {Data} {Curation} at {Johns} {Hopkins} {University}},
	volume = {57},
	issn = {1559-0682},
	url = {https://muse.jhu.edu/article/262031},
	doi = {10.1353/lib.0.0028},
	abstract = {At Johns Hopkins University, the institutional repository (IR) is being developed as a component of an overall digital library architecture that will emphasize long-term preservation. The IR represents a set of services that will be developed to support the identified needs or requirements of faculty and students. Given the research-intensive environment at Johns Hopkins, one particular area of interest relates to data sets from a diversity of disciplines ranging from the humanities to the sciences. Essentially, the IR is being developed as a “gateway” to the underlying digital archive that will support data curation as part of an evolving cyberinfrastructure featuring open, modular components. In addition to this technological framework, Johns Hopkins is developing new roles and relationships between the library and the academic community, most notably through the development of “data scientists” or “data humanists.” These developments reflect the realization that the IR is the first step in a longer journey and that for institutional efforts to be successful, they must be integrated into a larger landscape of repositories that serve a distributed and diverse academic community.},
	language = {en},
	number = {2},
	urldate = {2020-07-22},
	journal = {Library Trends},
	author = {Choudhury, G. Sayeed},
	year = {2008},
	note = {Publisher: Johns Hopkins University Press},
	pages = {211--220},
	annote = {"'data scientist' or 'data humanist'"
With this insightful characterization, IRs can be considered one of many systems that will ultimately come together into an overall infrastructure, which will include both technology and human components. Duranceau’s article (this issue) points out the importance of new library professionals who can gather requirements, explain the value of IRs, and advance IR development accordingly. The data curation activities at JHU have highlighted the importance of new roles of “data scientist” or “data humanist.” These individuals, who are few in number at the moment, possess domain-specific knowledge and data management expertise. They act as the human interface between the library and the eScience projects. In a fundamental sense, they may represent the future of subject librarianship and help craft a new relationship between the library and scientists. [End Page 217] Scientific datasets may be thought of as the “special collections” of the digital age (Choudhury \& Stinson, 2007). Libraries’ role in preserving and curating special collections has led to a deep engagement with humanists who see the library as an objective, trusted laboratory. As libraries develop data curation programs, scientists may start to see libraries in a similar manner, leading to greater advocacy and support within and without the university.},
	file = {Choudhury - 2008 - Case Study in Data Curation at Johns Hopkins Unive.pdf:/Users/rca2t1/Dropbox/Zotero/storage/S9CH6AHQ/Choudhury - 2008 - Case Study in Data Curation at Johns Hopkins Unive.pdf:application/pdf},
}

@article{witt_institutional_2008,
	title = {Institutional repositories and research data curation in a distributed environment},
	volume = {57},
	number = {2},
	journal = {Library Trends},
	author = {Witt, Michael},
	year = {2008},
	note = {Publisher: Johns Hopkins University Press},
	pages = {191--201},
	annote = {



The D2C2 quickly grew to include five graduate assistants and a full-time Data Research Scientist, a position based on the data scientist role de- scribed in the “Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century” report from the National Science Board (2005). 
D2C2 = The Distributed Data Curation Center 



},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/CHBLVJ2V/Witt - 2008 - Institutional repositories and research data curat.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/XGNNKYHZ/summary.html:text/html},
}

@article{srivastava_data_2013,
	title = {Data {Mining} @ {Google} {Data} {Mining}},
	url = {https://www.academia.edu/26287209/Data_Mining_at_Google_Data_Mining},
	abstract = {Data Mining @ Google Data Mining},
	language = {en},
	urldate = {2020-07-27},
	author = {Srivastava, Vivek},
	year = {2013},
	note = {Date provided by author in personal communication.},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/IPTZJKFP/Data_Mining_at_Google_Data_Mining.html:text/html},
}

@article{plantin_data_2018,
	title = {Data {Cleaners} for {Pristine} {Datasets}: {Visibility} and {Invisibility} of {Data} {Processors} in {Social} {Science}:},
	copyright = {© The Author(s) 2018},
	shorttitle = {Data {Cleaners} for {Pristine} {Datasets}},
	url = {https://journals.sagepub.com/doi/10.1177/0162243918781268},
	doi = {10.1177/0162243918781268},
	abstract = {This article investigates the work of processors who curate and “clean” the data sets that researchers submit to data archives for archiving and further dissemi...},
	language = {en},
	urldate = {2020-07-29},
	journal = {Science, Technology, \& Human Values},
	author = {Plantin, Jean-Christophe},
	month = jun,
	year = {2018},
	note = {Publisher: SAGE PublicationsSage CA: Los Angeles, CA},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/YDFIN9GV/0162243918781268.html:text/html},
}

@article{wing_data_2019,
	title = {The {Data} {Life} {Cycle}},
	volume = {1},
	issn = {,},
	url = {https://hdsr.mitpress.mit.edu/pub/577rq08d/release/3},
	doi = {10.1162/99608f92.e26845b4},
	abstract = {To put data science in context, we present phases of the data life cycle, from data generation to data interpretation. These phases transform raw bits into value for the end user. Data science is thus much more than data analysis, e.g., using techniques from machine learning and statistics; extracting this value takes a lot of work, before and after data analysis. Moreover, data privacy and data ethics need to be considered at each phase of the life cycle.Keywordsanalysis, collection, data life cycle, ethics, generation, interpretation, management, privacy, storage, story-telling, visualization},
	language = {en},
	number = {1},
	urldate = {2020-07-30},
	journal = {Harvard Data Science Review},
	author = {Wing, Jeannette M.},
	month = jul,
	year = {2019},
	note = {Publisher: PubPub},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/FX2ANGB3/Wing - 2019 - The Data Life Cycle.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/R4ZJXP5J/3.html:text/html},
}

@patent{noauthor_prior_1998,
	title = {{PRIOR} {DATA} {SCIENCES} {LTD} / {KEN} {MACKAY}, {Consultant}},
	url = {https://lobbycanada.gc.ca/app/secure/ocl/lrs/do/vwRg?regId=488442&lang=eng},
	abstract = {Version 1 of 1 (1998-10-16 to 2000-02-03) was submitted prior to the Lobbying Act coming into force on July 2, 2008. Due to different information requirements at that time, the registration is presented in the following format.},
	language = {eng},
	urldate = {2020-08-01},
	month = oct,
	year = {1998},
	note = {Last Modified: Insert the date of last modification (YYYY-MM-DD)
Library Catalog: lobbycanada.gc.ca},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/EK6TQJM7/vwRg.html:text/html},
}

@book{mcewen_management_1974,
	title = {Management of {Data} {Elements} in {Information} {Processing}},
	publisher = {National Bureau of Standards, Department of Commerce},
	author = {McEwen, Hazel E.},
	year = {1974},
	file = {McEwen - 1974 - Management of data elements in information process.pdf:/Users/rca2t1/Dropbox/Zotero/storage/5TAQWYTJ/McEwen - 1974 - Management of data elements in information process.pdf:application/pdf},
}

@book{mcewen_management_1975,
	title = {Management of {Data} {Elements} in {Information} {Processing}},
	author = {McEwen, H.E.},
	year = {1975},
	file = {McEwen - 1975 - Management of Data Elements in Information Process.pdf:/Users/rca2t1/Dropbox/Zotero/storage/79A293SP/McEwen - 1975 - Management of Data Elements in Information Process.pdf:application/pdf},
}

@article{karlow_data_1969,
	title = {Data {Information} {System} at the {National} {Space} {Science} {Data} {Center}},
	author = {Karlow, Nick and Vette, James I.},
	year = {1969},
	annote = {Uses "space data scientist" and "impedance matching".},
	file = {Karlow and Vette - 1969 - Data Information System at the National Space Scie.pdf:/Users/rca2t1/Dropbox/Zotero/storage/UF48KUU8/Karlow and Vette - 1969 - Data Information System at the National Space Scie.pdf:application/pdf},
}

@article{smith_management_1972,
	title = {The {Management} of {Information} {Analysis} {Centers}: {Proceedings} of a {Forum} {Sponsored} by the {COSATI} {Panel} on {Information} {Analysis} {Centers}.},
	shorttitle = {The {Management} of {Information} {Analysis} {Centers}},
	author = {Smith, William A.},
	year = {1972},
	note = {Publisher: ERIC},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/K4XSB2EK/Smith - 1972 - The Management of Information Analysis Centers Pr.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/PWCZKP8J/eric.ed.gov.html:text/html},
}

@misc{oreilly_what_2005,
	title = {What {Is} {Web} 2.0},
	url = {https://oreilly.com{file}},
	abstract = {Tim O'Reilly attempts to clarify just what is meant by Web 2.0, the term first coined at a conference brainstorming session between O'Reilly Media and MediaLive International, which also spawned the Web 2.0 Conference.},
	urldate = {2020-08-06},
	author = {O'Reilly, Tim},
	month = sep,
	year = {2005},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/E7QUTSVQ/what-is-web-20.html:text/html},
}

@inproceedings{oreilly_web_2009,
	address = {San Francisco : Santa Monica, CA},
	title = {Web {Squared}: {Web} 2.0 {Five} {Years} {On}},
	url = {https://conferences.oreilly.com/web2summit/web2009/public/schedule/detail/10194},
	abstract = {Co-produced by UBM TechWeb \& O'Reilly Conferences},
	urldate = {2020-08-06},
	publisher = {O'Reilly Media, Inc.},
	author = {O'Reilly, Tim and Battelle, John},
	month = oct,
	year = {2009},
	file = {O'Reilly and Battelle - 2009 - Web Squared Web 2.0 Five Years On.pdf:/Users/rca2t1/Dropbox/Zotero/storage/G4BUL26C/O'Reilly and Battelle - 2009 - Web Squared Web 2.0 Five Years On.pdf:application/pdf;Web Squared\: Web 2.0 Five Years On\: Web 2.0 Summit 2009 - Co-produced by UBM TechWeb & O'Reilly Conferences, October 20 - 22, 2009, San Francisco, CA:/Users/rca2t1/Dropbox/Zotero/storage/UQTDLMKQ/10194.html:text/html},
}

@misc{dungate_what_2020,
	title = {What can the humanities do for data science?},
	url = {https://www.turing.ac.uk/news/what-can-humanities-do-data-science},
	abstract = {A new white paper explores the potential for research at the intersection between data science and humanities.},
	language = {en},
	urldate = {2020-08-07},
	publisher = {The Alan Turing Institute},
	author = {Dungate, Joanna},
	month = aug,
	year = {2020},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/E6IWZ3EA/what-can-humanities-do-data-science.html:text/html},
}

@article{mckinsey__company_hal_2009,
	title = {Hal {Varian} on {How} the {Web} {Challenges} {Managers}},
	url = {https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/hal-varian-on-how-the-web-challenges-managers},
	urldate = {2020-08-07},
	journal = {McKinsey \& Company},
	author = {{McKinsey \& Company}},
	month = jan,
	year = {2009},
	file = {Hal Varian on how the Web challenges managers | McKinsey:/Users/rca2t1/Dropbox/Zotero/storage/IEKUQ8VB/hal-varian-on-how-the-web-challenges-managers.html:text/html},
}

@article{halevy_unreasonable_2009,
	title = {The {Unreasonable} {Effectiveness} of {Data}},
	volume = {24},
	url = {https://ieeexplore.ieee.org/abstract/document/4804817},
	number = {2},
	journal = {IEEE Intelligent Systems},
	author = {Halevy, Alon and Norvig, Peter and Pereira, Fernando},
	year = {2009},
	note = {Publisher: IEEE},
	pages = {8--12},
	file = {Halevy et al. - 2009 - The Unreasonable Effectiveness of Data.pdf:/Users/rca2t1/Dropbox/Zotero/storage/J78Z43RA/Halevy et al. - 2009 - The Unreasonable Effectiveness of Data.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CNSIJIRY/4804817.html:text/html},
}

@patent{bharat_generating_2016,
	title = {Generating user information for use in targeted advertising},
	author = {Bharat, Krishna and Lawrence, Stephen and Sahami, Mehran},
	month = jan,
	year = {2016},
	note = {Publisher: Google Patents},
	annote = {US Patent 9,235,849},
	file = {Bharat et al. - 2016 - Generating user information for use in targeted ad.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HKAEGNAZ/Bharat et al. - 2016 - Generating user information for use in targeted ad.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RDMMSKK2/en.html:text/html},
}

@misc{rodriguez_asa_2013,
	title = {The {ASA} and {Big} {Data}},
	url = {https://magazine.amstat.org/blog/2013/06/01/the-asa-and-big-data/},
	language = {en-US},
	urldate = {2020-08-12},
	journal = {Amstat News},
	author = {Rodriguez, Robert and Davidian, Marie and Schenker, Nathaniel},
	month = jun,
	year = {2013},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2DDP9ZWL/the-asa-and-big-data.html:text/html},
}

@misc{rodriguez_big_2012,
	title = {Big {Data} and {Better} {Data}},
	url = {https://magazine.amstat.org/blog/2012/06/01/prescorner/},
	abstract = {Bob Rodriguez talks big data in the June President's Corner column.},
	language = {en-US},
	urldate = {2020-08-12},
	journal = {Amstat News},
	author = {Rodriguez, Robert},
	month = jun,
	year = {2012},
	file = {June2012.pdf:/Users/rca2t1/Dropbox/Zotero/storage/43GZXTXM/June2012.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4UDK73BS/prescorner.html:text/html},
}

@book{ishikawa_social_2015,
	title = {Social {Big} {Data} {Mining}},
	isbn = {978-1-4987-1094-7},
	abstract = {This book focuses on the basic concepts and the related technologies of data mining for social medial. Topics include: big data and social data, data mining for making a hypothesis, multivariate analysis for verifying the hypothesis, web mining and media mining, natural language processing, social big data applications, and scalability. It explains},
	language = {en},
	publisher = {CRC Press},
	author = {Ishikawa, Hiroshi},
	month = mar,
	year = {2015},
	note = {Google-Books-ID: UX0ZBwAAQBAJ},
	keywords = {Computers / Databases / Data Mining, Science / Life Sciences / General, Computers / Machine Theory, Computers / Software Development \& Engineering / Systems Analysis \& Design},
}

@misc{dominici_big_2012,
	title = {Big {Data}: {Benefit} to {Society}, or {Drowning} in a {Data} {Deluge}?},
	shorttitle = {Big {Data}},
	url = {https://www.socialsciencespace.com/2012/11/big-databenefit-to-society-or-drowning-in-a-data-deluge/},
	abstract = {With larger data sets offering researchers the potential to look at more subtle interactions, big data is becoming increasingly valuable to social sciences, yet challenges remain.},
	language = {en-US},
	urldate = {2020-08-13},
	journal = {Social Science Space},
	author = {Dominici, David Castillo},
	month = nov,
	year = {2012},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CNXM3X2N/big-databenefit-to-society-or-drowning-in-a-data-deluge.html:text/html},
}

@misc{marr_brief_2015,
	type = {Organization {Blog}},
	title = {A {Brief} {History} of {Big} {Data} {Everyone} {Should} {Read}},
	url = {https://www.weforum.org/agenda/2015/02/a-brief-history-of-big-data-everyone-should-read/},
	abstract = {The World Economic Forum is an independent international organization committed to improving the state of the world by engaging business, political, academic and other leaders of society to shape global, regional and industry agendas. Incorporated as a not-for-profit foundation in 1971, and headquartered in Geneva, Switzerland, the Forum is tied to no political, partisan or national interests.},
	language = {en},
	urldate = {2020-08-14},
	journal = {World Economic Forum},
	author = {Marr, Bernard},
	month = feb,
	year = {2015},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/M8P2ECPQ/a-brief-history-of-big-data-everyone-should-read.html:text/html},
}

@article{noauthor_volume_nodate,
	title = {Volume 455 {Issue} 7209, 4 {September} 2008},
	copyright = {©2020 Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/nature/volumes/455/issues/7209},
	abstract = {Volume 455 Issue 7209, 4 September 2008},
	language = {en},
	urldate = {2020-08-15},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NIGJFR8Y/7209.html:text/html},
}

@article{noauthor_community_2008,
	title = {Community cleverness required},
	volume = {455},
	copyright = {2008 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/455001a},
	doi = {10.1038/455001a},
	abstract = {Researchers need to adapt their institutions and practices in response to torrents of new data — and need to complement smart science with smart searching.},
	language = {en},
	number = {7209},
	urldate = {2020-08-15},
	journal = {Nature},
	month = sep,
	year = {2008},
	note = {Number: 7209
Publisher: Nature Publishing Group},
	pages = {1--1},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/AJJ6NJEZ/2008 - Community cleverness required.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/UFGRI472/455001a.html:text/html},
}

@misc{noauthor_journal_nodate,
	title = {Journal of {Data} {Science}: {Volume} 1, {Number} 1, {January} 2003},
	url = {http://www.jds-online.com/v1-1},
	urldate = {2020-08-16},
	file = {Journal of Data Science\: Volume 1, Number 1, January 2003:/Users/rca2t1/Dropbox/Zotero/storage/IE6NB6HP/v1-1.html:text/html},
}

@article{dewan_occipital_1967,
	title = {Occipital {Alpha} {Rhythm} {Eye} {Position} and {Lens} {Accommodation}},
	volume = {214},
	copyright = {1967 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/214975a0},
	doi = {10.1038/214975a0},
	abstract = {People can be taught to control voluntarily their own alpha rhythms. This can be used to send messages in Morse code when an electroencephalogram pattern is used as part of a computer programme. Such procedures may help to explain the mechanisms by which the alpha rhythm is “blocked” or “unblocked”.},
	language = {en},
	number = {5092},
	urldate = {2020-08-17},
	journal = {Nature},
	author = {Dewan, Edmond M.},
	month = jun,
	year = {1967},
	note = {Number: 5092
Publisher: Nature Publishing Group},
	pages = {975--977},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/8RA244TF/Dewan - 1967 - Occipital Alpha Rhythm Eye Position and Lens Accom.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/EVCR9CNU/214975a0.html:text/html},
}

@article{loy_embracing_2016,
	title = {Embracing {Data} {Science}},
	url = {http://arxiv.org/abs/1607.00858},
	abstract = {Statistics is running the risk of appearing irrelevant to today's undergraduate students. Today's undergraduate students are familiar with data science projects and they judge statistics against what they have seen. Statistics, especially at the introductory level, should take inspiration from data science so that the discipline is not seen as somehow lesser than data science. This article provides a brief overview of data science, outlines ideas for how introductory courses could take inspiration from data science, and provides a reference to materials for developing stand-alone data science courses.},
	urldate = {2020-08-21},
	journal = {arXiv:1607.00858 [cs, stat]},
	author = {Loy, Adam},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.00858},
	keywords = {Statistics - Other Statistics, Computer Science - General Literature},
	annote = {Comment: 9 pages, 1 figure},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/FNHPTAQA/Loy - 2016 - Embracing Data Science.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QURMZV5T/1607.html:text/html},
}

@article{horton_setting_2015-1,
	title = {Setting the {Stage} for {Data} {Science}: {Integration} of {Data} {Management} {Skills} in {Introductory} and {Second} {Courses} in {Statistics}},
	volume = {28},
	issn = {0933-2480, 1867-2280},
	shorttitle = {Setting the {Stage} for {Data} {Science}},
	url = {http://arxiv.org/abs/1502.00318},
	doi = {10.1080/09332480.2015.1042739},
	abstract = {Many have argued that statistics students need additional facility to express statistical computations. By introducing students to commonplace tools for data management, visualization, and reproducible analysis in data science and applying these to real-world scenarios, we prepare them to think statistically. In an era of increasingly big data, it is imperative that students develop data-related capacities, beginning with the introductory course. We believe that the integration of these precursors to data science into our curricula-early and often-will help statisticians be part of the dialogue regarding "Big Data" and "Big Questions".},
	number = {2},
	urldate = {2020-08-21},
	journal = {CHANCE},
	author = {Horton, Nicholas J. and Baumer, Benjamin S. and Wickham, Hadley},
	month = apr,
	year = {2015},
	note = {arXiv: 1502.00318},
	keywords = {Statistics - Computation, Computer Science - Computers and Society, Statistics - Other Statistics, 62-01},
	pages = {40--50},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/G95SIU29/Horton et al. - 2015 - Setting the stage for data science integration of.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/7SXDTP9R/1502.html:text/html},
}

@article{saunders_data_2013,
	chapter = {News},
	title = {Data {Science} and {Data} {Scientists}: {What}'s in a {Name}?},
	copyright = {© 2013 Information Management and SourceMedia, Inc. All rights reserved.},
	shorttitle = {Data {Science} and {Data} {Scientists}},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=INFOM00020131111e9bb0002u&cat=a&ep=ASE},
	abstract = {Once again, people in the information management field are confronted with a new term surrounded by lots of excitement and promise, but also lots of hype and ambiguity. The term du jour is data science. I will attempt to give a reasonable definition for data science and describe the capabilities possessed by a data scientist. I’ll also attempt to compare and contrast data science with business intelligence and data analysis, which often seem to be confused with (or considered synonymous with) with data science. The Hype},
	language = {English},
	urldate = {2020-08-28},
	journal = {Information Management},
	author = {Saunders, Todd},
	month = nov,
	year = {2013},
	note = {Publisher: SourceMedia, Inc.
Volume: Vol.1, No.1},
	keywords = {Software, Computers/Electronics, Technology, Applications Software, Business Intelligence Software, Computing},
	annote = {The hype is nearly impossible to miss. Large numbers of articles and blogs, often with provocative titles, have been published.  For example, back in 2009 Mike Driscoll wrote an article, “The Three Sexy Skills of Data Geeks.” And about a year ago, the Harvard Business Review published an article titled, “Data Scientist: The Sexiest Job of the 21st Century.”  Let’s face it, in the technical fields we don’t see titles like that very often!  The website KDNuggets, which focuses on the data mining community, reported that, “The big demand for analytics, data mining, and data science professionals led to a significant jump in their salaries in 2013.”  And many colleges and universities are beginning to offer courses and degrees in data science. (For a sample list see: http://datascience101.wordpress.com/2012/04/09/colleges-with-data-science-degrees). This illustrates that there is at least some validity to the hype. Companies are spending money on data science, people are being hired and paid generous salaries to be data scientists, and individuals are investing their own time and money to take courses and earn degrees to become data scientists. But what exactly is data science and what is a data scientist? What is a Data Scientist? First, we might want to consider where the term originated.  A very nice article that was published in Forbes Magazine titled, “A Very Short History of Data Science” gives a good overview of the origins of data science (both the term and the practice). The article mentions that one of the first occurrences of the term “data science” appeared in a book published in 1974 by Peter Naur titled, “Concise Survey of Computer Methods.”  The Forbes article then goes on to cite other articles, papers, books, and conferences over the subsequent years that mention data science. What is interesting is that the frequency of the use of the term increases significantly the last few years. While that last statement is purely anecdotal, I can attest that from my many years of working in the BI services industry that the term ”data scientist” is certainly more prevalent now than at any time in the past. This history of the term data science shows us that it typically referred to a combination of the usage of statistics, computers, and data along with some domain (i.e., business or a specific discipline) knowledge. This leads to what I think works well as a definition of data science (drawing heavily from the mission statement of International Association for Statistical Computing): Data science is the linkage of traditional statistical methodology, modern computer technology, and the knowledge of domain experts in order to convert data into information and knowledge. This definition is somewhat broad, and we can have a rather lengthy discussion about each of the different components of the definition (I will touch on some of the components later in this article), but the real point is to provide sufficient clarity for the term so that it is less likely to be confused with other terms such as business intelligence or data analysis. And why is that important? Simply to be pragmatic. The point of a definition is efficient communication. The three terms that sometimes get confused – BI, data analysis, data science – all have relatively wide ranges of definitions and overlap. But what is important is that you and the person you are talking to have a similar understanding of whatever term the two of you are talking about. You can certainly find much more varied and detailed definitions of data science, but many suffer from what is called “over-fit” in the statistical world. Those definitions are so detailed and specific they tend to be more obfuscating than illuminating. I prefer to sacrifice a little bit of specificity in favor of practicality and usefulness. What it comes down to is that if you have a data-related problem that needs to be solved, it helps to understand what skills would be needed to solve that problem and what type of person would have those skills so you can put the right person on the job. So what separates a data scientist from a business intelligence practitioner from a data analyst?  To answer that question, let’s take a slightly more detailed look at each role and what skills are required for each.  Data Analyst Data analysts typically focus on the sources and uses of data. These people will identify where data is created and how it flows through the business processes, track the business rules that are applied to the data, and observe how the data is reported and used. They research and understand how different pieces of data are related and affect each other. They examine and monitor the quality of data (completeness, timeliness, consistency, accuracy), and often they build or support data models used in solutions within the organization. In addition to data models, data analysts often develop and work with data dictionaries and metadata. They also utilize software that can help them analyze data along the quality components. Rudimentary statistics (min, max, mean, count, average) are typically all that is needed for most data analyst tasks. However, they need a rather thorough understanding of the business and business processes to effectively analyze the data. Business Intelligence Practitioner A BI practitioner can cover a wide range of activities and skills. Since BI focuses on providing information to business users to support decision-making, the BI practitioner typically possesses understanding and skills involved in both business and technology. This type of person may leverage technical skills to combine data from multiple sources into an integrated environment (e.g., data warehouse or data mart) from which reports and analysis can be developed using reporting and visualization software. Or they may apply their knowledge of the data and the business to define and build reports and analysis that are meaningful to the business and can convey that information effectively to the business users.  This type of person typically has computer skills that facilitate moving data among systems, building databases or using reporting and visualization software. And they usually have the ability to communicate their findings to business users. While the types of analyses they perform are usually more along the lines of descriptive statistics (current results, trends), they may incorporate results from statistical models that are provided to the BI solution in their business communications. Data Scientist What sets a data scientist apart from the other two categories is primarily the use of statistics.  While some definitions of data science minimize (or at least reduce) the dependency on advanced statistical techniques, history seems to indicate that data science is a broadening of the capabilities of statisticians.  While a data scientist has the capability to do much of the same work as a data analyst or BI practitioner, his or her primary focus is statistical analysis, be it predictive model development, machine learning or data mining. And what sets data scientists apart from pure statisticians is their computer programming ability used to manage large data sets along with their domain knowledge, which they use to guide their analysis. Consider the following example to illustrate the above definitions. If, as a businessperson, you need to understand what your organization’s definition of “current customer” and where that information resides, you probably need a data analyst. If you need to visualize and organize information and present it to an executive team, you probably need a business intelligence person. If you would like to predict future earnings based on past performance, current and forecasted economic conditions, social media sentiment, website activity and customer churn rates, you probably want a data scientist. What’s Changed? So what happened recently that has made data science so popular? Why is a (relatively) new job description needed now when it wasn’t needed nearly as much only a couple years ago?  My assertion is that the emergence of big data has led to the data science movement. Since the term “big data” is another relatively new and hyped term, allow me to give it a definition within the context of this article.  When I refer to big data, I’m talking about the vast amounts and types of structured and unstructured data that is growing by leaps and bounds that can be captured and made available for analysis. Businesses and organizations now have access to enormous amounts of data that come in as and/or can be converted into a variety of forms: key value pairs, documents, object notation, text, free-form language, columnar data, etc. To manage all this data, many new tools and technologies have been developed, e.g., Hadoop, MongoDB, MapReduce, natural language processing, columnar databases, NoSQL, Pig, Hive, Impala, and many others. Because statistical analysis relies heavily on the quality and structure of the underlying data being analyzed, statisticians started gaining skills with these new data management technologies to allow them to structure and build the data sets they needed to perform the desired statistical analysis.  The data structures and technologies also provided more capability to analyze extremely large sets of data like clickstream data, astronomy data, health care data, and weather data. That is where the data scientist most  clearly stands out: While the statistician typically carried SAS or SPSS in their tool chest, data scientists carry the statistical packages (SAS, SPSS, R) along with programming and data manipulation languages (Python, PHP, Ruby, Java, MapReduce, C++, Hive, Pig, Impala, etc.). They know how to best write the code to execute machine learning algorithms based on the underlying data structure and volumes. And they know how to apply the domain context to the results. Covering More Ground One last caveat about data science: As I stated earlier, I view data science as a broadening of the practice of statistical analysis. This implies that data science initiatives are broader than statistical analysis initiatives. With traditional statistical analysis (and admittedly oversimplified), statisticians just needed a server loaded with their favorite stats software package and plenty of disk space, and they were good to go. Now that we have big data in the mix, a data science initiative needs to cover a lot more ground. The types and volumes of data need to be assessed to determine what technical architecture will be required. Will you build a HDFS system? NoSQL? Document store? Do you need large numbers of standard servers or a small number of beefy, multicore servers? What is the goal of the analysis?  Who is responsible for finding, loading and assessing the data?  Who will install the software?  Who else needs to be involved with the initiative?  The question list is extensive. The point being made is that data science initiatives will probably require program and project management, business analysis and executive sponsorship and oversight in addition to the statistical analysis. It’s not just one guy with a PC in a back room with a six-pack of Mountain Dew and a bag of Cheetos (… no disrespect). You might want your data scientist to cover the project management, solution design, architecture and presentation components of the initiative in addition to the actual analysis. Or you may want to consider a team approach, since it is rare to find one individual with all those capabilities. Overlap and Divergence I’ve attempted to show that BI, data analysis, and data science all serve valuable functions and provide substantial benefits to organizations by helping to turn data into information. Hence, there is a lot of overlap among these disciplines. Namely, data is being captured, structured, manipulated and analyzed in order to provide information and insight. Where these disciplines diverge is in regard to the tools they use, the types of analyses they perform, and the specific types of issues they address.},
}

@article{noauthor_booz_2013,
	title = {Booz {Allen} {Maps} the {DNA} of {Data} {Science} with {Release} of {The} {Field} {Guide} to {Data} {Science}},
	copyright = {(c) 2013 Business Wire. All Rights Reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=BWR0000020131106e9b60007r&cat=a&ep=ASE},
	abstract = {MCLEAN, Virginia--(BUSINESS WIRE)--November 06, 2013-- A commercial airline facing increased market competition leveraged "big data" analytical tools and machine learning on terabytes of data to better serve its most frequent fliers and priority passengers and to improve financial performance. This is one example in today's increasingly complex world, where data -- no matter its form, shape or size -- is omnipresent and can be used for competitive edge. Leaders at organizations of all shapes and sizes are doing their best to figure out how to turn that data into a resource. They are looking for answers in a new, growing field - data science.},
	language = {English},
	urldate = {2020-08-28},
	journal = {Business Wire},
	month = nov,
	year = {2013},
	note = {Publisher: Business Wire, Inc.},
	keywords = {Accounting/Consulting, Booz Allen Hamilton Holding Corp., Business Consultancy, Business/Consumer Services, Management Consulting, The Carlyle Group},
	annote = {The Field Guide to Data Science by Booz Allen Hamilton (Photo: Business Wire) Working to spur awareness of and best practices in data science, Booz Allen Hamilton (NYSE:BAH), a leading provider of management consulting, technology and engineering services, today released The Field Guide to Data Science. The Guide taps into the diverse, collective expertise of the firm's data science team and offers insight into how organizations can navigate the data science waters to capture revenue-driving and mission-enabling insights for the business, a process Booz Allen Hamilton refers to as 'Cloud EBITDA'. The guide offers readers a look into: -- Data Science 101 -- what is data science and how does it work, what it takes to set up a data science team and how to refine capabilities -- The Nuances of Data Science -- various principles, parts and models to be incorporated into a data science strategy -- A Deep Dive - the more technical side of managing and analyzing data -- Success -- case studies and examples of work that Booz Allen Hamilton has completed as a partner to clients "Our hope is that The Field Guide to Data Science will serve as a resource to help pioneer the data science community as the field continues to evolve and grow, particularly at the university level where data science degrees will soon be the norm," said Booz Allen Hamilton vice president and data scientist, Dr. Joshua Sullivan. "Our team of data science experts are entrenched in the nuances of this field and have so much to offer; however, we also realize that there is enormous potential to tap into the data science community and provide them with the opportunity to contribute and create an industry wide set of best practices." The Guide, a living document, is available via the Booz Allen Hamilton website. It will be open for user generated submissions; interested, qualified parties are invited to email ideas and perspectives or submit content via a pull request on the GitHub repository. For more information about Booz Allen Hamilton and The Field Guide to Data Science, follow us on Twitter: @boozallen @joshdsullivan @petrguerra @CloudEBITDA About Booz Allen Hamilton Booz Allen Hamilton is a leading provider of management consulting, technology, and engineering services to the U.S. government in defense, intelligence, and civil markets, and to major corporations, institutions, and not-for-profit organizations. Booz Allen is headquartered in McLean, Virginia, employs more than 23,000 people, and had revenue of \$5.76 billion for the 12 months ended March 31, 2013. BAHPR-CW Photos/Multimedia Gallery Available: http://www.businesswire.com/multimedia/home/20131106005514/en/},
}

@article{langenkamp_how_2014,
	chapter = {News},
	title = {How to {Become} a {Data} {Scientist}},
	copyright = {© 2014 Information Management and SourceMedia, Inc. All rights reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=INFOM00020141017eaah0002t&cat=a&ep=ASE},
	abstract = {In an interview with Information Management, data scientist Irmak Sirer discusses the realities and necessities of data science. Sirer is instructing a 12-week data science boot camp offered through a partnership between test preparation organization Kaplan and Chicago-based data science and design firm Datascope. Boot camps, he explains, are one of the three main routes people can choose to begin a data science career. In an interview with , data scientist Irmak Sirer discusses the realities and necessities of data science. Sirer is also instructing a 12-week data science boot camp offered through a partnership between test preparation organization Kaplan and Chicago-based data science and design firm Datascope. Boot camps, he explains, are one of the three main routes people can choose to begin a data science career.},
	language = {English},
	urldate = {2020-08-28},
	journal = {Information Management},
	author = {Langenkamp, Julie},
	month = oct,
	year = {2014},
	note = {Publisher: SourceMedia, Inc.
Volume: Vol.1, No.1},
	annote = {I like the word “scientist” in data scientist. My background is in science, too. I have a PhD, and basically I was looking at data sets in nature or complex systems. [In science] we have the scientific method to deal with a lot of data and extract information from it. In our day and age, businesses have started to gather a ton of data, and science already knew how to deal with [such large volumes]. Hence data science, where we take the tools developed from physics, applied mathematics and computer science and we apply them to business data. This way we can extract the most information in the most correct and [applicable] way. I think the incentive came from today’s technology gaining a lot of pace and businesses actually starting to create a lot of data that they can look at [and learn] from. I think data science is basically applying the scientific approach to business. It’s a pretty simple definition, but I think it exactly captures the whole idea behind it. Clearly data science is very hot right now. Where I think data science contributes the most is basically converting numbers and data into consumable information for human brains; data science helps with decision-making. Beyond the hype and the application of the scientific method to business data, [data science] is a great way to convert the information hidden in the numbers and data into visually and conceptually understandable models that managers can make decisions upon. With any position like data science, there’s a lot of excitement as people realize they can benefit from it. People see the value and the industry is really excited, which I think is great, but also there is a lot of confusion. The confusion [will die] down as people are getting used to what data science does and how it can [help decision-making], and some of the demand may die down as the extra excitement and hype goes down. But because of that root problem of data containing information which needs to be rotated and converted for humans to understand and make decisions, data science will stay here for a very, very long time - as long as businesses are generating data, and I don’t think that’s going anywhere. So I think there will be some clarification and some dying down of the hype in the near future, but I think data science is not just a fad and it’s actually a fundamental part of data-driven businesses. Businesses know now that they need data scientists, but it’s difficult to [determine] how to find good data scientists. This is part of the reason that we were really happy to jump on the idea of a boot camp. Just like the businesses that are not sure where to find skilled data scientists, it’s also not very clear for students how to actually get into data science. And as things become clearer with more [understanding of] the necessary skills, how to gain those skills and how you find a job in data science, I think there will be a steady demand and supply for data scientists. In data science, nobody knows everything. If you enrolled in data science school for four or five years you would still not know everything. I don’t know everything. None of the other data scientists that I know knows everything; that’s why data scientists work in teams. The most important property is to adapt quickly and learn quickly on the job. On a daily basis with my projects I see things that I have no idea how to tackle, but I have a strong enough foundation that I can quickly learn, adapt and take those projects head on. This is the most important skill to teach that in a boot camp. [The boot camp] is held by instructors who are actually data scientists. We can guide and we can show what’s important on a day-to-day basis on a data science job, what’s less important, what you need focus on. This is the experience that we are trying to provide. The way we designed [the boot camp] is completely around projects. The structure is there are interactive lectures on theory in the morning, and most of the time in the afternoon is spent working on the current project. It’s kind of like you were hired as a data scientist and these are the projects you have to finish for your job. At the end of a boot camp, it is almost like you already had three months of job experience. Also, because you are going through actual projects and completing the actual data science project you build up your portfolio during the boot camp. When you graduate at the end of the 12 weeks, you basically have a whole bunch of evidence to show your skills. In terms of background, data science definitely encompasses statistics and coding. So if you’re a data scientist, you know how to program. You don’t need to be a software engineer or [be able to] to program like an app developer, but you need to know how to program. And you need to have knowledge of statistical analytics. People have different strengths and weaknesses, so when I say statistical analytics, that [encompasses] a lot. Some people have way more experience with machine learning; others have way more experience with regression analysis and correlation hypothesis testing, and again people have different levels of programming. Nobody knows everything. Also, I would say character properties are important. I think grit, curiosity and creativity are all very important character traits for a data scientist. A lot of the job is about confidence, being able to tackle completely new problems and adapting to things that you don’t know yet. Curiosity is definitely needed to motivate you to continuously keep attacking a problem. And creativity [is important] because a lot of data science is also about the design of the problem. As I mentioned, data science is the rotating of information, taking all the information in that data and making it understandable by humans to make decisions. The most important part is framing questions to answer and figuring out exactly what questions and what type of answer will help. That requires a lot of iterative design, continuously thinking about looking at the problem from different angles; and that takes creativity. I don’t mean creativity as in an artist’s creativity or an author’s creativity, but in terms of being able to come up with new ways of looking at the data again and again. I think a very important question that a lot of potential data scientists have is about how to take it on. Where do I start? What do I do? There are three main routes: online courses, master’s programs and boot camps. All have different advantages and disadvantages [[http://datascopeanalytics.com/what-we-think/2014/08/04/how-do-i-become-a-data-scientist-an-evaluation-of-3-alternatives]]. I obviously am a big fan of boot camps because I think that the balance of in-person lectures and real job experience with actual data scientists, having a job portfolio and having placement managers to help you find a job is the perfect storm. But for people who have time to spend in a more intensive master’s program, or other people who don’t have the time to commit three months of their time or the tuition for a boot camp, the massive open online courses are a good option. I [recommend that people] look into these three different options more closely and choose the one that fits them the best.},
}

@article{argamon_myth_2014,
	chapter = {News},
	title = {The {Myth} of the {Mythical} {Unicorn}},
	copyright = {© 2014 Information Management and SourceMedia, Inc. All rights reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=INFOM00020140522ea5m00002&cat=a&ep=ASE},
	abstract = {Many have claimed recently that multifaceted data scientists are mythical beings, as impossible to find as unicorns. This itself is a myth, and a dangerous one at that. Hype is cyclic. A new idea excites people, exaggerated claims are made (and often believed), and the idea takes on bigger-than-life proportions. Eventually, however, reality sets in, and a critical backlash begins. There is a strong tendency to take the criticism seriously, much more than the initial hype. However, just as the goodness of the original idea ballooned wildly during the boom, the critique gets overstated significantly during the bust. The clear-eyed observer will avoid getting taken in by either of these sides of the hype cycle and move quickly to the “plateau of productivity,” but it is hard to see through the smoke and mirrors.},
	language = {English},
	urldate = {2020-08-28},
	journal = {Information Management},
	author = {Argamon, Shlomo},
	month = may,
	year = {2014},
	note = {Publisher: SourceMedia, Inc.
Volume: Vol.1, No.1},
	annote = {So it is in data science. The well-documented need for data scientists, the “sexiest” new profession, led initially to a flurry of discussion of what constitutes a good data scientist, such descriptions often describing lofty and powerful multidisciplinary superheroes. The pushback inevitably soon arrived, with experts and pundits declaring that data scientists are mythical “unicorns,” and that companies should forget about them and focus instead on building teams of traditional experts (statisticians, operations researchers, software engineers and such) to do data science. Or as the parody Twitter account Big Data Borat had it: Unicorn, Data Scientist and Santa Claus walk in bar. Bartender turn at Santa Claus and say "I must be hallucinate!"— Big Data Borat (@BigDataBorat) April 17, 2013 Unquestionably, strong and diverse teams of specialists in relevant areas have a key place in any organization’s data science strategy. But the idea that data scientists are as mythical as unicorns is simply false. Let us stipulate that “rock star” data scientists, who truly excel in all the important areas of data engineering, statistical modeling of complex data, building scalable software systems, and business analysis are in fact extremely rare. But it is not an all-or-nothing game. It is eminently possible to take people with expertise in one or more of these areas and teach them the fundamentals and key skills in the others to turn them into data scientists. This in fact what we at Illinois Institute of Technology are now doing in our Master of Data Science program, as are many other universities in similar programs. The point is that “data scientist” is not merely a new name for “people with deep analytical skills,” as some would have it, but rather a designation for people that have, in addition to analytical skills, broad knowledge of the diverse areas relevant to dealing with complex real-world data science problems. Dealing with the size, speed, diversity and complexity of modern data sets requires much more than statistical analytical expertise and off-the-shelf software tools – a data scientist must know about data representation, software engineering, visual design, and business processes, as well as being able to tell the “story of the data” based on rigorously quantitative analysis results. This ideal “well-rounded” data scientist is not an omnipotent “unicorn” whose existence is mere fable, but rather a serious professional who understands the full lifecycle of a data science problem and also has deeper skill and expertise in one or several specific aspects of data science. That is, there are many kinds of data scientists. One may be best at structuring and cleaning ill-formed data, putting it into a uniform structure that can be effectively analyzed; another may be expert at building statistical models; and a third may have strong skills in developing high-performance software systems for data analysis. But all of them will understand the need for data normalization, the assumptions made by different statistical methods, and the tradeoffs inherent in developing scalable data processing systems, as well as how to learn quickly about a business problem, formulate it as a data science task, and communicate results effectively to decision-makers. These data scientists may not have the superhuman productivity or impact of a “rock star,” if you can even find one of those, but they are indispensable to developing strong data science efforts, even those based on multidisciplinary teams. As anyone who has tried to build a team out of such disparate professionals as statisticians, software engineers, business analysts and communications specialists knows, it is incredibly difficult to bridge the cultural and linguistic gaps between them and fashion a cohesive group that works effectively together. The data scientist knows how to think and speak as a statistician, as a software engineer, as a business analyst, as a communication specialist, and so can bridge these gaps and ensure a smooth data science process. In fact, such a team is likely to perform best when most of its members are data scientists, with just a few deep specialists involved. Recall that every data scientist will have some area of particular focus and so several can together form a diversified team to attack complex data science problems. But since they all understand the rest of the teams’ areas of focus from the inside, they will better be able to work together, critique their shared work, and produce a coherent analysis – the last of which is critical to data science success. Additionally, many smaller organizations lack the substantial resources (easily \$1M per year) to hire and support an interdisciplinary data science team. Such organizations might outsource their data analytics to one of a growing number of data science consulting firms, but would still significantly benefit from an internal data science generalist to coordinate the data science work and advise management on its proper application. The risk is that the loss of this individual might derail your data science efforts, but it can be mitigated by both ensuring proper documentation to aid continuity and designing a career development path for the position to increase its attractiveness. You should not believe the fantasy that data scientists are mythical, and should definitely not neglect developing data science capabilities. It is hard to imagine any organization today that would not benefit from a serious data science program. And the easiest and best way to field such an effort is to find real data scientists to create it. Not unicorns, not superheroes, but data scientists. They are no myth – they walk the earth today, their numbers are growing, and we all need them.},
}

@article{noauthor_booz_2014,
	title = {Booz {Allen} {Hamilton} and {Kaggle} {Launch} {Inaugural} {National} {Data} {Science} {Bowl}},
	copyright = {(c) 2014 Business Wire. All Rights Reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=BWR0000020141215eacf0007f&cat=a&ep=ASE},
	abstract = {Competition will challenge participants to use data science to affect change on a global scale MCLEAN, Va.--(BUSINESS WIRE)--December 15, 2014--},
	language = {English},
	urldate = {2020-08-28},
	journal = {Business Wire},
	month = dec,
	year = {2014},
	note = {Publisher: Business Wire, Inc.},
	keywords = {Accounting/Consulting, Booz Allen Hamilton Holding Corp., Business Consultancy, Business/Consumer Services, Management Consulting, The Carlyle Group},
	annote = {Booz Allen Hamilton, the management and technology consulting firm, and Kaggle, the leading online data science competition community, today announced the launch of the inaugural National Data Science Bowl. A 90-day competition, the National Data Science Bowl will provide the data science community with an opportunity to utilize its skills and training to create impact on a global scale. Specifically, in this inaugural competition, participants will develop complex algorithms to advance the study of ocean health, the result of which will generate an estimated one million dollar 'in-kind' donation of analytics research to the Hatfield Marine Science Center at Oregon State University. Booz Allen Hamilton and Kaggle will also award a total of \$175,000 to the top three algorithms' creators and the leading university team; the largest purse, to date, for a Kaggle competition benefitting social good. "The National Data Science Bowl was born from the realization that, in order for the data science community to grow and thrive, it must be given opportunities to use its talents to benefit both business and society," said Booz Allen Hamilton's Josh Sullivan, a vice president in the firm's Strategic Innovation Group. "We are extremely honored to partner with leaders such as Kaggle and the Hatfield Marine Science Center at Oregon State for this initiative and believe its findings will be a testament to the role data science can -- and should -- play in solving previously impossible challenges moving forward." The competition will task participants with examining nearly 100,000 underwater images to develop an algorithm that will enable researchers to identify and monitor planktonic organisms at a speed and scale never before possible. Extremely susceptible to changes in temperature and chemistry, a large and thriving plankton population is crucial for driving some of the planet's most life-sustaining processes. These organisms produce much of the world's oxygen and absorb a large percentage of carbon dioxide from the atmosphere every year, while serving as the foundation for all marine and many terrestrial food chains. Rapid assessment of their populations will therefore allow the scientific community to monitor ocean health at an unprecedented scale, an important step forward in understanding and protecting the environment. "This partnership allows us to leverage a project funded by the National Science Foundation into a much larger product that will extend the capabilities of the ocean science community to rapidly assess key biological metrics of ocean conditions," said Hatfield Marine Science Center Director Bob Cowen. "The algorithms resulting from this competition will be applied to millions of images taken in a variety of marine environments, allowing cross-comparison and analysis at an unprecedented scale of detail and coverage." The National Data Science Bowl is part of Booz Allen Hamilton's ongoing commitment to supporting data science education and awareness, evidenced by its recently launched Explore Data Science training program and Field Guide to Data Science. By partnering with Kaggle, the firm is further providing data science practitioners -- from experts to novices -- with the opportunity to refine and expand their analytics expertise; all while advancing critical environmental research. Kaggle Founder and CEO Anthony Goldbloom said, "We're thrilled to be partnering with Booz Allen Hamilton and the Hatfield Marine Science Center to bring this impressive challenge to our community. With over 100 categories of marine life appearing in any orientation, this problem is pushing the boundaries of what is possible with image classification. This is an opportunity for data scientists around the world to have a real impact on the health of our oceans." For more information on the competition as well as Booz Allen Hamilton and Kaggle's support of the data science community, please visit www.datasciencebowl.com. About Booz Allen Hamilton Booz Allen Hamilton is a leading provider of management consulting, technology, and engineering services to the US government in defense, intelligence, and civil markets, and to major corporations and not-for-profit organizations. Booz Allen is headquartered in McLean, Virginia, employs more than 22,000 people, and had revenue of \$5.48 billion for the 12 months ended March 31, 2014. In 2014, Booz Allen celebrates its 100th anniversary year. To learn more, visit www.boozallen.com. (NYSE:BAH) About Kaggle Kaggle is the leading platform for developing highly sophisticated predictive models and recruiting top data science talent. Through its competitions, Kaggle has built the world's largest community of data scientists, with over 40,000 active participants. They compete with each other to solve complex data science problems, and the top competitors are invited to work on the most interesting and sensitive business problems from some of the world's largest companies. About the Hatfield Marine Science Center at Oregon State University The Hatfield Marine Science Center is a research and teaching facility of Oregon State University that is located in Newport, Oregon, on the Yaquina Bay estuary -- immediately adjacent to the open waters of the Pacific Ocean. It plays an integral role in programs of marine and estuarine research and instruction; as a laboratory serving resident scientists, as a base for far-ranging oceanographic studies and as a classroom for students. BAHPR--CO Photos/Multimedia Gallery Available: http://www.businesswire.com/multimedia/home/20141215005253/en/},
}

@article{noauthor_booz_2013-1,
	title = {Booz {Allen} {Hamilton} {Maps} the {DNA} of {Data} {Science} with {Release} of {The} {Field} {Guide} to {Data} {Science}},
	copyright = {(c) 2013, Electronic News Publishing. All Rights Reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=ENPNEW0020131107e9b7000d3&cat=a&ep=ASE},
	abstract = {Release date - 06112013 McLean, Virginia - A commercial airline facing increased market competition leveraged ‘big data’ analytical tools and machine learning on terabytes of data to better serve its most frequent fliers and priority passengers and to improve financial performance.},
	language = {English},
	urldate = {2020-08-28},
	journal = {ENP Newswire},
	month = nov,
	year = {2013},
	note = {Publisher: Electronic News Publishing Ltd.},
	keywords = {Accounting/Consulting, Booz Allen Hamilton Holding Corp., Business Consultancy, Business/Consumer Services, Management Consulting, The Carlyle Group},
	annote = {This is one example in today’s increasingly complex world, where data - no matter its form, shape or size - is omnipresent and can be used for competitive edge. Leaders at organizations of all shapes and sizes are doing their best to figure out how to turn that data into a resource. They are looking for answers in a new, growing field - data science.
Working to spur awareness of and best practices in data science, Booz Allen Hamilton (NYSE:BAH), a leading provider of management consulting, technology and engineering services, today released The Field Guide to Data Science. The Guide taps into the diverse, collective expertise of the firm’s data science team and offers insight into how organizations can navigate the data science waters to capture revenue-driving and mission-enabling insights for the business, a process Booz Allen Hamilton refers to as ‘Cloud EBITDA’.
The guide offers readers a look into
Data Science 101 - what is data science and how does it work, what it takes to set up a data science team and how to refine capabilities
The Nuances of Data Science - various principles, parts and models to be incorporated into a data science strategy
A Deep Dive - the more technical side of managing and analyzing data
Success - case studies and examples of work that Booz Allen Hamilton has completed as a partner to clients
‘Our hope is that The Field Guide to Data Science will serve as a resource to help pioneer the data science community as the field continues to evolve and grow, particularly at the university level where data science degrees will soon be the norm,’ said Booz Allen Hamilton vice president and data scientist, Dr. Joshua Sullivan. ‘Our team of data science experts are entrenched in the nuances of this field and have so much to offer; however, we also realize that there is enormous potential to tap into the data science community and provide them with the opportunity to contribute and create an industry wide set of best practices.’
The Guide, a living document, is available via the Booz Allen Hamilton website. It will be open for user generated submissions; interested, qualified parties are invited to email ideas and perspectives or submit content via a pull request on the GitHub repository.
For more information about Booz Allen Hamilton and The Field Guide to Data Science, follow us on Twitter:
Booz Allen Hamilton @boozallen
Josh Sullivan @joshdsullivan
Peter Guerra @petrguerra
Mark Herman @CloudEBITDA
About Booz Allen Hamilton
Booz Allen Hamilton is a leading provider of management consulting, technology, and engineering services to the U.S. government in defense, intelligence, and civil markets, and to major corporations, institutions, and not-for-profit organizations. Booz Allen is headquartered in McLean, Virginia, employs more than 23,000 people, and had revenue of \$5.76 billion for the 12 months ended March 31, 2013.
Media Contact
Carrie Lake 703-377-7785, Lake\_Carrie@bah.com
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk]},
}

@article{noauthor_big_2013,
	title = {Big {Data} {Career} {Switch}: 4 {Key} {Points}},
	copyright = {Copyright ©2013 United Business Media LLC. All rights reserved.},
	shorttitle = {Big {Data} {Career} {Switch}},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=CMPT000020130718e97h0002t&cat=a&ep=ASE},
	abstract = {The U.S. has an employment problem. There are too many jobs and not enough workers … in data science. You've probably seen the headlines: Data Scientist: The Sexiest Job of the 21st Century, In a Data Deluge, Companies Seek to Fill a New Role, Geeks Wanted -- Big Data Firms Push Data Scientist Development.},
	language = {English},
	urldate = {2020-08-28},
	journal = {CMP TechWeb},
	month = jul,
	year = {2013},
	note = {Publisher: CMP Media LLC},
	annote = {But if you graduated from college more than five years ago and you're not in a data science position right now, you probably don't have the skills that are required to apply for most of these positions. "Fair enough," I hear you saying. "I can retool my skillset … there are lots of programs in data science to choose from." Yes, but… [ Check out these one- and two-year graduate programs in data analytics. Big Data Analytics Master's Degrees: 20 Top Programs. ] Less than a year ago, I wrote in this publication that universities needed to pivot to better meet the needs of the market. Specifically, a year ago, you would have been hard-pressed to find a university curriculum aligned with data science. Today the educational landscape looks very different. With this shifting landscape, there's good news and bad news. First, the good news: Some very strong university (and non-university) programs have partnered with organizations native to big data and to data science and are bringing practical, real skills into the classroom. (Perhaps those universities read my article.) These programs have risen to the top and produce highly sought-after graduates. And they're constantly getting better as we learn how to tame the issues related to big data and bring these insights into the classroom. Some leading programs include Stanford, NC State, Texas A\&M, Kennesaw State University, Oklahoma State University, Arizona State University and Central Florida, to name just a few. The bad news? Some educational institutions are misrepresenting their curricula as data science. Most are doing so inadvertently, because they don't appreciate how different the discipline is from anything that has historically come from universities. Regardless, not all data science programs are created equal. A lot of programs out there are posing as data science but are not. Here are a few important points to ponder as you consider pursuing a degree in data science: Content. What is data science? The definition is still a slightly moving target, but most practitioners cite a few common characteristics: a strong grounding in mathematics; a familiarity with programming languages; a working knowledge of analytical modeling; and some area content knowledge -- all combined with an innate sense of curiosity. (As an academic, I am still struggling with how to teach people to become curious, because it is so important.) The fact that all these characteristics should be present in some form in any program using the label of "data science" explains why so many MBAs are having difficulty finding positions. About a quarter of the people who apply to our MS program in Applied Statistics already have an MBA, but no job. Partnerships with native organizations. Let's be honest -- there are no professors of data science. No matter what we say or how we try to spin our degrees, no one with a Ph.D. teaching in a university today is a professor of data science. The concepts and the discipline are too new and have come upon us too quickly. Unless you are a professor who has had 1 1/2 feet in an organization that is native to big data and to data science over the last three years (and there are a few), you'll be hard-pressed to truly teach data science. That's why the best programs out there -- including those listed above -- have strong partnerships with companies who are living the challenges of big data and, in many cases, are growing their own data scientists. The best university programs have recognized their limitations in this space and have partnered with local professionals to come into the classroom and speak to the challenges and the real problems that are all part of working with big data. Online versus traditional. There are more online data science programs than traditional university ones. Online programs serve an important educational role, and some of them are excellent. Online programs can also be synchronous -- meaning that the sessions are scheduled and live -- or asynchronous -- meaning that the sessions are pre-recorded and can be experienced on demand. While the on-demand option is certainly the most convenient, it also requires the most self-discipline. For people who have been working in an analytical capacity and need to pick up skills in Hadoop, for example, an online program probably makes sense. However, people coming to data science for the first time, from a less analytical position, would likely benefit from the direct contact with practitioners and with other students in the classroom. Application. In his brilliant Last Lecture, the late Dr. Randy Pausch described his first iteration of the curriculum for the MS in Entertainment Technology at Carnegie Mellon basically as all applied projects. Although the university required Dr. Pausch to incorporate some "real" classes, the popular degree program has maintained its very strong application orientation -- students spend 90\% of their time in hands-on applied projects. Data science is, by definition, applied. It has to be. Therefore, any program representing itself as data science should have a strong applied -- as opposed to a theoretical -- orientation. And again, the best programs have co-ops and internships with companies that represent the front line of learning what working with big, messy data is all about. Dr. Jennifer Priestley is an associate professor of statistics at Kennesaw State University, where she is the director of the Center for Statistics and Analytical Services. She also oversees the undergraduate curriculum in statistics and was recognized by the SAS Institute as the 2012 Distinguished Statistics Professor of the Year. She served as the co-chair of the 2012 National Analytics Conference in Las Vegas, NV.},
}

@article{wladawsky-berger_why_2014-1,
	title = {Why {Do} {We} {Need} {Data} {Science} {When} {We}'ve {Had} {Statistics} for {Centuries}? -- {WSJ} {Blog}},
	copyright = {Copyright © 2014, Dow Jones \& Company, Inc.},
	shorttitle = {Why {Do} {We} {Need} {Data} {Science} {When} {We}'ve {Had} {Statistics} for {Centuries}?},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=DJDN000020140502ea52002l5&cat=a&ep=ASE},
	abstract = {Data Science is emerging as one of the hottest new professions and academic disciplines in these early years of the 21st century. A number of articles have noted that the demand for data scientists is racing ahead of supply. People with the necessary skills are scarce, primarily because the discipline is so new. But, the situation is rapidly changing, as universities around the world have started to offer different kinds of graduate programs in data science. This year, for example, New York University is offering two new degrees--a general Master in Data Science, and a more domain-specific Master in Applied Urban Science and Informatics.},
	language = {English},
	urldate = {2020-08-28},
	journal = {Dow Jones Institutional News},
	author = {Wladawsky-Berger, Irving},
	month = may,
	year = {2014},
	note = {Publisher: Dow Jones \& Company, Inc.},
	keywords = {Computers/Electronics, Technology, Computing, International Business Machines Corp.},
	annote = {It's very exciting to contemplate the emergence of a major new discipline. It reminds me of the advent of computer science in the 1960s and 1970s. Like data science, computer science had its roots in a number of related areas, including math, engineering and management. In its early years, the field attracted people from a variety of other disciplines who started out using computers in their work or studies, and eventually switched to computer science from their original field.
This was the case with me. I used computers extensively while a student at the University of Chicago, where I worked closely with Prof. Clemens Roothaan, one of the pioneers in the use of computers in physics and chemistry. As an undergraduate, I worked part-time at the university's supercomputing center which he founded. Later he was my thesis advisor as a graduate student in physics. When the time came to look for a job, I realized that I enjoyed the computing side of my work more than the physics. I decided to switch fields and in 1970 joined the computer science department at IBM's Watson Research Center.
Not unlike data science today, computing had to overcome the initial resistance of some prominent academics. I still remember a meeting in 1965 with a very eminent physicist from whom I was taking a graduate course. He asked me what I planned to do research on for my degree, and I told him that I was already working with Prof. Roothaan on atomic and molecular calculations. He just said that good theoretical physics should require no more than pencil and paper, rather than these elaborate new computers. In his mind, this wasn't real physics. A number of the physics faculty felt the same way. Change does not come easy, even for brilliant physicists.
Computer science has since become a well respected academic discipline. It has grown extensively since its early days and expanded in many new directions. It's quite possible that being around in the early days of computer science and computing in general is part of the reason I'm so interested in the evolution of data science today. So, what is data science all about? One of the best papers on the subject is Data Science and Prediction by Vasant Dhar, professor in NYU's Stern School of Business and Director of NYU's Center for Business Analytics. The paper was published in the Communications of the ACM in December 2013. "Use of the term data science is increasingly common, as is big data," Mr. Dhar writes in the opening paragraph. "But what does it mean? Is there something unique about it? What skills do data scientists need to be productive in a world deluged by data? What are the implications for scientific inquiry?"
He defines data science as being essentially the systematic study of the extraction of knowledge from data. But analyzing data is something people have been doing with statistics and related methods for a while. "Why then do we need a new term like data science when we have had statistics for centuries? The fact that we now have huge amounts of data should not in and of itself justify the need for a new term."
In short, it's all about the difference between explaining and predicting. Data analysis has been generally used as a way of explaining some phenomenon by extracting interesting patterns from individual data sets with well-formulated queries. Data science, on the other hand, aims to discover and extract actionable knowledge from the data, that is, knowledge that can be used to make decisions and predictions, not just to explain what's going on.
The raw materials of data science are not independent data sets, no matter how large they are, but heterogeneous, unstructured data set of all kinds - text, images, video. The data scientist will not simply analyze the data, but will look at it from many angles, with the hope of discovering new insights.
One of the problems with conducting such an in-depth, exploratory analysis is that the multiple data sets that are typically required to do so are often found within organizational silos; be they different lines of business in a company, different companies in an industry or different institutions across society at large. Data science platforms and tools aim to address this problem by working with, linking together and analyzing data sets previously locked away in disparate silos.
"Unlike database querying, which asks What data satisfies this pattern (query)? discovery asks What patterns satisfy this data?," notes Mr. Dhar. "Specifically, our concern is finding interesting and robust patterns that satisfy the data, where interesting is usually something unexpected and actionable and robust is a pattern expected to occur in the future."
The article discusses the key skills data scientists should have, starting with machine learning, a complex concept which Mr. Dhar explains in a particularly simple way.
"Most of us are trained to believe theory must originate in the human mind based on prior theory, with data then gathered to demonstrate the validity of the theory. Machine learning turns this process around. Given a large trove of data, the computer taunts us by saying, If only you knew what question to ask me, I would give you some very interesting answers based on the data. Such a capability is powerful since we often do not know what question to ask. . ."
"Suitably designed machine learning algorithms help find such patterns for us. To be useful both practically and scientifically, the patterns must be predictive. The emphasis on predictability typically favors Occam's razor, or succinctness, since simpler models are more likely to hold up on future observations than more complex ones, all else being equal. . ."
Data scientists should also have good computer science skills--including data structures, algorithms, systems and scripting languages--as well as a good understanding of correlation, causation and related concepts which are central to modeling exercises involving data.
"The final skill set is the least standardized and somewhat elusive and to some extent a craft but also a key differentiator to be an effective data scientist - the ability to formulate problems in a way that results in effective solutions. . . formulation expertise involves the ability to see commonalities across very different problems . . ."
Like computing, one of the most exciting part of data science is that it can be applied to many domains of knowledge. But doing so effectively requires domain expertise to identify the important problems to solve in a given area, the kinds of questions we should be asking and the kinds of answers we should be looking for, as well as how to best present whatever insights are discovered so they can be understood by domain practitioners in their own terms. Garbage-in, garbage-out, a phrase I often heard in the early days of computing, is just as applicable to data science today.
Physics, chemistry, biology and other natural science disciplines have long been practicing their own version of data science. In physics, for example, "a theory is expected to be complete in the sense a relationship among certain variables is intended to explain the phenomenon completely, with no exceptions. . . In such domains, the explanatory and predictive models are synonymous."
But given our newfound ability to gather valuable data on almost any topic, prediction can now apply to softer disciplines like the health and social sciences. Mr. Dhar points out that while these fields generally lack solid theories, "large amounts of data can result in accurate predictive models, even though no causal insights are immediately apparent. As long as their prediction errors are small, they could still point us in the right direction for theory development."
Finally, beyond access to the appropriate skills, are there cultural and management implications in embracing data science in the business world?
"Besides recognizing and nurturing the appropriate skill sets, it requires a shift in managers' mind-sets toward data-driven decision making to replace or augment intuition and past practices. A famous quote by 20th-century American statistician W. Edwards Demming - In God we trust, everyone else please bring data - has come to characterize the new orientation, from intuition-based decision making to fact-based decision making. . . It is suddenly possible to test many of their established intuitions, experiment cheaply and accurately, and base decisions on data. This opportunity requires a fundamental shift in organizational culture, one seen in organizations that have embraced the emerging world of data for decision making."
Irving Wladawsky-Berger is a former vice-president of technical strategy and innovation at IBM. He is a strategic advisor to Citigroup and is a regular contributor to CIO Journal.
 
 More at The Wall Street Journal's CIO Report blog, http://blogs.wsj.com/cio/
 
(END) Dow Jones Newswires
May 02, 2014 11:47 ET (15:47 GMT)},
	annote = {



Why Do We Need Data Science When We've Had Statistics for Centuries? -- WSJ Blog
By Irving Wladawsky-Berger
1602 words
2 May 2014
11:47
Dow Jones Institutional News
DJDN
English
Copyright © 2014, Dow Jones \& Company, Inc.
 
Data Science is emerging as one of the hottest new professions and academic disciplines in these early years of the 21st century. A number of articles have noted that the demand for data scientists is racing ahead of supply. People with the necessary skills are scarce, primarily because the discipline is so new. But, the situation is rapidly changing, as universities around the world have started to offer different kinds of graduate programs in data science. This year, for example, New York University is offering two new degrees--a general Master in Data Science, and a more domain-specific Master in Applied Urban Science and Informatics.
It's very exciting to contemplate the emergence of a major new discipline. It reminds me of the advent of computer science in the 1960s and 1970s. Like data science, computer science had its roots in a number of related areas, including math, engineering and management. In its early years, the field attracted people from a variety of other disciplines who started out using computers in their work or studies, and eventually switched to computer science from their original field.
This was the case with me. I used computers extensively while a student at the University of Chicago, where I worked closely with Prof. Clemens Roothaan, one of the pioneers in the use of computers in physics and chemistry. As an undergraduate, I worked part-time at the university's supercomputing center which he founded. Later he was my thesis advisor as a graduate student in physics. When the time came to look for a job, I realized that I enjoyed the computing side of my work more than the physics. I decided to switch fields and in 1970 joined the computer science department at IBM's Watson Research Center.
Not unlike data science today, computing had to overcome the initial resistance of some prominent academics. I still remember a meeting in 1965 with a very eminent physicist from whom I was taking a graduate course. He asked me what I planned to do research on for my degree, and I told him that I was already working with Prof. Roothaan on atomic and molecular calculations. He just said that good theoretical physics should require no more than pencil and paper, rather than these elaborate new computers. In his mind, this wasn't real physics. A number of the physics faculty felt the same way. Change does not come easy, even for brilliant physicists.
Computer science has since become a well respected academic discipline. It has grown extensively since its early days and expanded in many new directions. It's quite possible that being around in the early days of computer science and computing in general is part of the reason I'm so interested in the evolution of data science today. So, what is data science all about? One of the best papers on the subject is Data Science and Prediction by Vasant Dhar, professor in NYU's Stern School of Business and Director of NYU's Center for Business Analytics. The paper was published in the Communications of the ACM in December 2013. "Use of the term data science is increasingly common, as is big data," Mr. Dhar writes in the opening paragraph. "But what does it mean? Is there something unique about it? What skills do data scientists need to be productive in a world deluged by data? What are the implications for scientific inquiry?"
He defines data science as being essentially the systematic study of the extraction of knowledge from data. But analyzing data is something people have been doing with statistics and related methods for a while. "Why then do we need a new term like data science when we have had statistics for centuries? The fact that we now have huge amounts of data should not in and of itself justify the need for a new term."
In short, it's all about the difference between explaining and predicting. Data analysis has been generally used as a way of explaining some phenomenon by extracting interesting patterns from individual data sets with well-formulated queries. Data science, on the other hand, aims to discover and extract actionable knowledge from the data, that is, knowledge that can be used to make decisions and predictions, not just to explain what's going on.
The raw materials of data science are not independent data sets, no matter how large they are, but heterogeneous, unstructured data set of all kinds - text, images, video. The data scientist will not simply analyze the data, but will look at it from many angles, with the hope of discovering new insights.
One of the problems with conducting such an in-depth, exploratory analysis is that the multiple data sets that are typically required to do so are often found within organizational silos; be they different lines of business in a company, different companies in an industry or different institutions across society at large. Data science platforms and tools aim to address this problem by working with, linking together and analyzing data sets previously locked away in disparate silos.
"Unlike database querying, which asks What data satisfies this pattern (query)? discovery asks What patterns satisfy this data?," notes Mr. Dhar. "Specifically, our concern is finding interesting and robust patterns that satisfy the data, where interesting is usually something unexpected and actionable and robust is a pattern expected to occur in the future."
The article discusses the key skills data scientists should have, starting with machine learning, a complex concept which Mr. Dhar explains in a particularly simple way.
"Most of us are trained to believe theory must originate in the human mind based on prior theory, with data then gathered to demonstrate the validity of the theory. Machine learning turns this process around. Given a large trove of data, the computer taunts us by saying, If only you knew what question to ask me, I would give you some very interesting answers based on the data. Such a capability is powerful since we often do not know what question to ask. . ."
"Suitably designed machine learning algorithms help find such patterns for us. To be useful both practically and scientifically, the patterns must be predictive. The emphasis on predictability typically favors Occam's razor, or succinctness, since simpler models are more likely to hold up on future observations than more complex ones, all else being equal. . ."
Data scientists should also have good computer science skills--including data structures, algorithms, systems and scripting languages--as well as a good understanding of correlation, causation and related concepts which are central to modeling exercises involving data.
"The final skill set is the least standardized and somewhat elusive and to some extent a craft but also a key differentiator to be an effective data scientist - the ability to formulate problems in a way that results in effective solutions. . . formulation expertise involves the ability to see commonalities across very different problems . . ."
Like computing, one of the most exciting part of data science is that it can be applied to many domains of knowledge. But doing so effectively requires domain expertise to identify the important problems to solve in a given area, the kinds of questions we should be asking and the kinds of answers we should be looking for, as well as how to best present whatever insights are discovered so they can be understood by domain practitioners in their own terms. Garbage-in, garbage-out, a phrase I often heard in the early days of computing, is just as applicable to data science today.
Physics, chemistry, biology and other natural science disciplines have long been practicing their own version of data science. In physics, for example, "a theory is expected to be complete in the sense a relationship among certain variables is intended to explain the phenomenon completely, with no exceptions. . . In such domains, the explanatory and predictive models are synonymous."
But given our newfound ability to gather valuable data on almost any topic, prediction can now apply to softer disciplines like the health and social sciences. Mr. Dhar points out that while these fields generally lack solid theories, "large amounts of data can result in accurate predictive models, even though no causal insights are immediately apparent. As long as their prediction errors are small, they could still point us in the right direction for theory development."
Finally, beyond access to the appropriate skills, are there cultural and management implications in embracing data science in the business world?
"Besides recognizing and nurturing the appropriate skill sets, it requires a shift in managers' mind-sets toward data-driven decision making to replace or augment intuition and past practices. A famous quote by 20th-century American statistician W. Edwards Demming - In God we trust, everyone else please bring data - has come to characterize the new orientation, from intuition-based decision making to fact-based decision making. . . It is suddenly possible to test many of their established intuitions, experiment cheaply and accurately, and base decisions on data. This opportunity requires a fundamental shift in organizational culture, one seen in organizations that have embraced the emerging world of data for decision making."
Irving Wladawsky-Berger is a former vice-president of technical strategy and innovation at IBM. He is a strategic advisor to Citigroup and is a regular contributor to CIO Journal.
 
 
 More at The Wall Street Journal's CIO Report blog, http://blogs.wsj.com/cio/
 
(END) Dow Jones Newswires
May 02, 2014 11:47 ET (15:47 GMT)
Dow Jones \& Company, Inc.
Document DJDN000020140502ea52002l5




UI Ver:32.5.0 Mod:15:09 ID:AWSPFWAUTH09},
}

@article{noauthor_booz_2014-1,
	title = {Booz {Allen} {Hamilton} {Launches} {Explore} {Data} {Science} to {Address} {Rapidly} {Growing} {Shortage} of {Data} {Scientists}},
	copyright = {(c) 2014, Electronic News Publishing. All Rights Reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=ENPNEW0020141016eaag000c6&cat=a&ep=ASE},
	abstract = {Release date - 15102014 McLean, VA - Booz Allen Hamilton today announced the release of its Explore Data Science online training program, a self-paced, hands-on course geared toward all levels of data science proficiency - from introductory to professional.},
	language = {English},
	urldate = {2020-08-28},
	journal = {ENP Newswire},
	month = oct,
	year = {2014},
	note = {Publisher: Electronic News Publishing Ltd.},
	keywords = {Accounting/Consulting, Booz Allen Hamilton Holding Corp., Business Consultancy, Business/Consumer Services, Management Consulting, The Carlyle Group},
	annote = {With more than 40 hours of content available to users, the program features galactic-themed gamification elements that teach common data science principles while guiding students through increasingly advanced, scenario-based challenges.
Faced with 32 distinct ‘missions,’ users with basic proficiencies in programming are able to transform raw information into business-critical insights and when a level is successfully completed, participants earn points, awards and badges that are shareable on social media. More importantly, however, successfully finishing missions allows users to develop or increase competency in the core tenets of data science.
For example, analyzing a densely forested planet’s wildlife to identify the most dangerous plants and animals introduces players to data organization techniques as well as algorithms for pattern learning - integral tools for improving business outcomes.
Explore Data Science is the latest effort on behalf of Booz Allen Hamilton to support data science education and awareness. In 2013, the firm launched its Field Guide to Data Science, an industry resource of best practices. The new Explore Data Science training program complements those teachings by enabling future, or current, data scientists to practice, test and grow their capabilities in a simulation-based environment. The techniques learned in the Explore Data Science training program can then be easily translated into daily business operations.
‘In today’s highly competitive marketplace, being able to effectively compile, manage and analyze data is critically important to a business’ growth, strategic development and overall success,’ said Booz Allen Hamilton’s Peter Guerra, a Principal in the firm’s Strategic Innovation Group. ‘We’re therefore seeing a clear demand - across all industries - for data science expertise, but it far exceeds the available supply of trained professionals. By introducing training like Explore Data Science, we’re providing companies and interested individuals with an invaluable resource while empowering an increasingly data-driven workforce.’
ABOUT BOOZ ALLEN HAMILTON
Booz Allen Hamilton is a leading provider of management consulting, technology, and engineering services to the US government in defense, intelligence, and civil markets, and to major corporations and not-for-profit organizations. Booz Allen is headquartered in McLean, Virginia, employs nearly 23,000 people, and had revenue of \$5.48 billion for the 12 months ended March 31, 2014. In 2014, Booz Allen celebrates its 100th anniversary year.
To learn more, visit www.boozallen.com
Media Contact:
Carrie Lake Tel: 703-377-7785 Email: Lake\_carrie@bah.com
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk]},
}

@article{noauthor_data_2013,
	title = {Data {Scientists} {Create} {Code} {Of} {Professional} {Conduct}},
	copyright = {Copyright ©2013 United Business Media LLC. All rights reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=CMPT000020131008e9a700031&cat=a&ep=ASE},
	abstract = {Concerned about big data's potential for misuse, a new organization of data scientists has created a set of rules for their profession. The Data Science Association is a non-profit organization with more than 500 members, even though it's only about 2 months old. Based in Denver, Colorado, its mission is to define the term "data science" and the duties and ethical responsibilities of the people who call themselves data scientists, according to founder and president Michael Walker.},
	language = {English},
	urldate = {2020-08-28},
	journal = {CMP TechWeb},
	month = oct,
	year = {2013},
	note = {Publisher: CMP Media LLC},
	annote = {"Things were really getting out of control in terms of the definition of 'data science,'" said Walker in a phone interview with InformationWeek . "A lot of people who really weren't data scientists started calling themselves data scientists. And I saw a lot of data science malpractice in the companies, or clients, that we work with." [ Looking to fast-track a career in data science? Read Become A Data Scientist … In 12 Weeks? ] Walker is a managing partner at Rose Business Technologies, a Denver-based provider of data management and IT services. He hopes the Data Science Association can help protect the integrity of his chosen profession, which he said is rife with under-qualified practitioners and big data vendors making false promises. "What's in short supply are trained data scientists to analyze and interpret and get that actionable, valuable intelligence [from data]," Walker said. In addition, many data science products don't deliver the insights they promise. "A lot of vendors are making outlandish claims," said Walker. "Spend hundreds of thousands, or millions, of dollars on our new technology, feed it with data, push a couple of buttons and -- voilà! -- you're going to get predictive analytics and a competitive advantage." The din is growing louder, he added, as more big data tools hit the market. "I can tell you, it's just malarkey. It doesn't work that way," said Walker. "It's actually very difficult to analyze data, especially large data sets, and use the scientific method in the right way to get valuable, actionable intelligence to help your company, or to help [government] policymakers make better policy." The Data Science Code of Professional Conduct covers both common-sense business practices and ethical guidelines, including a variety of rules that may prove challenging for data scientists -- and the companies and governments that hire them -- to follow. For instance, the Code of Professional Conduct states that if a data scientist "reasonably believes a client is misusing data science to communicate a false reality or promote an illusion of understanding, the data scientist shall take reasonable remedial measures, including disclosure to the client, and including, if necessary, disclosure to the proper authorities. The data scientist shall take reasonable measures to persuade the client to use data science appropriately." The above passage addresses the common problem of confirmation bias, where you only include data that confirms a particular position, and you ignore evidence of a contradictory position, Walker explained. "Say you have a data analytics team in a company, and your boss says, 'We need to be able to achieve XYZ goals,'" he added. "Or a policymaker might say, 'This is policy that we favor, go out and find the evidence to support it.'" These pressures, not surprisingly, often lead to very bad data science, a problem the Data Science Association hopes to combat. "We educate people on these issues, and [data science] becomes a profession that follows a code of conduct," said Walker. "All of us can band together and tell an employer or client, 'No, we cannot do that. I'm not going to find evidence to support something you want to do, unless [the supporting data] is really there.'" Without a professional code of ethics for data science, businesses and governments can easily exploit data scientists. Said Walker, "If you don't do what they want you to do, they'll fire you and get someone else." The big data market is not just about technologies and platforms -- it's about creating new opportunities and solving problems. The Big Data Conference provides three days of comprehensive content for business and technology professionals seeking to capitalize on the boom in data volume, variety and velocity. The Big Data Conference happens in Chicago, Oct. 22-23.},
}

@article{noauthor_drowning_2013,
	title = {Drowning in data: {NKU} creates new data science major},
	copyright = {© 2013, M2 Communications. All rights reserved.},
	shorttitle = {Drowning in data},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=UWIR000020130926e99p0006z&cat=a&ep=ASE},
	abstract = {Northern Kentucky University ; Highland Heights, KY - news By},
	language = {English},
	urldate = {2020-08-28},
	journal = {U-Wire},
	month = sep,
	year = {2013},
	note = {Publisher: Normans Media Ltd},
	annote = {NKU’s interdisciplinary programThe university’s launch of an undergraduate data science program is a “game changer” and “really big deal”, according to Cukier, data editor for The Economist and author of a book utilized in the first data science course.“Most people wouldn’t think of Kentucky as being the epicenter of big data,” Cukier said.He said it is “essential” that universities prepare to train students in data science and big data because the more NKU explores and develops this program, the more competitive the students will be as employees, and Kentucky will be as a state.Students going to a school with a cross disciplinary program will “have a leg up in the workforce, bring more value to their employers and have a more satisfying career because they are well-trained,” according to McGuffee.“We don’t envision it will ever be the largest per-student degree, but it’s going to be an extraordinarily prestigious. If not one of the most prestigious degrees at this university, if not in the entire commonwealth,” McGuffee said.To create a well-rounded program and data scientists in the end, the curriculum combines component mathematics and statistics skills, programming and machine learning, and specific subject matter expertise. The students are also studying the ethics of the field.Students are required to crunch the data by finding and exploring; to make sense of the information with machine learning and statistics; and explain the findings to others to make decisions. They are trained to use new technology and tools to decipher trillions of data points.The degree “emphasizes the critical arc that runs from data to information, information to knowledge, and knowledge to decision making,” according to the program’s website. Throughout the program, the curriculum works on building skills spanning the foundations of data science, statistical modeling, data mining, business analytics and scientific visualization.A principal part of the program is the capstone project, which requires students to collect, explore, communicate and interpret a big data set.The program will benefit the university through spin-off opportunities, such as collaborative student research projects and possibly a data science minor in the future, according to McGuffee.“I actually don’t think you can underestimate the impact this major is having on this university,” McGuffee said. Meet one of the first data science majorsThe data science program attracts students driven by curiosity, according to Kirby. He refers to these type of students as “detectives.” Students have to sort through trillions of data bytes coming at them fast and find a pattern or meaning in the information.The program seeks student detectives with a dedication to using new tools to discover hidden patterns buried in vast amount of data and communicating this information in compelling and effective ways, according to Kirby.Freshman Nathaniel Hudson is one of these curious students and one of the first data science majors. He describes himself as a “big nerd when it comes to computers.” He found the field after attending a program with Google over the summer.“Data science is one [field] our lecturer pushed more than anything else,” Hudson said. “It was kind of cool because I was sitting among the other people that got in. There were people going to Stanford, Princeton, Harvard, Carnegie Mellon and the like, and I was the only one that could say my school has a data science program.”Not everyone grasps how much data is being generated and stored by various corporations every day. In the United States, 15 out of 17 industry sectors have more data stored per company than the U.S. Library of Congress, according to the McKinsey Global Institute.However, data science majors begin to register its true volume and potential impact early on.“The one thing that will be intimidating, but its just because I don’t have the experience at the moment, is the idea of how big the data is,” Hudson said. “By the end of the major you are supposed to be able to take on I think petabytes [about 1,000 terabytes] of information.”The program will train students in everything from utilizing the information discovered in these enormous data sets to help businesses make decisions to building search engines.In the future, Hudson plans to work for one of the first major companies to analyze big data to make decisions: Google. ((Distributed for UWIRE via M2 Communications www.m2.com))},
}

@article{noauthor_data_2012,
	title = {Data {Science}},
	copyright = {(c) Computerwoche 2012},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=CPWCHE0020121026e8at00004&cat=a&ep=ASE},
	abstract = {Hadoop und NoSQL sind im Big-Data-Segment neben einer Vielzahl von Algorithmen bekannte Größen. Data Science gilt es zu entdecken. Big Data ist auf der Überholspur. Hadoop, NoSQL und eine Vielzahl von Algorithmen aus der künstlichen Intelligenz (KI) sind die neuen Stars der IT- und Business-Intelligence-Welt. Die von Gartner postulierten drei Vs - Volume, Velocity und Variety - dienen als wegweisende Aspekte einer mannigfaltigen und vielversprechenden "datenbetriebenen" Zukunft. Neben all diesen eher technischen und strategischen Aspekten des Big Data taucht ein weiterer Begriff immer häufiger im Kontext von Big Data auf: Data Science.},
	language = {German},
	urldate = {2020-08-28},
	journal = {Computerwoche},
	month = oct,
	year = {2012},
	note = {Publisher: IDG Communications Verlag AG},
	keywords = {Consumer Products, Cosmetics/Toiletries, Hair Care Products, Personal Care Products/Appliances},
	annote = {Schnittstellenkompetenz Hilary Mason, Chief Data Scientist bei bit.ly und Meister dieser neuen Disziplin, hat Data Science einmal als Schnittstellenkompetenz beschrieben. Data Science liegt da, wo Computerwissenschaften, Statistik und Mathematik, Ingenieurskunst und "Hacking", der neugierige, kreative Umgang mit Computern, Software und Algorithmen, zusammentreffen. Data Science ist ein multidisziplinärer Raum, in dem neue Ideen und Lösungen entstehen. Hilary Mason nennt die Menschen, die diesen Raum bewohnen, "awesome nerds" (zu Deutsch: fantastische Computerfreaks) oder, Business-tauglicher, "Data Scientists". Ursuppe der Entwicklung Wie schon öfter in der Vergangenheit ist das eigentlich Aufregende und Spannende an den aktuellen Entwicklungen, die sich hinter den Begriffen Big Data und Data Science verbergen, die Multidisziplinarität. Auf einmal kommen bis dato fachfremde Ideen, Theorien und Strömungen zusammen und bilden eine Art Ursuppe, in der ganz Neues entstehen kann. Für sich genommen ist vieles ein alter Hut. Die Algorithmen der künstlichen Intelligenz, die semantischen Analysen der Computerlinguistik, das Paradigma des "Parallel Computing" inklusive einer optimierten Verteilung von Rechenprozessen, spaltenorientierte Datenbanken - all dies hat auch schon vorher innerhalb einzelner Fachrichtungen existiert, teils seit Jahrzehnten. Aber auf einmal kommt alles zusammen. Die Grenzen verschwimmen, neue technische Entwicklungen werden von den großen "Datenfirmen" Yahoo, Google, Twitter oder Facebook als Open Source zur Verfügung gestellt, und der Data Scientist wird zum "heißesten" neuen Job der Big-Data-Ära erhoben. Endlich Antworten Data Science ist aber weit mehr als Technik, Statistik und künstliche Intelligenz. Dies sind nur die momentanen Zugpferde. Der Autor dieses Beitrags geht über die von Hilary Mason definierte Verortung hinaus. Data Science findet dort statt, wo die Brücken ins Business geschlagen werden. Dort, wo von Business-Seite neue Impulse kommen. Wo neue Fragen in Richtung der "Daten" (= der Kunden, Produkte, Märkte, Wettbewerber, Prozesse etc.) formuliert werden. Die können nun (endlich) mit diesen neuen Technologien und Algorithmen beantwortet werden. Und das direkter, schneller und in beliebiger Relation und Kombination. Data Science ist damit weit mehr als ein weiteres Werkzeug innerhalb bestehender Organisationsstrukturen und -prozesse, beispielsweise im Rahmen der Business Intelligence. Die Aufbereitung, Provisionierung und der Zugang zu Daten, Analysen und Reports müssen und werden in Zukunft neu und weiter gedacht werden. Dies gilt gerade in Kombination mit den Entwicklungen im Bereich der Datenvisualisierung und des "Storytellings mit Daten". Dies entfaltet seine Gültigkeit mit den aktuellen Trends in der Interface-Entwicklung und den immer höheren Anforderungen an Portabilität und Echtzeitkontrolle (Stichworte: Mobile Business Apps) von Seiten der Anwender. Business und Daten Business und Daten werden näher zusammenrücken. Daten werden nahtloser, unmittelbarer und oft in Echtzeit in die Entscheidungsprozesse integriert. Das wird unweigerlich auch zu Veränderungen in den Strukturen und Prozessen von Unternehmen führen. Data Scientists sind die Personen im Unternehmen, die die Aufgabe haben, die aus den Fachabteilungen formulierten Business-Anforderungen in Big-Data-Lösungen zu übersetzen. Sie modellieren die dafür erforderlichen Systeme, Prozesse und Interfaces. Sie kreieren ganzheitliche "Data Experiences" (DX) von der Quelle (den Daten) bis zur Senke (den Interfaces und nicht zuletzt den Nutzern). Ähnlich wie beim "User Experience Design" (UX) von Mensch-Maschine-Schnittstellen in der Software- und Online-Welt ist der Ausgangspunkt eine wohlformulierte Anforderung oder Fragestellung. Deren Beantwortung wird die Basis einer Entscheidungsfindung im Rahmen strategischer oder operativer Prozesse. Das Vorgehen ist häufig agil und insbesondere zu Beginn geprägt von einer schnellen Abfolge von empirischen Untersuchungen und Ad-hoc-Analysen. In dieser Phase ist der Data Scientist seiner Namensgebung am nächsten. Er ist ein Forscher in den Daten und, um auch diese Analogie zu ziehen, macht Probebohrungen im neuen Rohstoff Daten, dem Öl des Big-Data-Zeitalters. In den oftmals noch unbekannten, aufgrund ihrer Größe zu aufwendig zu verarbeitenden oder zu schnelllebigen Daten werden Muster und Rhythmen aufgespürt. Zudem werden Regelmäßigkeiten und Unregelmäßigkeiten identifiziert, Relationen ermittelt, Modelle definiert, trainiert und oftmals auch verworfen. Es geht um neue Strukturen in den Daten, die man ans Tageslicht fördern und zur Annotation und weiteren Verarbeitung verwenden will. Erfolgsfaktor: Mut zur Lücke Was macht nun einen guten, erfolgreichen Data Scientist aus? Wesentliche Eigenschaften sind Neugierde und Kreativität. Hinzukommen muss ein gesundes Maß an Skepsis gegenüber den ermittelten Ergebnissen. Ein Data Scientist sollte auch keine Angst davor haben, auch mal nichts in all den Daten zu finden, was als Antwort dienen kann. Vollendung unmöglich Betrachtet man die Vielzahl an Kompetenzen, die ein Data Scientist in sich vereinen muss, um in allen benannten Facetten Optimales zu vollbringen, ist sofort klar, dass sie kaum je ein Einzelner auf sich vereinen kann. Je nach Aufgabe kann ein erfahrener Generalist und Experte in einigen Bereichen sicher allein agieren. Meistens jedoch ist Data Science ein Teamsport. Statistiker und Mathematiker etwa arbeiten zusammen. Viele Experten - ein Team Auch Programmierer, Daten- und Business-Analysten, KI-Experten, kommunikationsstarke und Business-orientierte Generalisten (die dann in diesem Kontext oft den Titel Data Scientist tragen) und nicht zuletzt die Experten aus einzelnen Fachdomänen bilden Data-Science-Teams. DJ Patil von LinkedIn und Jeff Hammerbacher bei Facebook waren Mitte der 2000er Jahre mit die Ersten, die Data-Science-Teams gründeten, um einen geschäftlichen Nutzen aus den riesigen Datenmengen ihrer sozialen Netzwerke zu generieren. Diesem Beispiel dürften in den kommenden Jahren viele weitere Unternehmen folgen. Klaas Bollhoefer ist Data Scientist bei der Berliner The unbelievable Machine Company GmbH. klaas.bollhoefer@ unbelievable-machine.com},
}

@article{argamon_well-rounded_2014,
	chapter = {News},
	title = {The {Well}-{Rounded} {Data} {Scientist}},
	copyright = {© 2014 Information Management and SourceMedia, Inc. All rights reserved.},
	url = {http://global.factiva.com/redir/default.aspx?P=sa&an=INFOM00020140416ea4f00001&cat=a&ep=ASE},
	abstract = {The work of interpreting data to help decision-makers goes back some 5,000 years to the bureaucrats and businessmen of ancient Sumer. But dealing with the astronomical size and complexity of modern data sets requires a new, multifaceted set of computational, statistical, and communication and people skills, called “data science.” Data scientists are among the most sought-after professionals today, and the need for them will only increase as our world grows ever more complex and interconnected.},
	language = {English},
	urldate = {2020-08-28},
	journal = {Information Management},
	author = {Argamon, Shlomo},
	month = apr,
	year = {2014},
	note = {Publisher: SourceMedia, Inc.
Volume: Vol.1, No.1},
	annote = {As Mark A. Smith of Ventana Research blogged in January, a key challenge for organizations in 2014 is acquiring expertise at extracting the best possible insights from big data. That means finding people with a uniquely balanced set of data science skills that enable them to take on today’s challenge of making sense of petascale and larger data sets from the enterprise, the cloud and the Web. But what do these well-rounded data scientists look like, exactly, and where can they be found? The function of the data scientist is, in a word, sensemaking — providing a clear understanding of an organization’s universe through data analysis, helping improve decision-making and supporting leadership. The best data scientists also will be intensely curious and interested in discovering new insights. They will be creative in their approach to identifying and solving problems. Their professional expertise stands upon three pillars: (i) deep theoretical knowledge of statistics and computability, (ii) practical knowledge of diverse data science tools (and the ability to create them when needed), and (iii) an ability to communicate effectively with people with no technical background about very complex technical material. Specifically, well-rounded data scientists have the following skills: The first generation of data scientists was largely self-taught. They started from backgrounds in physics/science, statistics, mathematics, or computer science, and learned the other necessary skills and knowledge along the way. But universities (including Illinois Institute of Technology) are providing new multidisciplinary degree programs to teach students data science, which should help to take the guesswork out of finding data scientists. These programs go beyond traditional degrees in statistics, mathematics, computer science, and business intelligence by teaching a broad set of both technical and soft skills to prepare students for careers in data science. But not all such programs are created equal, and it is important to be aware of the differences among them. Some programs focus on teaching students specific tool-based skills and application areas. These programs can produce graduates who can start work on well-defined projects fairly quickly. Other programs with deeper theoretical content produce graduates who will be able to more easily work outside of their initial comfort zone, and who can learn, grow and adapt as the field changes. Similarly, programs that focus deeply on mathematical and computational content may produce more technically knowledgeable graduates, but unless they entered the program with already excellent communications skills, these graduates may not be well-suited to real-world data science jobs where communicating with nontechnical people is an essential part of the job. Programs that more fully integrate soft skills into the curriculum will produce more well-rounded data scientists who can take on leadership roles. Data science brings a distinct set of challenges to business communication. How does one explain statistical evidence and analytical results without oversimplifying or creating confusion? Students need to learn how to weave results into a coherent story, how to explain statistical assumptions and caveats clearly, and how to create data visualizations that give insight and are not just pretty pictures. The only way to learn these skills is by practicing them at the same time as learning the related technical material. Finally, a critical component of any quality data science education program is some sort of practical experience component, whether it is a student project, an internship program, or a guided practicum. Until they have worked on real-world data science problems, students will not fully understand how to perform central data science activities that cannot be taught in a classroom setting: struggling to define the analytical problem correctly, dealing with real data complexities and inconsistencies, and communicating results in a clear, enlightening, and satisfying fashion to non-technical, non-academic clients. Our model is to place students into teams of two to four individuals who work on projects for industrial partners with academic guidance. In such team-based work, students are forced to work together, exercising interpersonal communication skills. They can learn from and teach each other, seeing in the process how people with different talents and knowledge can together achieve more than they could as individuals. And by working with real clients from industry, students get direct experience and feedback on both their technical performance as well as their communication skills. Understanding what makes for a good data scientist and how to evaluate different educational programs is essential for effective recruiting. There is no question that it will become easier as the field matures and general standards for data science education start to emerge. The field of data science will of course continue to evolve and change, as the nature and complexity of data continue to evolve and change. But one constant will remain: well-rounded data scientists will be needed to help us all make sense of our changing world.},
}

@misc{wladawsky-berger_data_2013,
	title = {Data {Science} - the {Emergence} of a {New} {Discipline}},
	url = {https://blog.irvingwb.com/blog/2013/04/data-science-the-potential-emergence-of-a-new-discipline.html},
	abstract = {Data Science is emerging as a hot new profession and academic discipline. Data Scientist: the Sexiest Job of the 21st Century is the title of a recent Harvard Business Review article. Its authors, Tom Davenport and D. J. Patil, define...},
	urldate = {2020-08-28},
	journal = {Irving Wladawsky-Berger},
	author = {Wladawsky-Berger, Irving},
	month = apr,
	year = {2013},
	annote = {But, the situation is rapidly changing.  A number of universities are setting up graduate programs in data science.  In New York City alone, for example, NYU has launched a new Center for Data Science which will start offering a Master in Data Science in the Fall of this year.  Urban informatics, - the application of data science to urban problems, - is the primary focus of NYU’s new Center for Urban Science and Progress, which will start a masters program in Applied Urban Science and Informatics this Fall as well.  Columbia University is starting an Institute for Data Science and Engineering.  Similar research and educational programs are being organized in universities around the world.},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TKV87U4G/data-science-the-potential-emergence-of-a-new-discipline.html:text/html},
}

@misc{woodie_for_2016,
	title = {For {Data} {Scientists}, {What}'s in a {Name} {Really} {Matters}},
	url = {https://www.datanami.com/2016/03/29/data-scientists-whats-name-really-matters/},
	abstract = {Shakespeare once pondered the nature of names, pointing out that "a rose by any other name would smell as sweet." For data scientists, the meaning behind},
	urldate = {2020-08-28},
	journal = {Datanami},
	author = {Woodie, Alex},
	month = mar,
	year = {2016},
}

@article{woodie_tracking_2016,
	title = {Tracking the {Data} {Science} {Talent} {Gap}},
	url = {https://www.datanami.com/2016/03/25/tracking-data-science-talent-gap/},
	urldate = {2020-08-28},
	journal = {Datanami},
	author = {Woodie, Alex},
	month = mar,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/UCCALJ53/tracking-data-science-talent-gap.html:text/html},
}

@misc{noauthor_finding_2016,
	title = {Finding {Long}-{Term} {Solutions} to the {Data} {Scientist} {Shortage}},
	url = {https://www.datanami.com/2016/03/28/finding-long-term-solutions-data-scientist-shortage/},
	abstract = {As we learned in the first part of this series, the gap between demand for skilled data scientists and supply is driving salaries north of \$200,000 in},
	urldate = {2020-08-28},
	journal = {Datanami},
	month = mar,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/GMXSHNKF/finding-long-term-solutions-data-scientist-shortage.html:text/html},
}

@misc{smith_data_2011,
	title = {"{Data} {Science}": what's in a name?},
	shorttitle = {"{Data} {Science}"},
	url = {https://blog.revolutionanalytics.com/2011/05/data-science-whats-in-a-name.html},
	abstract = {The terms "Data Science" and "Data Scientist" have only been in common usage for a little over a year, but they've really taken off since then: many companies are now hiring for "data scientists", and entire conferences are run under the name of "data science". But despite the widespread adoption, some have resisted the change from the more traditional terms like "statistician" or "quant" or "data analyst". Personally, I love the term. As a statistician, I was getting tired of explaining that no, I don't spend my time writing down baseball or cricket scores. I think "Data Science" better describes...},
	urldate = {2020-08-28},
	journal = {Revolutions},
	author = {Smith, David},
	month = may,
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/SK9MWUKT/data-science-whats-in-a-name.html:text/html},
}

@misc{press_data_2012,
	title = {Data {Scientists}: {The} {Definition} of {Sexy}},
	shorttitle = {Data {Scientists}},
	url = {https://www.forbes.com/sites/gilpress/2012/09/27/data-scientists-the-definition-of-sexy/},
	abstract = {A pocket protector. (Photo credit: Wikipedia) I put “sexy” in the title because I’m told that the words in the title make all the difference in getting noticed on the Web. That has certainly proven true for the Harvard Business Review after it included the word “sexiest” in the title of [...]},
	language = {en},
	urldate = {2020-08-31},
	journal = {Forbes},
	author = {Press, Gil},
	month = sep,
	year = {2012},
	note = {Section: Tech},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CMDYSVJ8/data-scientists-the-definition-of-sexy.html:text/html},
}

@misc{yau_rise_2009,
	title = {Rise of the {Data} {Scientist}},
	url = {https://flowingdata.com/2009/06/04/rise-of-the-data-scientist/},
	abstract = {Photo by majamarko As we’ve all read by now, Google’s chief economist Hal Varian commented in January that the next sexy job in the next 10 years would be statisticians. Obviously, I wh…},
	language = {en},
	urldate = {2020-08-31},
	journal = {FlowingData},
	author = {Yau, Nathan},
	month = jun,
	year = {2009},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/VXVUI2A3/rise-of-the-data-scientist.html:text/html},
}

@misc{noauthor_what_nodate,
	title = {What it means to be a data scientist. {\textbar} {LinkedIn}},
	url = {https://www.linkedin.com/pulse/what-means-data-scientist-troy-sadkowsky/},
	urldate = {2020-08-31},
	file = {What it means to be a data scientist. | LinkedIn:/Users/rca2t1/Dropbox/Zotero/storage/NYEA8JC5/what-means-data-scientist-troy-sadkowsky.html:text/html},
}

@article{mckenzie_probing_2019,
	title = {Probing the slowdown in master's degree growth},
	url = {https://www.insidehighered.com/digital-learning/article/2019/12/20/probing-slowdown-masters-degree-growth},
	abstract = {Analysis suggests projections of rapid growth in the master’s degree market were vastly overstated.},
	language = {en},
	urldate = {2020-09-11},
	journal = {Inside Higher Ed},
	author = {McKenzie, Lindsay},
	month = dec,
	year = {2019},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2ACVKZYS/probing-slowdown-masters-degree-growth.html:text/html},
}

@misc{herman_field_2013,
	title = {Field {Guide} to {Data} {Science}},
	url = {https://www.boozallen.com/s/insight/publication/field-guide-to-data-science.html},
	abstract = {This guide is aimed at helping organizations understand how to better use data as a resource.},
	language = {en},
	urldate = {2020-09-11},
	publisher = {Booz Allen Hamilton Inc.},
	author = {Herman, Mark and Rivera, Stephanie and Stephen, Mills and Sullivan, Josh and Guerra, Peter and Cosmas, Alex and Farris, Drew and Kholey, Ed and Yacci, Paul and Keller, Brian and Kherlopian, Armen and Kim, Michael},
	year = {2013},
	file = {Herman et al. - 2013 - Field Guide to Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RVMBILPF/Herman et al. - 2013 - Field Guide to Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/N24K6B46/field-guide-to-data-science.html:text/html},
}

@misc{noauthor_17_nodate,
	title = {(17) ({PDF}) {The} {Field} {Guide} to {Data} {Science}},
	url = {https://www.researchgate.net/publication/258698880_The_Field_Guide_to_Data_Science},
	abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	language = {en},
	urldate = {2020-09-11},
	journal = {ResearchGate},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/HAQP43RR/258698880_The_Field_Guide_to_Data_Science.html:text/html},
}

@article{davenport_recessions_2020,
	title = {The {Recession}’s {Impact} on {Analytics} and {Data} {Science}},
	url = {https://sloanreview.mit.edu/article/the-recessions-impact-on-analytics-and-data-science/},
	abstract = {There has been a huge demand for data scientists in the past decade. Is that about to change?},
	language = {en-US},
	urldate = {2020-09-11},
	journal = {MIT Sloan Management Review},
	author = {Davenport, Melissa R. Bowers, {and} Thomas H., Jeffrey D. Camm},
	month = jun,
	year = {2020},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2JPUH2Z3/the-recessions-impact-on-analytics-and-data-science.html:text/html},
}

@misc{miles_what_2018,
	title = {What do data scientists at {Google} know that most other data scientists don't?},
	url = {https://www.quora.com/What-do-data-scientists-at-Google-know-that-most-other-data-scientists-dont/answer/Jeremy-Miles?ch=10&share=99816136&srid=3thZX},
	urldate = {2020-09-12},
	journal = {Quora},
	author = {Miles, Jeremy},
	month = oct,
	year = {2018},
	file = {Jeremy Miles's answer to What do data scientists at Google know that most other data scientists don't? - Quora:/Users/rca2t1/Dropbox/Zotero/storage/ENK342YB/Jeremy-Miles.html:text/html},
}

@book{goto_rims_1983,
	title = {{RIMS} {Symposium} on {Software} {Science} and {Engineering}: {Kyoto}, 1982. {Proceedings}},
	isbn = {978-3-540-11980-7},
	shorttitle = {{RIMS} {Symposium} on {Software} {Science} and {Engineering}},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Goto, E. and Furukawa, K. and Nakajima, R. and Nakata, I. and Yonezawa, A.},
	month = feb,
	year = {1983},
	note = {Google-Books-ID: L2EG2rkwuQsC},
	keywords = {Computers / Information Technology, Computers / Software Development \& Engineering / General, Computers / Computer Science, Computers / Programming / General},
}

@article{cukier_rise_2013,
	title = {The {Rise} of {Big} {Data}: {How} it's {Changing} the {Way} {We} {Think} about the {World} {Essay}},
	volume = {92},
	shorttitle = {The {Rise} of {Big} {Data}},
	url = {https://heinonline.org/HOL/P?h=hein.journals/fora92&i=592},
	language = {eng},
	number = {3},
	urldate = {2020-09-28},
	journal = {Foreign Affairs},
	author = {Cukier, Kenneth and Mayer-Schoenberger, Viktor},
	year = {2013},
	pages = {[i]--40},
	file = {Cukier and Mayer-Schoenberger - 2013 - The Rise of Big Data How it's Changing the Way We.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NU8CACX5/Cukier and Mayer-Schoenberger - 2013 - The Rise of Big Data How it's Changing the Way We.pdf:application/pdf},
}

@article{lohr_study_2009,
	chapter = {Technology},
	title = {Study {Measures} the {Chatter} of the {News} {Cycle}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2009/07/13/technology/internet/13influence.html},
	abstract = {Findings suggested traditional news sites were typically ahead of blogs by two and a half hours when a story line spread.},
	language = {en-US},
	urldate = {2020-10-03},
	journal = {The New York Times},
	author = {Lohr, Steve},
	month = jul,
	year = {2009},
	keywords = {Computers and the Internet, Blogs and Blogging (Internet), News and News Media, Social Networking (Internet)},
}

@article{lohr_for_2009,
	chapter = {Technology},
	title = {For {Today}’s {Graduate}, {Just} {One} {Word}: {Statistics}},
	issn = {0362-4331},
	shorttitle = {For {Today}’s {Graduate}, {Just} {One} {Word}},
	url = {https://www.nytimes.com/2009/08/06/technology/06stats.html},
	abstract = {With the explosion of digital data, statisticians can earn \$125,000 in their first year after getting a doctorate.},
	language = {en-US},
	urldate = {2020-10-03},
	journal = {The New York Times},
	author = {Lohr, Steve},
	month = aug,
	year = {2009},
	keywords = {Computers and the Internet, Mathematics, Statistics, Google Inc, Research},
}

@misc{yau_data_2009,
	title = {Data is the {New} {Hot}, {Drop}-dead {Gorgeous} {Field}},
	url = {https://flowingdata.com/2009/08/07/data-is-the-new-hot-drop-dead-gorgeous-field/},
	abstract = {We all know this already, but it’s nice to get some backing from The New York Times every now and then. In this NYT article, that I’m sure has spread to every statistician’s email…},
	language = {en},
	urldate = {2020-10-03},
	journal = {FlowingData},
	author = {Yau, Nathan},
	month = aug,
	year = {2009},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/W7VELTU9/data-is-the-new-hot-drop-dead-gorgeous-field.html:text/html},
}

@misc{manyika_hal_2009,
	title = {Hal {Varian} on {How} the {Web} {Challenges} {Managers}},
	url = {https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/hal-varian-on-how-the-web-challenges-managers},
	urldate = {2020-10-04},
	journal = {McKinsey \& Company},
	author = {Varian, Hal R},
	collaborator = {Manyika, James},
	month = jan,
	year = {2009},
	file = {Hal Varian on how the Web challenges managers | McKinsey:/Users/rca2t1/Dropbox/Zotero/storage/SXSUT2UI/hal-varian-on-how-the-web-challenges-managers.html:text/html},
}

@misc{yau_googles_2009,
	title = {Google’s {Chief} {Economist} {Hal} {Varian} on {Statistics} and {Data}},
	url = {https://flowingdata.com/2009/02/25/googles-chief-economist-hal-varian-on-statistics-and-data/},
	abstract = {I keep saying the sexy job in the next ten years will be statisticians. People think I’m joking, but who would’ve guessed that computer engineers would’ve been the sexy job of the…},
	language = {en},
	urldate = {2020-10-04},
	journal = {FlowingData},
	author = {Yau, Nathan},
	month = feb,
	year = {2009},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Y6C25BJY/googles-chief-economist-hal-varian-on-statistics-and-data.html:text/html},
}

@misc{driscoll_three_2009,
	title = {The {Three} {Sexy} {Skills} of {Data} {Geeks}},
	url = {https://web.archive.org/web/20090530074011/dataspora.com/blog/sexy-data-geeks/},
	urldate = {2020-10-04},
	journal = {Dataspore Blog},
	author = {Driscoll, Michael E.},
	month = may,
	year = {2009},
	file = {The Three Sexy Skills of Data Geeks \: Dataspora Blog:/Users/rca2t1/Dropbox/Zotero/storage/G262CKFE/sexy-data-geeks.html:text/html},
}

@phdthesis{fry_computational_2004,
	type = {Thesis},
	title = {Computational {Information} {Design}},
	copyright = {M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.},
	url = {https://dspace.mit.edu/handle/1721.1/26913},
	abstract = {The ability to collect, store, and manage data is increasing quickly, but our ability to understand it remains constant. In an attempt to gain better understanding of data, fields such as information visualization, data mining and graphic design are employed, each solving an isolated part of the specific problem, but failing in a broader sense: there are too many unsolved problems in the visualization of complex data. As a solution, this dissertation proposes that the individual fields be brought together as part of a singular process titled Computational Information Design. This dissertation first examines the individual pedagogies of design, information, and computation with a focus on how they support one another as parts of a combined methodology for the exploration, analysis, and representation of complex data. Next, in order to make the process accessible to a wider audience, a tool is introduced to simplify the computational process for beginners, and can be used as a sketch- ing platform by more advanced users. Finally, a series of examples show how the methodology and tool can be used to address a range of data problems, in particular, the human genome.},
	language = {en\_US},
	urldate = {2020-10-04},
	school = {Massachusetts Institute of Technology},
	author = {Fry, Benjamin Jotham},
	year = {2004},
	note = {Accepted: 2005-09-06T20:47:40Z},
	file = {Fry - 2004 - Computational Information Design.pdf:/Users/rca2t1/Dropbox/Zotero/storage/VEYQLWB5/Fry - 2004 - Computational Information Design.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/P8WNUM3A/26913.html:text/html},
}

@misc{noauthor_commoditization_2009,
	title = {The {Commoditization} of {Massive} {Data} {Analysis} - {O}'{Reilly} {Radar}},
	url = {https://web.archive.org/web/20090428190430/http://radar.oreilly.com/2008/11/the-commoditization-of-massive.html},
	urldate = {2020-10-04},
	month = apr,
	year = {2009},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/9Y57TEN4/the-commoditization-of-massive.html:text/html},
}

@article{varian_big_2014,
	title = {Big {Data}: {New} {Tricks} for {Econometrics}},
	volume = {28},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.28.2.3},
	abstract = {Computers are now involved in many economic transactions and can capture data associated with these transactions, which can then be manipulated and analyzed. Conventional statistical and econometric techniques such as regression often work well, but there are issues unique to big datasets that may require different tools. First, the sheer size of the data involved may require more powerful data manipulation tools. Second, we may have more potential predictors than appropriate for estimation, so we need to do some kind of variable selection. Third, large datasets may allow for more flexible relationships than simple linear models. Machine learning techniques such as decision trees, support vector machines, neural nets, deep learning, and so on may allow for more effective ways to model complex relationships. In this essay, I will describe a few of these tools for manipulating and analyzing big data. I believe that these methods have a lot to offer and should be more widely known and used by economists.},
	number = {2},
	urldate = {2020-10-05},
	journal = {Journal of Economic Perspectives},
	author = {Varian, Hal R},
	year = {2014},
	pages = {3--28},
	file = {jep.28.2.pdf:/Users/rca2t1/Dropbox/Zotero/storage/PBBGL5X4/jep.28.2.pdf:application/pdf},
}

@article{miller_data_2013,
	chapter = {Education},
	title = {Data {Science}: {The} {Numbers} of {Our} {Lives}},
	issn = {0362-4331},
	shorttitle = {Data {Science}},
	url = {https://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html},
	abstract = {Big data, big money, big skill set now required. Universities are on it.},
	language = {en-US},
	urldate = {2020-10-05},
	journal = {The New York Times},
	author = {Miller, Claire Cain},
	month = apr,
	year = {2013},
	keywords = {Colleges and Universities, Data Science, Careers and Professions, College of Charleston, Columbia University, Data-Mining and Database Marketing, Miller, Claire Cain, University of San Francisco, University of Washington},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/527W7K62/universities-offer-courses-in-a-hot-new-field-data-science.html:text/html},
}

@article{rooney_big_2012,
	chapter = {Tech},
	title = {Big {Data}'s {Big} {Problem}: {Little} {Talent}},
	issn = {0099-9660},
	shorttitle = {Big {Data}'s {Big} {Problem}},
	url = {https://online.wsj.com/article/SB10001424052702304723304577365700368073674.html},
	abstract = {Big Data is the next big thing in technology, but the people who know how to make the most of it are in short supply.},
	language = {en-US},
	urldate = {2020-11-27},
	journal = {Wall Street Journal},
	author = {Rooney, Ben},
	month = apr,
	year = {2012},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/HLWQAKBR/SB10001424052702304723304577365700368073674.html:text/html},
}

@article{walker_professionalisation_2015,
	title = {The professionalisation of data science},
	volume = {1},
	issn = {2053-0811},
	url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJDS.2015.069048},
	doi = {10.1504/IJDS.2015.069048},
	abstract = {Data science is establishing basic foundations to become a profession. Like the professionalisation of law and medicine in the past 100 years, the data science field is at the very beginning of becoming a profession - with competency standards, a code of professional conduct, specialised graduate-level curriculums, certification and licensure and self-regulation. All professions require highly specialised education and training, an ethical code, self-regulation by a professional association and certification and licensing. Data science should become a profession for the same reasons medicine and law became professions: each requires practitioners to have a specialised body of knowledge, a code of conduct and self-regulation by knowledgeable professionals to assure competency and protect the public. The data science community can follow a roadmap for how data science can be professionalised by reviewing the history of the medical and legal professions. Suggested is a seven-step process for the professionalisation of data science.},
	number = {1},
	urldate = {2020-11-30},
	journal = {International Journal of Data Science},
	author = {Walker, Michael A.},
	month = jan,
	year = {2015},
	note = {Publisher: Inderscience Publishers},
	pages = {7--16},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/9PZLRTNW/IJDS.2015.html:text/html;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Z74T3DFU/IJDS.2015.html:text/html;Submitted Version:/Users/rca2t1/Dropbox/Zotero/storage/MCKRXJNP/Walker - 2015 - The professionalisation of data science.pdf:application/pdf},
}

@misc{noauthor_code_2020,
	title = {Code of {Conduct}},
	url = {http://www.datascienceassn.org/code-of-conduct.html},
	urldate = {2020-11-30},
	journal = {Data Science Association},
	year = {2020},
	annote = {(b) "Data Science" means the scientific study of the creation, validation and transformation of data to create meaning.},
	file = {Code of Conduct | Data Science Association:/Users/rca2t1/Dropbox/Zotero/storage/SRSEHWYH/code-of-conduct.html:text/html;datasciencecodeofprofessionalconduct.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HAJRGH7P/datasciencecodeofprofessionalconduct.pdf:application/pdf},
}

@book{izenman_modern_2008,
	address = {New York ; London},
	edition = {1st ed. 2008, Corr. 2nd printing 2013 edition},
	title = {Modern {Multivariate} {Statistical} {Techniques}: {Regression}, {Classification}, and {Manifold} {Learning}},
	isbn = {978-0-387-78188-4},
	shorttitle = {Modern {Multivariate} {Statistical} {Techniques}},
	abstract = {This is the first book on multivariate analysis to look at large data sets which describes the state of the art in analyzing such data. Material such as database management systems is included that has never appeared in statistics books before.},
	language = {English},
	publisher = {Springer},
	author = {Izenman, Alan J.},
	month = aug,
	year = {2008},
	file = {Izenman - 2008 - Modern Multivariate Statistical Techniques Regres.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LKGI4V83/Izenman - 2008 - Modern Multivariate Statistical Techniques Regres.pdf:application/pdf},
}

@misc{noauthor_nih_2015,
	title = {{NIH} to recruit {Associate} {Director} for {Data} {Science}},
	url = {https://www.nih.gov/news-events/news-releases/nih-recruit-associate-director-data-science},
	abstract = {National Institutes of Health Director Francis S. Collins, M.D., Ph.D., today announced plans to recruit a new senior scientific position, the Associate Director for Data Science.},
	language = {EN},
	urldate = {2020-12-05},
	journal = {National Institutes of Health (NIH)},
	month = jul,
	year = {2015},
	annote = {FULL TEXT
National Institutes of Health Director Francis S. Collins, M.D., Ph.D., today announced plans to recruit a new senior scientific position, the Associate Director for Data Science. The associate director will lead a series of NIH-wide strategic initiatives that collectively aim to capitalize on the exponential growth of biomedical research data, such as from genomics, imaging, and electronic health records. Dr. Collins recently charged a working group of the Advisory Committee to the NIH Director (ACD) to examine the growing data and informatics challenges associated with biomedical research. One of the major recommendations made by that working group in June 2012 is the creation of a new NIH leadership position focused on data science.
"There is an urgent need and increased opportunities for advanced collaboration and coordination of access to, and analysis of, the rapidly expanding collections of biomedical data," Dr. Collins said. "NIH aims to play a catalytic lead role in addressing these complex issues — not only internally, but also with stakeholders in the research community, other government agencies, and private organizations involved in scientific data generation, management, and analysis."
Dr. Collins has asked Eric Green, M.D., Ph.D., to serve as the Acting Associate Director for Data Science. Dr. Green was appointed as the third director of the National Human Genome Research Institute (NHGRI) in 2009. Dr. Green has been at the forefront of efforts to map, sequence, and understand eukaryotic genomes. He played a leadership role in the Human Genome Project and subsequently pioneered work in comparative genomics that provided important insights about genome structure, function, and evolution. Among his many honors, Dr. Green was inducted into the Association of American Physicians in 2007, and received the Cotlove Award from the Academy of Clinical Laboratory Physicians and Scientists in 2011 and the Wallace H. Coulter Lectureship Award from the American Association for Clinical Chemistry in 2012. He will continue to serve in his current role at NHGRI while serving in this acting leadership position.
The Office of the Director, the central office at NIH, is responsible for setting policy for NIH, which includes 27 Institutes and Centers. This involves planning, managing, and coordinating the programs and activities of all NIH components. The Office of the Director also includes program offices which are responsible for stimulating specific areas of research throughout NIH. Additional information is available at http://www.nih.gov/icd/od.},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NM85CWTC/nih-recruit-associate-director-data-science.html:text/html},
}

@article{noauthor_data_2010,
	title = {Data, data everywhere},
	issn = {0013-0613},
	url = {https://www.economist.com/special-report/2010/02/27/data-data-everywhere},
	abstract = {Information has gone from scarce to superabundant. That brings huge new benefits, says Kenneth Cukier (interviewed here)—but also big headaches},
	urldate = {2020-12-06},
	journal = {The Economist},
	month = feb,
	year = {2010},
	file = {The Economist Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TVX93S5F/data-data-everywhere.html:text/html},
}

@book{hastie_elements_2009,
	title = {The {Elements} of {Statistical} {Learning}: {Data} {Mining}, {Inference}, and {Prediction}},
	isbn = {978-0-387-84857-0 978-0-387-84884-6},
	shorttitle = {The {Elements} of {Statistical} {Learning}},
	abstract = {"During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for "wide'' data (p bigger than n), including multiple testing and false discovery rates."--Publisher's description.},
	language = {English},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H},
	year = {2009},
	note = {OCLC: 300478243},
	file = {Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf:/Users/rca2t1/Dropbox/Zotero/storage/TS7NHQ64/Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf:application/pdf},
}

@misc{research_and_development_research_team_data_2019,
	title = {Data {Scientist} {Hiring} {Guide}},
	url = {https://www.gartner.com/en/documents/3970210/data-scientist-hiring-guide},
	abstract = {Gartner Research on Data Scientist Hiring Guide},
	language = {en},
	urldate = {2020-12-07},
	journal = {Gartner},
	author = {{Research and Development Research Team}},
	month = oct,
	year = {2019},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4LG2CDZT/3970210.html:text/html},
}

@misc{bloor_data_2013,
	title = {A {Data} {Science} {Rant}},
	url = {https://insideanalysis.com/a-data-science-rant/},
	abstract = {What is data science? From the hype in the IT press right now, you might think that it is something excitingly new, destined to determine the future prosperity of a whole swathe of companies big an…},
	language = {en-US},
	urldate = {2020-12-07},
	journal = {Inside Analysis},
	author = {Bloor, Robin},
	month = aug,
	year = {2013},
	annote = {Data science as solecism; Statistics 2.0
Typical a priori response. It's just statistics!},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/LEVMCHNA/a-data-science-rant.html:text/html},
}

@misc{laney_defining_2012,
	title = {Defining and {Differentiating} the {Role} of the {Data} {Scientist}},
	url = {https://web.archive.org/web/20120327163714/http://blogs.gartner.com/doug-laney/defining-and-differentiating-the-role-of-the-data-scientist/},
	urldate = {2020-12-07},
	journal = {Gartner},
	author = {Laney, Doug},
	month = mar,
	year = {2012},
	file = {Defining and Differentiating the Role of the Data Scientist:/Users/rca2t1/Dropbox/Zotero/storage/GQB7KL88/defining-and-differentiating-the-role-of-the-data-scientist.html:text/html},
}

@misc{laney_emerging_2012,
	title = {Emerging {Role} of the {Data} {Scientist} and the {Art} of {Data} {Science}},
	url = {https://web.archive.org/web/20130115192221/http://www.gartner.com/DisplayDocument?ref=clientFriendlyUrl&id=1955615},
	abstract = {Data scientists can be invaluable in generating insights, especially from "big data;" but their unique combination of technical and business skills, together with their heightened demand, makes them difficult to find or cultivate.},
	urldate = {2020-12-07},
	author = {Laney, Douglas and Kart, Lisa},
	month = mar,
	year = {2012},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3EPMGFRQ/DisplayDocument.html:text/html},
}

@misc{ramanathan_data_2016,
	title = {The {Data} {Science} {Delusion}},
	url = {https://medium.com/@anandr42/the-data-science-delusion-7759f4eaac8e},
	abstract = {Prologue},
	language = {en},
	urldate = {2020-12-07},
	journal = {Medium},
	author = {Ramanathan, Anand},
	month = dec,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/39NFR4BT/the-data-science-delusion-7759f4eaac8e.html:text/html},
}

@misc{mason_data_2014,
	title = {Data {Driven}: {Creating} a {Data} {Culture}},
	shorttitle = {Data {Driven}},
	url = {https://www.oreilly.com/content/data-driven/},
	abstract = {To succeed with data, businesses must develop a data culture.},
	language = {en-US},
	urldate = {2020-12-07},
	journal = {O’Reilly Media},
	author = {Mason, Hilary, DJ Patil},
	month = dec,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/G6G2HVTF/data-driven.html:text/html},
}

@misc{broman_i_2016,
	title = {I am a data scientist},
	url = {https://kbroman.wordpress.com/2016/04/08/i-am-a-data-scientist/},
	abstract = {Three years ago this week, I wrote a blog post, “Data science is statistics”. I was fiercely against the term at that time, as I felt that we already had a data science, and it was called Statistic…},
	language = {en},
	urldate = {2020-12-07},
	journal = {The stupidest thing...},
	author = {Broman, Karl},
	month = apr,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TT9M6IEC/i-am-a-data-scientist.html:text/html},
}

@misc{broman_data_2013,
	title = {Data science is statistics},
	url = {https://kbroman.wordpress.com/2013/04/05/data-science-is-statistics/},
	abstract = {When physicists do mathematics, they don’t say they’re doing “number science”. They’re doing math. If you’re analyzing data, you’re doing statistics. You c…},
	language = {en},
	urldate = {2020-12-07},
	journal = {The stupidest thing...},
	author = {Broman, Karl},
	month = apr,
	year = {2013},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QJVE32W3/data-science-is-statistics.html:text/html},
}

@misc{broman_reform_2014,
	title = {Reform academic statistics},
	url = {https://kbroman.wordpress.com/2014/05/01/reform-academic-statistics/},
	abstract = {Terry Speed recently gave a talk on the role of statisticians in “Big Data” initiatives (see the video or just look at the slides). He points to the history of statisticians’ discussions of m…},
	language = {en},
	urldate = {2020-12-07},
	journal = {The stupidest thing...},
	author = {Broman, Karl},
	month = may,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/WY4ZYGYM/reform-academic-statistics.html:text/html},
}

@book{council_massive_1996,
	title = {Massive {Data} {Sets}: {Proceedings} of a {Workshop}},
	isbn = {978-0-309-05694-6},
	shorttitle = {Massive {Data} {Sets}},
	url = {https://www.nap.edu/catalog/5505/massive-data-sets-proceedings-of-a-workshop},
	abstract = {Download a PDF of "Massive Data Sets" by the National Research Council for free.},
	language = {en},
	urldate = {2020-12-07},
	author = {Council, National Research},
	year = {1996},
	doi = {10.17226/5505},
	file = {Council - 1996 - Massive Data Sets Proceedings of a Workshop.pdf:/Users/rca2t1/Dropbox/Zotero/storage/9Z2687GL/Council - 1996 - Massive Data Sets Proceedings of a Workshop.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ZCFEZZ5B/massive-data-sets-proceedings-of-a-workshop.html:text/html},
}

@misc{leek_data_2013,
	title = {Data {Science} {Only} {Poses} a {Threat} to (bio)statistics {If} {We} {Don}'t {Adapt}},
	url = {https://simplystatistics.org/2013/04/15/data-science-only-poses-a-threat-to-biostatistics-if-we-dont-adapt/},
	urldate = {2020-12-07},
	journal = {Simply Statistics},
	author = {Leek, Jeff},
	month = apr,
	year = {2013},
	file = {Data science only poses a threat to (bio)statistics if we don't adapt · Simply Statistics:/Users/rca2t1/Dropbox/Zotero/storage/DYEZ4A64/data-science-only-poses-a-threat-to-biostatistics-if-we-dont-adapt.html:text/html},
}

@misc{wasserman_data_2013,
	title = {Data {Science}: {The} {End} of {Statistics}?},
	shorttitle = {Data {Science}},
	url = {https://normaldeviate.wordpress.com/2013/04/13/data-science-the-end-of-statistics/},
	abstract = {As I see newspapers and blogs filled with talk of “Data Science” and “Big Data” I find myself filled with a mixture of optimism and drea…},
	language = {en},
	urldate = {2020-12-07},
	journal = {Normal Deviate},
	author = {Wasserman, Larry},
	month = apr,
	year = {2013},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2XEFCPMF/data-science-the-end-of-statistics.html:text/html},
}

@article{chatfield_data_2014,
	title = {Data {Scientists} as {Game} {Changers} in {Big} {Data} {Environments}},
	abstract = {The potential power of big data to generate insights and create new forms of value in the ways which transform organizations and society has been observed by big data-driven organizations and big data experts. Despite the recent sensational declaration of a data scientist as “the sexiest job of the 21st century”, however, there is a lack of published rigorous studies of what a data scientist is, and what job skills this hottest job title may require. In order to address this gap, we systematically examine relevant source material to extract key definitions and categorize them towards understanding emergent roles and skills of data scientists. We conclude that the current lack of clear skills specifications and the growing skills shortage are key barriers to realizing the potential benefits of big data in organizations, through hiring data scientists and leveraging their game changer roles, indicating important educational implications for our IS field.},
	language = {en},
	journal = {New Zealand},
	author = {Chatfield, Akemi Takeoka and Shlemoon, Vivian Najem and Redublado, Wilbur and Rahman, Faizur},
	year = {2014},
	pages = {11},
	annote = {"Despite the recent sensational declaration of a data scientist as “the sexiest job of the 21st century” . . . there is a lack of published rigorous studies of what a data scientist is, and what job skills this hottest job title may require. In order to address this gap, we systematically examine relevant source material to extract key definitions and categorize them towards understanding emergent roles and skills of data scientists."
"In summary, it appears that the evolution of data science concepts corresponds to the diffusion process of innovations in computer technologies and computer-based information systems at the organizational level."
"It also seems that it has gained significant attention of academics and managers in such areas as database marketing (BusinessWeek 1994) and data mining for extracting information from large structured databases, as data output has significantly increased in correlation with the increasing processing power of computers in the organizat},
	file = {Chatfield et al. - 2014 - Data Scientists as Game Changers in Big Data Envir.pdf:/Users/rca2t1/Dropbox/Zotero/storage/Q7Q4XPZT/Chatfield et al. - 2014 - Data Scientists as Game Changers in Big Data Envir.pdf:application/pdf},
}

@book{mayer-schonberger_big_2013,
	title = {Big {Data}: {A} {Revolution} that {Will} {Transform} how {We} {Live}, {Work}, and {Think}},
	isbn = {978-0-544-00269-2},
	shorttitle = {Big {Data}},
	abstract = {A revelatory exploration of the hottest trend in technology and the dramatic impact it will have on the economy, science, and society at large.  Which paint color is most likely to tell you that a used car is in good shape? How can officials identify the most dangerous New York City manholes before they explode? And how did Google searches predict the spread of the H1N1 flu outbreak?  The key to answering these questions, and many more, is big data. "Big data" refers to our burgeoning ability to crunch vast collections of information, analyze it instantly, and draw sometimes profoundly surprising conclusions from it. This emerging science can translate myriad phenomena--from the price of airline tickets to the text of millions of books--into searchable form, and uses our increasing computing power to unearth epiphanies that we never could have seen before. A revolution on par with the Internet or perhaps even the printing press, big data will change the way we think about business, health, politics, education, and innovation in the years to come. It also poses fresh threats, from the inevitable end of privacy as we know it to the prospect of being penalized for things we haven't even done yet, based on big data's ability to predict our future behavior.  In this brilliantly clear, often surprising work, two leading experts explain what big data is, how it will change our lives, and what we can do to protect ourselves from its hazards. Big Data is the first big book about the next big thing. www.big-data-book.com},
	language = {en},
	publisher = {Houghton Mifflin Harcourt},
	author = {Mayer-Schönberger, Viktor and Cukier, Kenneth},
	year = {2013},
	keywords = {Technology \& Engineering / General, Science / General, Business \& Economics / Information Management},
}

@book{brynjolfsson_second_2014,
	address = {New York, NY, US},
	series = {The second machine age: {Work}, progress, and prosperity in a time of brilliant technologies},
	title = {The second machine age: {Work}, progress, and prosperity in a time of brilliant technologies},
	isbn = {978-0-393-23935-5},
	shorttitle = {The second machine age},
	abstract = {In recent years, Google's autonomous cars have logged thousands of miles on American highways and IBM's Watson trounced the best human Jeopardy! players. Digital technologies—with hardware, software, and networks at their core—will in the near future diagnose diseases more accurately than doctors can, apply enormous data sets to transform retailing, and accomplish many tasks once considered uniquely human. In The Second Machine Age MIT's Erik Brynjolfsson and Andrew McAfee—two thinkers at the forefront of their field—reveal the forces driving the reinvention of our lives and our economy. As the full impact of digital technologies is felt, we will realize immense bounty in the form of dazzling personal technology, advanced infrastructure, and near-boundless access to the cultural Items that enrich our lives. Amid this bounty will also be wrenching change. Professions of aii kinds—from lawyers to truck drivers—will be forever upended. Companies will be forced to transform or die. Recent economic indicators reflect this shift: fewer people are working, and wages are failing even as productivity and profits soar. Drawing on years of research and up-to-the-minute trends, Brynjolfsson and McAfee identify the best strategies for survival and offer a new path to prosperity. These include revamping education so that it prepares people for the next economy instead of the last one, designing new collaborations that pair brute processing power with human ingenuity, and embracing policies that make sense in a radically transformed landscape. A fundamentally optimistic book, The Second Machine Age will alter how we think about Issues of technological, societal, and economic progress. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {W W Norton \& Co},
	author = {Brynjolfsson, Erik and McAfee, Andrew},
	year = {2014},
	note = {Pages: 306},
	keywords = {Technology, Economy, Human Computer Interaction, Human Factors Engineering, Human Machine Systems},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CS8DIJB7/2014-07087-000.html:text/html},
}

@misc{lev-ram_data_2011,
	title = {Data scientist: {The} hot new gig in tech},
	shorttitle = {Data scientist},
	url = {https://fortune.com/2011/09/06/data-scientist-the-hot-new-gig-in-tech/},
	abstract = {Companies that want to make sense of all their bits and bytes are hiring so-called data scientists – if they can find any. FORTUNE — The unemployment rate in the U.S. continues to be abysmal (9.1\% in July), but the tech world has spawned a new kind of highly skilled, nerdy-cool job that companies are […]},
	language = {en},
	urldate = {2020-12-07},
	journal = {Fortune},
	author = {Lev-Ram, Michal},
	month = sep,
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/5FAFKPFG/data-scientist-the-hot-new-gig-in-tech.html:text/html},
}

@book{james_introduction_2013,
	address = {New York, NY},
	series = {Springer {Texts} in {Statistics}},
	title = {An {Introduction} to {Statistical} {Learning}},
	volume = {103},
	isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
	url = {http://link.springer.com/10.1007/978-1-4614-7138-7},
	language = {en},
	urldate = {2020-12-11},
	publisher = {Springer New York},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	doi = {10.1007/978-1-4614-7138-7},
	file = {James et al. - 2013 - An Introduction to Statistical Learning.pdf:/Users/rca2t1/Dropbox/Zotero/storage/JT5R6T4W/James et al. - 2013 - An Introduction to Statistical Learning.pdf:application/pdf},
}

@article{vapnik_overview_1999,
	title = {An overview of statistical learning theory},
	volume = {10},
	issn = {1941-0093},
	doi = {10.1109/72.788640},
	abstract = {Statistical learning theory was introduced in the late 1960's. Until the 1990's it was a purely theoretical analysis of the problem of function estimation from a given collection of data. In the middle of the 1990's new types of learning algorithms (called support vector machines) based on the developed theory were proposed. This made statistical learning theory not only a tool for the theoretical analysis but also a tool for creating practical algorithms for estimating multidimensional functions. This article presents a very general overview of statistical learning theory including both theoretical and algorithmic aspects of the theory. The goal of this overview is to demonstrate how the abstract learning theory established conditions for generalization which are more general than those discussed in classical statistical paradigms and how the understanding of these conditions inspired new algorithmic approaches to function estimation problems.},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Vapnik, V. N.},
	month = sep,
	year = {1999},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {learning (artificial intelligence), Algorithm design and analysis, Support vector machines, Machine learning, estimation theory, function estimation, generalisation (artificial intelligence), generalization conditions, Loss measurement, multidimensional function estimation, Multidimensional systems, Pattern recognition, Probability distribution, Risk management, statistical analysis, Statistical learning, statistical learning theory, support vector machines},
	pages = {988--999},
	file = {IEEE Xplore Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/U6L46GGN/Vapnik - 1999 - An overview of statistical learning theory.pdf:application/pdf},
}

@incollection{bousquet_introduction_2004,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Introduction to {Statistical} {Learning} {Theory}},
	isbn = {978-3-540-28650-9},
	url = {https://doi.org/10.1007/978-3-540-28650-9_8},
	abstract = {The goal of statistical learning theory is to study, in a statistical framework, the properties of learning algorithms. In particular, most results take the form of so-called error bounds. This tutorial introduces the techniques that are used to obtain such results.},
	language = {en},
	urldate = {2020-12-11},
	booktitle = {Advanced {Lectures} on {Machine} {Learning}: {ML} {Summer} {Schools} 2003, {Canberra}, {Australia}, {February} 2 - 14, 2003, {Tübingen}, {Germany}, {August} 4 - 16, 2003, {Revised} {Lectures}},
	publisher = {Springer},
	author = {Bousquet, Olivier and Boucheron, Stéphane and Lugosi, Gábor},
	editor = {Bousquet, Olivier and von Luxburg, Ulrike and Rätsch, Gunnar},
	year = {2004},
	doi = {10.1007/978-3-540-28650-9_8},
	keywords = {Empirical Process, Empirical Risk, Growth Function, Statistical Learn Theory, Structural Risk Minimization},
	pages = {169--207},
	file = {Springer Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/5DNXUWH5/Bousquet et al. - 2004 - Introduction to Statistical Learning Theory.pdf:application/pdf},
}

@misc{noauthor_introduction_nodate,
	title = {Introduction to {Statistical} {Learning} {Theory} and {Support} {Vector} {Machines}},
	url = {http://en.cnki.com.cn/Article_en/CJFDTotal-MOTO200001005.htm},
	urldate = {2020-12-11},
	file = {INTRODUCTION TO STATISTICAL LEARNING THEORY AND SUPPORT VECTOR MACHINES--《自动化学报》2000年01期:/Users/rca2t1/Dropbox/Zotero/storage/NFHPFP4L/CJFDTotal-MOTO200001005.html:text/html},
}

@incollection{luxburg_statistical_2011,
	series = {Inductive {Logic}},
	title = {Statistical {Learning} {Theory}: {Models}, {Concepts}, and {Results}},
	volume = {10},
	shorttitle = {Statistical {Learning} {Theory}},
	url = {http://www.sciencedirect.com/science/article/pii/B9780444529367500161},
	abstract = {Statistical learning theory is regarded as one of the most beautifully developed branches of artificial intelligence. It provides the theoretical basis for many of today's machine learning algorithms. The theory helps to explore what permits to draw valid conclusions from empirical data. This chapter provides an overview of the key ideas and insights of statistical learning theory. The statistical learning theory begins with a class of hypotheses and uses empirical data to select one hypothesis from the class. If the data generating mechanism is benign, then it is observed that the difference between the training error and test error of a hypothesis from the class is small. The statistical learning theory generally avoids metaphysical statements about aspects of the true underlying dependency, and thus is precise by referring to the difference between training and test error. The chapter also describes some other variants of machine learning.},
	language = {en},
	urldate = {2020-12-11},
	booktitle = {Handbook of the {History} of {Logic}},
	publisher = {North-Holland},
	author = {Luxburg, Ulrike von and Schölkopf, Bernhard},
	editor = {Gabbay, Dov M. and Hartmann, Stephan and Woods, John},
	month = jan,
	year = {2011},
	doi = {10.1016/B978-0-444-52936-7.50016-1},
	pages = {651--706},
	annote = {Statistical learning theory provides the theoretical basis for machine learning algorithms.},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/WDD5LSQ6/Luxburg and Schölkopf - 2011 - Statistical Learning Theory Models, Concepts, and.pdf:application/pdf;ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/HSFC5WHR/B9780444529367500161.html:text/html;ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2ZQIP6P5/B9780444529367500161.html:text/html},
}

@article{estes_analysis_1954,
	title = {Analysis of a verbal conditioning situation in terms of statistical learning theory},
	volume = {47},
	issn = {0022-1015(Print)},
	doi = {10.1037/h0060989},
	abstract = {Learning rates, asymptotic behavior, and sequential properties of response in a verbal conditioning situation were studied in relation to predictions from statistical learning theory. The experimental situation was one in which S was asked to predict which one of two events would occur when the probability is controlled by E. In general it was found that the rate of learning was related to the difference between initial response probability and probability of reinforcement during a series. It was also noted that Ss did not respond to a series as a whole, but that sensitivity to the effects of reinforcements and nonreinforcements increased as a function of trials. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Experimental Psychology},
	author = {Estes, W. K. and Straughan, J. H.},
	year = {1954},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Statistics, Conditioning, Learning Theory, Verbal Learning},
	pages = {225--234},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RJUEFUSH/1955-00445-001.html:text/html},
}

@article{gureckis_behaviorism_nodate,
	title = {Behaviorism {Reborn}? {Statistical} {Learning} as {Simple} {Conditioning}},
	language = {en},
	author = {Gureckis, Todd M},
	pages = {6},
	file = {Gureckis - Behaviorism Reborn Statistical Learning as Simple.pdf:/Users/rca2t1/Dropbox/Zotero/storage/4THHSQMB/Gureckis - Behaviorism Reborn Statistical Learning as Simple.pdf:application/pdf},
}

@incollection{mendelson_few_2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Few} {Notes} on {Statistical} {Learning} {Theory}},
	isbn = {978-3-540-36434-4},
	url = {https://doi.org/10.1007/3-540-36434-X_1},
	abstract = {In these notes our aim is to survey recent (and not so recent) results regarding the mathematical foundations of learning theory. The focus in this article is on the theoretical side and not on the applicative one; hence, we shall not present examples which may be interesting from the practical point of view but have little theoretical significance. This survey is far from being complete and it focuses on problems the author finds interesting (an opinion which is not necessarily shared by the majority of the learning community). Relevant books which present a more evenly balanced approach are, for example 1, 4, 34, 35},
	language = {en},
	urldate = {2020-12-11},
	booktitle = {Advanced {Lectures} on {Machine} {Learning}: {Machine} {Learning} {Summer} {School} 2002 {Canberra}, {Australia}, {February} 11–22, 2002 {Revised} {Lectures}},
	publisher = {Springer},
	author = {Mendelson, Shahar},
	editor = {Mendelson, Shahar and Smola, Alexander J.},
	year = {2003},
	doi = {10.1007/3-540-36434-X_1},
	keywords = {Empirical Process, Absolute Constant, Boolean Function, Empirical Measure, Reproduce Kernel Hilbert Space},
	pages = {1--40},
	file = {Springer Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/Y6Z5FJ2W/Mendelson - 2003 - A Few Notes on Statistical Learning Theory.pdf:application/pdf},
}

@book{emmert-streib_information_2009,
	title = {Information {Theory} and {Statistical} {Learning}},
	isbn = {978-0-387-84815-0},
	abstract = {Information Theory and Statistical Learning presents theoretical and practical results about information theoretic methods used in the context of statistical learning.  The book will present a comprehensive overview of the large range of different methods that have been developed in a multitude of contexts. Each chapter is written by an expert in the field. The book is intended for an interdisciplinary readership working in machine learning, applied statistics, artificial intelligence, biostatistics, computational biology, bioinformatics, web mining or related disciplines. Advance Praise for Information Theory and Statistical Learning: "A new epoch has arrived for information sciences to integrate various disciplines such as information theory, machine learning, statistical inference, data mining, model selection etc. I am enthusiastic about recommending the present book to researchers and students, because it summarizes most of these new emerging subjects and methods, which are otherwise scattered in many places." -- Shun-ichi Amari, RIKEN Brain Science Institute, Professor-Emeritus at the University of Tokyo},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Emmert-Streib, Frank and Dehmer, Matthias},
	year = {2009},
	note = {Google-Books-ID: WGTF7daUvD4C},
	keywords = {Computers / Information Technology, Computers / Computer Science, Computers / Information Theory, Computers / Data Processing, Technology \& Engineering / Automation, Computers / Intelligence (AI) \& Semantics, Language Arts \& Disciplines / Library \& Information Science / General, Technology \& Engineering / Telecommunications, Mathematics / Discrete Mathematics, Mathematics / Probability \& Statistics / General, Medical / Biotechnology},
}

@book{vapnik_statistical_1998,
	title = {Statistical {Learning} {Theory}},
	isbn = {978-0-471-03003-4},
	abstract = {Introduction: The Problem of Induction and Statistical Inference. Two Approaches to the Learning Problem. Appendix to Chapter1: Methods for Solving III-Posed Problems. Estimation of the Probability Measure and Problem of Learning. Conditions for Consistency of Empirical Risk Minimization Principle. Bounds on the Risk for Indicator Loss Functions. Appendix to Chapter 4: Lower Bounds on the Risk of the ERM Principle. Bounds on the Risk for Real-Valued Loss Functions. The Structural Risk Minimization Principle. Appendix to Chapter 6: Estimating Functions on the Basis of Indirect Measurements. Stochastic III-Posed Problems. Estimating the Values of Function at Given Points. Perceptrons and Their Generalizations. The Support Vector Method for Estimating Indicator Functions. The Support Vector Method for Estimating Real-Valued Functions. SV Machines for Pattern Recognition. SV Machines for Function Approximations, Regression Estimation, and Signal Processing. Necessary and Sufficient Conditions for Uniform Convergence of Frequencies to Their Probabilities. Necessary and Sufficient Conditions for Uniform Convergence of Means to Their Expectations. Necessary and Sufficient Conditions for Uniform One-Sided Convergence of Means to Their Expectations.},
	language = {en},
	publisher = {Wiley},
	author = {Vapnik, Vladimir N. and VAPNIK, VLADIMIR AUTOR},
	month = sep,
	year = {1998},
	note = {Google-Books-ID: GowoAQAAMAAJ},
	keywords = {Computers / Intelligence (AI) \& Semantics, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes, Mathematics / Mathematical Analysis},
	annote = {Statistical learning theory explores ways of estimating functional dependency from a given collection of data.
Or: SLT estimates dependency from data.
What is dependency? How is related to Causality? Significance? Meaning? Information?
},
}

@book{estes_foundations_1959,
	title = {Foundations of {Statistical} {Learning} {Theory}: {The} stimulus sampling model},
	shorttitle = {Foundations of {Statistical} {Learning} {Theory}},
	language = {en},
	publisher = {Behavioral Sciences Division, Applied Mathematics and Statistics Laboratory, Stanford University},
	author = {Estes, William Kaye and Suppes, Patrick},
	year = {1959},
}

@article{atkinson_analysis_1958,
	title = {An analysis of two-person game situations in terms of statistical learning theory},
	volume = {55},
	issn = {0022-1015(Print)},
	doi = {10.1037/h0044476},
	abstract = {"The study deals with an analysis of a zero-sum, two-person game situation in terms of statistical learning theory and game theory… . Analysis of the data was in terms of two different but related stochastic models for learning and game theory. Specifically the following detailed comparisons of data and theory were made: (a) mean asymptotic response probabilities, (b) one- and two-stage transition probabilities, and (c) variances associated with asymptotic response probabilities." (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Experimental Psychology},
	author = {Atkinson, Richard C. and Suppes, Patrick},
	year = {1958},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Learning Theory, Games},
	pages = {369--378},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NPK5CJFS/1959-07689-001.html:text/html;Submitted Version:/Users/rca2t1/Dropbox/Zotero/storage/DJQSSKY5/Atkinson and Suppes - 1958 - An analysis of two-person game situations in terms.pdf:application/pdf},
}

@article{estes_toward_1950,
	title = {Toward a {Statistical} {Theory} of {Learning}},
	volume = {57},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/h0058559},
	abstract = {"An attempt has been made to clarify some issues in current learning theory by giving a statistical interpretation to the concepts of stimulus and response and by deriving quantitative laws that govern simple behavior systems. Dependent variables, in this formulation, are classes of behavior samples with common quantitative properties; independent variables are statistical distributions of environmental events. Laws of the theory state probability relations between momentary changes in behavioral and environmental variables. From this point of view it has been possible to derive simple relations between probability of response and several commonly used measures of learning, and to develop mathematical expressions describing learning in both classical conditioning and instrumental learning situations under simplified conditions." (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Review},
	author = {Estes, William K.},
	year = {1950},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Statistical Analysis, Learning Theory, Learning, Statistical Variables},
	pages = {94--107},
	file = {Estes - 1950 - Toward a Statistical Theory of Learning.pdf:/Users/rca2t1/Dropbox/Zotero/storage/JKLQRC7Q/Estes - 1950 - Toward a Statistical Theory of Learning.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/U2RGMMUL/1950-05093-001.html:text/html},
}

@inproceedings{aparicio_data_2019,
	title = {Data {Science} and {AI}: {Trends} {Analysis}},
	shorttitle = {Data {Science} and {AI}},
	doi = {10.23919/CISTI.2019.8760820},
	abstract = {This study has the primary goal to analyze the growth of data science through the main search trends. This study was conducted by defining in high level the concept of data science as well as its main components. Supported in those elements, we identified the main trends. We used mainly data from google trends to determine the evolution of search by topics., research area, or simple expressions. It allowed us to reckon that artificial intelligence (AI)suffered a lack of interest until 2012. Then it became an increasingly popular field since 2014. This is due to the progression of machine learning and data science. Results show a cumulative search of data science since 2012.},
	booktitle = {2019 14th {Iberian} {Conference} on {Information} {Systems} and {Technologies} ({CISTI})},
	author = {Aparicio, S. and Aparicio, J. T. and Costa, C. J.},
	month = jun,
	year = {2019},
	note = {ISSN: 2166-0727},
	keywords = {Computer science, AI, machine learning, search, trends, learning (artificial intelligence), artificial intelligence, Software, Mathematics, data science, Market research, Data science, Machine learning, google trends, programming languages, search engines, search problems, search trends},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/Users/rca2t1/Dropbox/Zotero/storage/GZU7KQFC/8760820.html:text/html;IEEE Xplore Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/H6C6S5UM/Aparicio et al. - 2019 - Data Science and AI Trends Analysis.pdf:application/pdf},
}

@article{buluswar_how_2016,
	title = {How companies are using big data and analytics},
	url = {https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/how-companies-are-using-big-data-and-analytics#signin/download/%2F~%2Fmedia%2FMcKinsey%2FBusiness%20Functions%2FMcKinsey%20Digital%2FOur%20Insights%2FHow%20companies%20are%20using%20big%20data%20and%20analytics%2FHow%20companies%20are%20using%20big%20data%20and%20analytics.pdf%3FshouldIndex%3Dfalse/1},
	abstract = {Just how do major organizations use data and analytics to inform strategic and operational decisions? Senior leaders provide insight into the challenges and opportunities.},
	urldate = {2020-12-18},
	journal = {McKinsey Analytics},
	author = {Buluswar, Murli},
	month = apr,
	year = {2016},
	file = {Buluswar - 1016 - How companies are using big data and analytics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/FTYEJGLV/Buluswar - 1016 - How companies are using big data and analytics.pdf:application/pdf;How companies are using big data and analytics:/Users/rca2t1/Dropbox/Zotero/storage/KHDL4DWA/how-companies-are-using-big-data-and-analytics.html:text/html},
}

@incollection{demchenko_emerging_2017,
	title = {The {Emerging} {Role} of the {Data} {Scientist} and the experience of {Data} {Science} education at the {University} of {Amsterdam}},
	author = {Demchenko, Yuri},
	month = jan,
	year = {2017},
	file = {Demchenko - 2017 - The Emerging Role of the Data Scientist and the ex.pdf:/Users/rca2t1/Dropbox/Zotero/storage/AFHGNMMD/Demchenko - 2017 - The Emerging Role of the Data Scientist and the ex.pdf:application/pdf},
}

@book{demchenko_instructional_2014,
	title = {Instructional {Model} for {Building} {Effective} {Big} {Data} {Curricula} for {Online} and {Campus} {Education}},
	abstract = {This paper presents current results and ongoing work to develop effective educational courses on the Big Data (BD) and Data Intensive Technologies (DIT) that is been done at the University of Amsterdam in cooperation with KPMG and by the Laureate Online Education (online partner of the University of Liverpool). The paper introduces the main Big Data concepts: multicomponent Big Data definition and Big Data Architecture Framework that provide the basis for defining the course structure and Common Body of Knowledge for Data Science and Big Data technology domains. The paper presents details on approach, learning model, and course content for two courses at the Laureate Online Education/University of Liverpool and at the University of Amsterdam. The paper provides also background information about existing initiatives and activities related to information exchange and coordination on developing educational materials and programs on Big Data, Data Science, and Research Data Management.},
	author = {Demchenko, Yuri and Gruengard, Emanuel and Klous, Sander},
	month = dec,
	year = {2014},
	doi = {10.1109/CloudCom.2014.162},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/G9WP2LZ7/Demchenko et al. - 2014 - Instructional Model for Building Effective Big Dat.pdf:application/pdf},
}

@article{mnushkin_adventures_2008,
	title = {Adventures with {Big} {Data}: {How} to {Import} 16 {Billion} {Rows} into a {Single} {Table}},
	volume = {10},
	url = {https://global.factiva.com/redir/default.aspx?P=sa&NS=16&AID=9VIV000400&an=SQLSRV0020080527e4610000t&cat=A&ep=ASI&napc=EV},
	abstract = {So here I was, writing some SQL Server 2005 Reporting Services (SSRS) reports for a user when a coworker asked if I could process some data for him. I'm the SQL Server guy at work, so I immediately volunteered to help.

The data arrived several days later on a 1TB external hard drive that contained 20,000 flat files taking up 400GB of space. The data consisted of latitude and longitude coordinates and three extra informational fields. I had no idea how many records the raw data represented because not all the latitude and longitude coordinates were to be included. For latitude and longitude coordinates to be included, their extra fields had to match certain criteria.},
	number = {6},
	journal = {SQL Server Magazine},
	author = {Mnushkin, Dmitry},
	month = jun,
	year = {2008},
}

@misc{bourne_is_2021,
	title = {Is ‘{Bioinformatics}’ {Dead}?},
	author = {Bourne, Philip E.},
	year = {2021},
	file = {Bourne - 2021 - Is ‘Bioinformatics’ Dead.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2A9K6F8X/Bourne - 2021 - Is ‘Bioinformatics’ Dead.pdf:application/pdf},
}

@misc{miyazaki_brief_2015,
	title = {A {Brief} {History} of {Data} {Analysis}},
	url = {https://flydata.com/blog/a-brief-history-of-data-analysis/},
	abstract = {Let's take a short journey together through the history of data analysis.},
	language = {en},
	urldate = {2021-03-27},
	author = {Miyazaki, Masashi},
	month = mar,
	year = {2015},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BQDL7BVC/a-brief-history-of-data-analysis.html:text/html},
}

@article{hoaglin_john_2003,
	title = {John {W}. {Tukey} and {Data} {Analysis}},
	volume = {18},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-18/issue-3/John-W-Tukey-and-Data-Analysis/10.1214/ss/1076102418.full},
	doi = {10.1214/ss/1076102418},
	abstract = {From the time that John W. Tukey started to do serious work in statistics, he was interested in problems and techniques of data analysis. Some people know him best for exploratory data analysis, which he pioneered, but he also made key contributions in analysis of variance, in regression and through a wide range of applications.This paper reviews illustrative contributions in these areas.},
	number = {3},
	urldate = {2021-03-27},
	journal = {Statistical Science},
	author = {Hoaglin, David C.},
	month = aug,
	year = {2003},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Analysis of variance, exploratory data analysis, regression},
	pages = {311--318},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/474RGY6Y/Hoaglin - 2003 - John W. Tukey and Data Analysis.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TTQSGFUL/1076102418.html:text/html},
}

@article{bryan_data_2017,
	title = {Data {Science}: {A} {Three} {Ring} {Circus} or a {Big} {Tent}?},
	shorttitle = {Data {Science}},
	url = {https://arxiv.org/abs/1712.07349v1},
	abstract = {This is part of a collection of discussion pieces on David Donoho's paper 50
Years of Data Science, appearing in Volume 26, Issue 4 of the Journal of
Computational and Graphical Statistics (2017).},
	language = {en},
	urldate = {2021-03-29},
	author = {Bryan, Jennifer and Wickham, Hadley},
	month = dec,
	year = {2017},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/5S8WVXNF/Bryan and Wickham - 2017 - Data Science A Three Ring Circus or a Big Tent.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/E5AP65AM/1712.html:text/html},
}

@article{carmichael_data_2018,
	title = {Data {Science} vs. {Statistics}: {Two} {Cultures}?},
	volume = {1},
	issn = {2520-8756, 2520-8764},
	shorttitle = {Data {Science} vs. {Statistics}},
	url = {http://arxiv.org/abs/1801.00371},
	doi = {10.1007/s42081-018-0009-3},
	abstract = {Data science is the business of learning from data, which is traditionally the business of statistics. Data science, however, is often understood as a broader, task-driven and computationally-oriented version of statistics. Both the term data science and the broader idea it conveys have origins in statistics and are a reaction to a narrower view of data analysis. Expanding upon the views of a number of statisticians, this paper encourages a big-tent view of data analysis. We examine how evolving approaches to modern data analysis relate to the existing discipline of statistics (e.g. exploratory analysis, machine learning, reproducibility, computation, communication and the role of theory). Finally, we discuss what these trends mean for the future of statistics by highlighting promising directions for communication, education and research.},
	number = {1},
	urldate = {2021-03-29},
	journal = {Japanese Journal of Statistics and Data Science},
	author = {Carmichael, Iain and Marron, J. S.},
	month = jun,
	year = {2018},
	note = {arXiv: 1801.00371},
	keywords = {Statistics - Other Statistics},
	pages = {117--138},
	file = {arXiv Fulltext PDF:/Users/rca2t1/Dropbox/Zotero/storage/YISREFG8/Carmichael and Marron - 2018 - Data Science vs. Statistics Two Cultures.pdf:application/pdf;arXiv.org Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2U5ERAIQ/1801.html:text/html},
}

@misc{yu_let_2014,
	title = {Let us own {Data} {Science}},
	shorttitle = {Institute of {Mathematical} {Statistics} {\textbar} {IMS} {Presidential} {Address}},
	url = {https://imstat.org/2014/10/01/ims-presidential-address-let-us-own-data-science/},
	abstract = {IMS Presidential Address.},
	language = {en},
	urldate = {2021-03-29},
	journal = {Institute of Mathematical Statistics},
	author = {Yu, Bin},
	month = oct,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/23YWM4IW/ims-presidential-address-let-us-own-data-science.html:text/html},
}

@incollection{kirschenbaum_digital_2011,
	title = {Digital {Humanities} {As}/{Is} a {Tactical} {Term}},
	volume = {I},
	shorttitle = {“{Chapter} 23},
	url = {https://dhdebates.gc.cuny.edu/read/untitled-88c11800-9446-469b-a3be-3fdb36bfbd1e/section/c0b0a8ee-95f0-4a9c-9451-e8ad168e3db5},
	language = {en-US},
	urldate = {2021-03-30},
	booktitle = {Debates in the {Digital} {Humanities}},
	publisher = {Univ of Minnesota Press},
	author = {Kirschenbaum, Mathew G.},
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/YAJH3ZLX/c0b0a8ee-95f0-4a9c-9451-e8ad168e3db5.html:text/html},
}

@article{englmeier_editorial_2017,
	title = {Editorial: {What} {Can} {We} {Expect} from {Data} {Scientists}},
	volume = {12},
	issn = {0718-1876},
	shorttitle = {Editorial},
	url = {https://scielo.conicyt.cl/scielo.php?script=sci_abstract&pid=S0718-18762017000100001&lng=es&nrm=iso&tlng=en},
	doi = {10.4067/S0718-18762017000100001},
	number = {1},
	urldate = {2021-04-16},
	journal = {Journal of theoretical and applied electronic commerce research},
	author = {Englmeier, Kurt and Murtagh, Fionn},
	year = {2017},
	note = {Publisher: Universidad de Talca},
	pages = {i--v},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/XDZLMDQD/Englmeier and Murtagh - 2017 - Editorial What Can We Expect from Data Scientists.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/KVL8GHDB/scielo.html:text/html},
}

@article{stone_facebook_2008,
	chapter = {Technology},
	title = {Facebook {Hires} {Google} {Executive} as {No}. 2},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2008/03/04/technology/04cnd-facebook.html},
	abstract = {A Google executive, Sheryl Sandberg, will join Facebook later this month as chief operating officer and will work closely with Mark Zuckerberg, Facebook’s co-founder.},
	language = {en-US},
	urldate = {2021-05-07},
	journal = {The New York Times},
	author = {Stone, Brad and Helft, Miguel},
	month = mar,
	year = {2008},
	keywords = {Google Inc, Appointments and Executive Changes, Facebook.com, Zuckerberg, Mark E},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/UNZJS6Y2/04cnd-facebook.html:text/html},
}

@article{noauthor_nature_2008,
	title = {Nature: {Big} {Data}: {Knowledge} in the {Petabyte} {Era}},
	volume = {455},
	copyright = {©2021 Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/nature/volumes/455/issues/7209},
	abstract = {B},
	language = {en},
	number = {7209},
	urldate = {2021-05-07},
	month = sep,
	year = {2008},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/YGYAF6RI/7209.html:text/html},
}

@article{brady_challenge_2019,
	title = {The {Challenge} of {Big} {Data} and {Data} {Science}},
	volume = {22},
	issn = {1094-2939},
	url = {https://doi.org/10.1146/annurev-polisci-090216-023229},
	doi = {10.1146/annurev-polisci-090216-023229},
	abstract = {Big data and data science are transforming the world in ways that spawn new concerns for social scientists, such as the impacts of the internet on citizens and the media, the repercussions of smart cities, the possibilities of cyber-warfare and cyber-terrorism, the implications of precision medicine, and the consequences of artificial intelligence and automation. Along with these changes in society, powerful new data science methods support research using administrative, internet, textual, and sensor-audio-video data. Burgeoning data and innovative methods facilitate answering previously hard-to-tackle questions about society by offering new ways to form concepts from data, to do descriptive inference, to make causal inferences, and to generate predictions. They also pose challenges as social scientists must grasp the meaning of concepts and predictions generated by convoluted algorithms, weigh the relative value of prediction versus causal inference, and cope with ethical challenges as their methods, such as algorithms for mobilizing voters or determining bail, are adopted by policy makers.},
	number = {1},
	urldate = {2021-05-07},
	journal = {Annual Review of Political Science},
	author = {Brady, Henry E.},
	month = may,
	year = {2019},
	note = {Publisher: Annual Reviews},
	pages = {297--323},
	annote = {doi: 10.1146/annurev-polisci-090216-023229},
	file = {Brady - 2019 - The Challenge of Big Data and Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/68BXS3XR/Brady - 2019 - The Challenge of Big Data and Data Science.pdf:application/pdf},
}

@article{chambers_greater_1993,
	title = {Greater or {Lesser} {Statistics}: {A} {Choice} for {Future} {Research}},
	volume = {3},
	issn = {1573-1375},
	shorttitle = {Greater or {Lesser} {Statistics}},
	url = {https://doi.org/10.1007/BF00141776},
	doi = {10.1007/BF00141776},
	language = {en},
	number = {4},
	urldate = {2021-05-09},
	journal = {Statistics and Computing},
	author = {Chambers, John M.},
	month = dec,
	year = {1993},
	pages = {182--184},
	file = {greater.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NE4G3NWG/greater.pdf:application/pdf;greater.ps:/Users/rca2t1/Dropbox/Zotero/storage/MR273URL/greater.ps:application/postscript},
}

@article{wickham_split-apply-combine_2011,
	title = {The split-apply-combine strategy for data analysis},
	volume = {40},
	number = {1},
	journal = {Journal of statistical software},
	author = {Wickham, Hadley},
	year = {2011},
	note = {Publisher: Citeseer},
	pages = {1--29},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/VZT7WABE/Wickham - 2011 - The split-apply-combine strategy for data analysis.pdf:application/pdf},
}

@incollection{beasley_bootstrapping_2012,
	title = {Bootstrapping and {Monte} {Carlo} methods},
	abstract = {Frequently a researcher is interested in a theoretical distribution or characteristics of that distribution, such as its mean, standard deviation, or 2.5 and 97.5 percentiles. One hundred or even 50 years ago, we were restricted practically by computing limitations to theoretical distributions that are described by an explicit equation, such as the binomial or multivariate normal distribution. Using mathematical models of distributions often requires considerable mathematical ability, and also imposes rather severe and often intractable assumptions on the applied researchers (e.g., normality, independence, variance assumptions, and so on). But computer simulations now provide more flexibility specifying distributions, which in turn provide more flexibility specifying models. One contemporary simulation technique is Markov chain Monte Carlo (MCMC) simulation, which can specify arbitrarily complex and nested multivariate distributions. It can even combine different theoretical families of variates. Another contemporary technique is the bootstrap, which can construct sampling distributions of conventional statistics that are free from most (but not all) assumptions. It can even create sampling distributions for new or exotic test statistics that the researcher created for a specific experiment},
	author = {Beasley, William and Rodgers, Joe},
	month = jan,
	year = {2012},
	doi = {10.1037/13620-022},
	pages = {407--425},
	annote = {Frequently a researcher is interested in a theoretical distribution or characteristics of that distribution, such as its mean, standard deviation, or 2.5 and 97.5 percentiles. One hundred or even 50 years ago, we were restricted practically by computing limitations to theoretical distributions that are described by an explicit equation, such as the binomial or multivariate normal distribution. Using mathematical models of distributions often requires considerable mathematical ability, and also imposes rather severe and often intractable assumptions on the applied researchers (e.g., normality, independence, variance assumptions, and so on). But computer simulations now provide more flexibility specifying distributions, which in turn provide more flexibility specifying models. One contemporary simulation technique is Markov chain Monte Carlo (MCMC) simulation, which can specify arbitrarily complex and nested multivariate distributions. It can even combine different theoretical families of variates. Another contemporary technique is the bootstrap, which can construct sampling distributions of conventional statistics that are free from most (but not all) assumptions. It can even create sampling distributions for new or exotic test statistics that the researcher created for a specific experiment . . .},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/DE4Q67GT/Beasley and Rodgers - 2012 - Bootstrapping and Monte Carlo methods.pdf:application/pdf},
}

@article{kuonen_data_2004,
	title = {Data mining and {Statistics}: {What} is the connection?},
	volume = {30},
	shorttitle = {Data mining and {Statistics}},
	journal = {The Data Administration Newsletter},
	author = {Kuonen, Diego},
	year = {2004},
	pages = {1--6},
	file = {Kuonen - 2004 - Data mining and Statistics What is the connection.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NJVNCSR9/Kuonen - 2004 - Data mining and Statistics What is the connection.pdf:application/pdf},
}

@article{friedman_data_1998,
	title = {Data {Mining} and {Statistics}: {What}'s the connection?},
	volume = {29},
	shorttitle = {Data {Mining} and {Statistics}},
	number = {1},
	journal = {Computing science and statistics},
	author = {Friedman, Jerome H.},
	year = {1998},
	note = {Publisher: Citeseer},
	pages = {3--9},
	file = {Friedman - 1998 - Data Mining and Statistics What's the connection.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RMRBPAIE/Friedman - 1998 - Data Mining and Statistics What's the connection.pdf:application/pdf},
}

@article{srivastava_understanding_2015,
	title = {Understanding {Linkage} {Between} {Data} {Mining} and {Statistics}},
	volume = {3},
	number = {10},
	journal = {International Journal of Engineering Technology, Management and Applied Sciences},
	author = {Srivastava, Jaya and Srivastava, Abhay Kumar},
	year = {2015},
	pages = {4--12},
	file = {Srivastava and Srivastava - 2015 - Understanding Linkage Between Data Mining and Stat.pdf:/Users/rca2t1/Dropbox/Zotero/storage/C3CS28JM/Srivastava and Srivastava - 2015 - Understanding Linkage Between Data Mining and Stat.pdf:application/pdf},
}

@article{grover_lure_2008,
	title = {The {Lure} of {Statistics} in {Data} {Mining}},
	volume = {16},
	number = {1},
	journal = {Journal of Statistics Education},
	author = {Grover, Lovleen Kumar and Mehra, Rajni},
	year = {2008},
	note = {Publisher: Taylor \& Francis},
	file = {Grover and Mehra - 2008 - The Lure of Statistics in Data Mining.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ZQN3JIKK/Grover and Mehra - 2008 - The Lure of Statistics in Data Mining.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/5GNWDIUY/10691898.2008.html:text/html},
}

@inproceedings{ganesh_data_2002,
	title = {Data {Mining}: {Should} {It} {Be} {Included} in the {Statistics} {Curriculum}},
	shorttitle = {Data {Mining}},
	booktitle = {The 6th international conference on teaching statistics ({ICOTS} 6), {Cape} {Town}, {South} {Africa}},
	author = {Ganesh, Siva},
	year = {2002},
	file = {Ganesh - 2002 - Data Mining Should It Be Included in the Statisti.pdf:/Users/rca2t1/Dropbox/Zotero/storage/TEA8TFYK/Ganesh - 2002 - Data Mining Should It Be Included in the Statisti.pdf:application/pdf},
}

@article{hassani_data_2014,
	title = {Data {Mining} and {Official} {Statistics}: {The} {Past}, the {Present} and the {Future}},
	volume = {2},
	shorttitle = {Data {Mining} and {Official} {Statistics}},
	number = {1},
	journal = {Big Data},
	author = {Hassani, Hossein and Saporta, Gilbert and Silva, Emmanuel Sirimal},
	year = {2014},
	note = {Publisher: Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA},
	pages = {34--43},
	file = {Hassani et al. - 2014 - Data Mining and Official Statistics The Past, the.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LC6D4N7L/Hassani et al. - 2014 - Data Mining and Official Statistics The Past, the.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3CPSU9UR/big.2013.html:text/html},
}

@article{zhou_three_2003,
	title = {Three {Perspectives} of {Data} {Mining}},
	volume = {143},
	number = {1},
	journal = {Artificial Intelligence},
	author = {Zhou, Zhi-Hua},
	year = {2003},
	note = {Publisher: Elsevier},
	pages = {139--146},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3FFISBCD/S0004370202003570.html:text/html;Zhou - 2003 - Three Perspectives of Data Mining.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ACDBIWFI/Zhou - 2003 - Three Perspectives of Data Mining.pdf:application/pdf},
}

@inproceedings{saporta_data_2000,
	title = {Data {Mining} and {Official} {Statistics}},
	booktitle = {Quinta {Conferenza} {Nationale} di {Statistica}},
	author = {Saporta, Gilbert},
	year = {2000},
	pages = {41--46},
	file = {Saporta - 2000 - Data Mining and Official Statistics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NG6E9BMU/Saporta - 2000 - Data Mining and Official Statistics.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/AK7797TW/hal-01124591.html:text/html},
}

@article{gupta_comprehensive_2020,
	title = {A {Comprehensive} {Survey} of {Data} {Mining}},
	journal = {International Journal of Information Technology},
	author = {Gupta, Manoj Kumar and Chandra, Pravin},
	year = {2020},
	note = {Publisher: Springer},
	pages = {1--15},
	file = {Gupta and Chandra - 2020 - A Comprehensive Survey of Data Mining.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LZG3C63C/Gupta and Chandra - 2020 - A Comprehensive Survey of Data Mining.pdf:application/pdf},
}

@article{kilic_data_2019,
	title = {Data {Mining} and {Statistics} in {Data} {Science}},
	author = {Kılıç, Güner Gözde and Turanlı, Münevver and Özden, Ünal Halit},
	year = {2019},
	file = {Kılıç et al. - 2019 - Data Mining and Statistics in Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/VQYC3DGI/Kılıç et al. - 2019 - Data Mining and Statistics in Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TQILA3Q2/3069.html:text/html},
}

@article{glymour_statistical_1996,
	title = {Statistical {Inference} and {Data} {Mining}},
	volume = {39},
	number = {11},
	journal = {Communications of the ACM},
	author = {Glymour, Clark and Madigan, David and Pregibon, Daryl and Smyth, Padhraic},
	year = {1996},
	note = {Publisher: ACM New York, NY, USA},
	pages = {35--41},
	annote = {"Statistics may have little to offer the search architectures in a data mining search, but a great deal to offer in evaluating hypotheses in the search, in evaluating the results of the search, and in applying the results"},
	file = {Glymour et al. - 1996 - Statistical Inference and Data Mining.pdf:/Users/rca2t1/Dropbox/Zotero/storage/I9NYG8NV/Glymour et al. - 1996 - Statistical Inference and Data Mining.pdf:application/pdf},
}

@article{brown_what_2015,
	title = {What {IT} {Needs} {To} {Know} {About} {The} {Data} {Mining} {Process}},
	url = {https://www.forbes.com/sites/metabrown/2015/07/29/what-it-needs-to-know-about-the-data-mining-process/},
	abstract = {No business can be data-driven if the only people interested in data analysis are the analysts. Just as the guidance of accountants and attorneys shapes everyday business, analytics must be integrated throughout the organization to provide value. But when it comes to getting everyone on board, accountants and attorneys have a [...]},
	language = {en},
	urldate = {2021-05-25},
	journal = {Forbes},
	author = {Brown, Meta S.},
	month = jul,
	year = {2015},
	note = {Section: Tech},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/X4JG4RZE/what-it-needs-to-know-about-the-data-mining-process.html:text/html},
}

@article{fayyad_knowledge_2001,
	title = {Knowledge discovery in databases: {An} overview},
	shorttitle = {Knowledge discovery in databases},
	journal = {Relational data mining},
	author = {Fayyad, Usama},
	year = {2001},
	note = {Publisher: Springer},
	pages = {28--47},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Q43AES9H/978-3-662-04599-2_2.html:text/html},
}

@article{matheus_systems_1993,
	title = {Systems for {Knowledge} {Discovery} in {Databases}},
	volume = {5},
	number = {6},
	journal = {IEEE Transactions on knowledge and data engineering},
	author = {Matheus, Christopher J. and Chan, Philip K. and Piatetsky-Shapiro, Gregory},
	year = {1993},
	note = {Publisher: IEEE},
	pages = {903--913},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/KHJIW874/250073.html:text/html},
}

@article{fayyad_data_1996-1,
	title = {From {Data} {Mining} to {Knowledge} {Discovery} in {Databases}},
	volume = {17},
	number = {3},
	journal = {AI magazine},
	author = {Fayyad, Usama and Piatetsky-Shapiro, Gregory and Smyth, Padhraic},
	year = {1996},
	pages = {37--37},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/ALPUIYBW/Fayyad et al. - 1996 - From data mining to knowledge discovery in databas.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3FD2J94L/1230.html:text/html},
}

@incollection{hipp_data_2002,
	title = {Data {Mining} of {Association} {Rules} and the {Process} of {Knowledge} {Discovery} in {Databases}},
	booktitle = {Advances in data mining},
	publisher = {Springer},
	author = {Hipp, Jochen and Güntzer, Ulrich and Nakhaeizadeh, Gholamreza},
	year = {2002},
	pages = {15--36},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/LKASCA4W/Hipp et al. - 2002 - Data mining of association rules and the process o.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/333PTWST/3-540-46131-0_2.html:text/html},
}

@article{frawley_knowledge_1992,
	title = {Knowledge {Discovery} in {Databases}: {An} {Overview}},
	volume = {13},
	shorttitle = {Knowledge {Discovery} in {Databases}},
	number = {3},
	journal = {AI magazine},
	author = {Frawley, William J. and Piatetsky-Shapiro, Gregory and Matheus, Christopher J.},
	year = {1992},
	pages = {57--57},
	file = {Frawley et al. - 1992 - Knowledge discovery in databases An overview.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LBVZ58DS/Frawley et al. - 1992 - Knowledge discovery in databases An overview.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6AGPGY35/1011.html:text/html},
}

@inproceedings{brachman_process_1994,
	title = {The {Process} of {Knowledge} {Discovery} in {Databases}: {A} {First} {Sketch}.},
	volume = {3},
	shorttitle = {The {Process} of {Knowledge} {Discovery} in {Databases}},
	booktitle = {{KDD} workshop},
	author = {Brachman, Ronald J. and Anand, Tej},
	year = {1994},
	pages = {1--12},
	file = {Brachman and Anand - 1994 - The Process of Knowledge Discovery in Databases A.pdf:/Users/rca2t1/Dropbox/Zotero/storage/BS2Y93JI/Brachman and Anand - 1994 - The Process of Knowledge Discovery in Databases A.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/7MZ65QIU/ws94-03-001.html:text/html},
}

@article{colak_data_2012,
	title = {Data mining and wind power prediction: {A} literature review},
	volume = {46},
	shorttitle = {Data mining and wind power prediction},
	journal = {Renewable Energy},
	author = {Colak, Ilhami and Sagiroglu, Seref and Yesilbudak, Mehmet},
	year = {2012},
	note = {Publisher: Elsevier},
	pages = {241--247},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/VFHPTSXN/S0960148112001541.html:text/html},
}

@article{chien_data_2008,
	title = {Data mining to improve personnel selection and enhance human capital: {A} case study in high-technology industry},
	volume = {34},
	shorttitle = {Data mining to improve personnel selection and enhance human capital},
	number = {1},
	journal = {Expert Systems with applications},
	author = {Chien, Chen-Fu and Chen, Li-Fei},
	year = {2008},
	note = {Publisher: Elsevier},
	pages = {280--290},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/SNL7AXP6/S0957417406002776.html:text/html},
}

@article{chen_data_1996,
	title = {Data {Mining}: {An} {Overview} from a {Database} {Perspective}},
	volume = {8},
	shorttitle = {Data {Mining}},
	number = {6},
	journal = {IEEE Transactions on Knowledge and data Engineering},
	author = {Chen, Ming-Syan and Han, Jiawei and Yu, Philip S.},
	year = {1996},
	note = {Publisher: IEEE},
	pages = {866--883},
	file = {Chen et al. - 1996 - Data Mining An Overview from a Database Perspecti.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NIW5W276/Chen et al. - 1996 - Data Mining An Overview from a Database Perspecti.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BHRHAK2I/553155.html:text/html},
}

@article{shafique_comparative_2014,
	title = {A {Comparative} {Study} of {Data} {Mining} {Process} {Models} (kdd, {Crisp}-{Dm} and {Semma})},
	volume = {12},
	number = {1},
	journal = {International Journal of Innovation and Scientific Research},
	author = {Shafique, Umair and Qaiser, Haseeb},
	year = {2014},
	note = {Publisher: Citeseer},
	pages = {217--222},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/2X47PUTJ/Shafique and Qaiser - 2014 - A comparative study of data mining process models .pdf:application/pdf},
}

@article{simoudis_reality_1996,
	title = {Reality {Check} for {Data} {Mining}},
	volume = {11},
	issn = {1541-1672},
	url = {https://www.computer.org/csdl/magazine/ex/1996/05/x5026/13rRUx0xPx9},
	doi = {10.1109/64.539014},
	abstract = {TO COMPETE EFFECTIVELY IN today's marketplace, business managers must take timely advantage of high-return opportunities. Doing so requires that they be able to exploit the mountains of data their organizations generate and collect during daily operations. Yet, the difficulty of discerning the value in that information--of separating the wheat from the chaff--prevents many companies from fully capitalizing on the wealth of data at their disposal. For example, a bank account manager might want to identify a group of married, two-income, affluent customers and send them information about the bank's growth mutual funds, before a competing discount broker can lure them away. The information surely resides in the bank's computer system--and has probably been there in some form for years. The trick, of course, is to find an efficient way to extract and apply it. Data mining -- the process of extracting valid, previously unknown, comprehensible, and actionable information from large databases and using it to make crucial business decisions--currently performs this task for a growing range of businesses. After presenting an overview of current data-mining techniques, this article explores two particularly noteworthy applications of those techniques: market basket analysis and customer segmentation.},
	language = {English},
	number = {05},
	urldate = {2021-05-26},
	journal = {IEEE Intelligent Systems},
	author = {Simoudis, Evangelos},
	month = sep,
	year = {1996},
	note = {Publisher: IEEE Computer Society},
	pages = {26--33},
	file = {Simoudis - 1996 - Reality Check for Data Mining.pdf:/Users/rca2t1/Dropbox/Zotero/storage/B7XEYRRJ/Simoudis - 1996 - Reality Check for Data Mining.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/8EP4B47R/13rRUx0xPx9.html:text/html},
}

@article{lee_postcards_2002,
	chapter = {Technology},
	title = {Postcards {From} {Planet} {Google}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2002/11/28/technology/postcards-from-planet-google.html},
	abstract = {Popular search engine Google tracks user queries to create snapshot of trends; finds that, despite geographic and ethnic diversity, people are spending much of their time thinking about same things; photos (M)},
	language = {en-US},
	urldate = {2021-05-26},
	journal = {The New York Times},
	author = {Lee, Jennifer 8},
	month = nov,
	year = {2002},
	keywords = {Computers and the Internet, GOOGLE},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BEB63UBK/postcards-from-planet-google.html:text/html},
}

@book{levy_plex_2012,
	edition = {Unabridged edition},
	title = {In {The} {Plex}: {How} {Google} {Thinks}, {Works}, and {Shapes} {Our} {Lives}},
	isbn = {978-1-4558-7572-6},
	shorttitle = {In {The} {Plex}},
	abstract = {Few companies in history have ever been as successful and as admired as Google, the company that has transformed the Internet and become an indispensable part of our lives. How has Google done it? Veteran technology reporter Steven Levy was granted unprecedented access to the company, and in this revelatory book he takes readers inside Google headquarters — the Googleplex — to show how Google works. While they were still students at Stanford, Google cofounders Larry Page and Sergey Brin revolutionized Internet search. They followed this brilliant innovation with another, as two of Google’s earliest employees found a way to do what no one else had: make billions of dollars from Internet advertising. With this cash cow (until Google’s IPO nobody other than Google management had any idea how lucrative the company’s ad business was), Google was able to expand dramatically and take on other transformative projects: more efficient data centers, open-source cell phones, free Internet video (YouTube), cloud computing, digitizing books, and much more. The key to Google’s success in all these businesses, Levy reveals, is its engineering mind-set and adoption of such Internet values as speed, openness, experimentation, and risk taking. After its unapologetically elitist approach to hiring, Google pampers its engineers — free food and dry cleaning, on-site doctors and masseuses — and gives them all the resources they need to succeed. Even today, with a workforce of more than 23,000, Larry Page signs off on every hire. But has Google lost its innovative edge? It stumbled badly in China—Levy discloses what went wrong and how Brin disagreed with his peers on the China strategy—and now with its newest initiative, social networking, Google is chasing a successful competitor for the first time. Some employees are leaving the company for smaller, nimbler start-ups. Can the company that famously decided not to be evil still compete? No other book has ever turned Google inside out as Levy does with In the Plex.},
	language = {English},
	publisher = {Brilliance Audio},
	author = {Levy, Steven and Ganser, L. J.},
	month = apr,
	year = {2012},
	file = {Steven Levy - In The Plex_ How Google Thinks, Works, and Shapes Our Lives-Simon & Schuster (2011).pdf:/Users/rca2t1/Dropbox/Zotero/storage/9IIQHICQ/Steven Levy - In The Plex_ How Google Thinks, Works, and Shapes Our Lives-Simon & Schuster (2011).pdf:application/pdf;Steven Levy - In The Plex_ How Google Thinks, Works, and Shapes Our Lives-Simon & Schuster Adult Publishing Group (2011).epub:/Users/rca2t1/Dropbox/Zotero/storage/LNYX8D35/Steven Levy - In The Plex_ How Google Thinks, Works, and Shapes Our Lives-Simon & Schuster Adult Publishing Group (2011).epub:application/epub+zip},
}

@article{azevedo_kdd_2008,
	title = {{KDD}, {SEMMA} and {CRISP}-{DM}: a parallel overview},
	shorttitle = {{KDD}, {SEMMA} and {CRISP}-{DM}},
	journal = {IADS-DM},
	author = {Azevedo, Ana Isabel Rojão Lourenço and Santos, Manuel Filipe},
	year = {2008},
	file = {Azevedo and Santos - 2008 - KDD, SEMMA and CRISP-DM a parallel overview.pdf:/Users/rca2t1/Dropbox/Zotero/storage/S3RTYB4Y/Azevedo and Santos - 2008 - KDD, SEMMA and CRISP-DM a parallel overview.pdf:application/pdf},
}

@book{azevedo_kdd_2019,
	title = {{KDD}, {SEMMA} and {CRISP}-{DM}: a parallel overview. {IADS}—{DM} (2008)},
	shorttitle = {{KDD}, {SEMMA} and {CRISP}-{DM}},
	author = {Azevedo, AIRL and Santos, M. F.},
	year = {2019},
}

@article{wiemer_data_2019,
	title = {Data {Mining} {Methodology} for {Engineering} {Applications} ({DMME})—{A} {Holistic} {Extension} to the {CRISP}-{DM} {Model}},
	volume = {9},
	number = {12},
	journal = {Applied Sciences},
	author = {Wiemer, Hajo and Drowatzky, Lucas and Ihlenfeldt, Steffen},
	year = {2019},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	pages = {2407},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/YH8U25TQ/2407.html:text/html;Wiemer et al. - 2019 - Data Mining Methodology for Engineering Applicatio.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HV3KUVNV/Wiemer et al. - 2019 - Data Mining Methodology for Engineering Applicatio.pdf:application/pdf},
}

@article{sveinsdottir_datalogy_1988-2,
	title = {Datalogy - {The} {Copenhagen} {Tradition} of {Computer} {Science}.},
	volume = {28},
	doi = {10.1007/BF01941128},
	abstract = {Since the middle of the 1960s, computer science has been practised in Denmark under Peter Naur's term datalogy, the science of data and data processes. Starting at Regnecentralen and the University of Copenhagen, the Copenhagen Tradition of computer science has developed its own special characteristics by means of a close connection with applications and other fields of knowledge. The tradition is not least visible in the area of education. Comprehensive project activity is an integral part of the curriculum, thus presenting theory as an aspect of realistic solutions known primarily through actual experience. Peter Naur early recognized the particular educational challenges presented by computer science. His innovations have shown their quality and vitality also at other universities. There is a close connection between computer science training as it has been formed at Copenhagen University, and the view of computer science which has characterized Peter Naur's research. We illustrate how the study of programming and system development conceived as a human activity has been an all-pervasive theme in Naur's work. This approach has set the scene for central research issues in software development which today seem more topical than ever.},
	journal = {BIT},
	author = {Sveinsdottir, Edda and Frøkjær, Erik},
	month = sep,
	year = {1988},
	pages = {450--472},
	file = {Sveinsdottir and Frøkjær - 1988 - Datalogy - The Copenhagen Tradition of Computer Sc.pdf:/Users/rca2t1/Dropbox/Zotero/storage/8ZLMR8DY/Sveinsdottir and Frøkjær - 1988 - Datalogy - The Copenhagen Tradition of Computer Sc.pdf:application/pdf},
}

@misc{berkeley_school_of_information_what_2021,
	type = {Academic {Program}},
	title = {What is {Data} {Science}?},
	shorttitle = {What is {Data} {Science}?},
	url = {https://ischoolonline.berkeley.edu/data-science/what-is-data-science/},
	abstract = {Data science continues to evolve as one of the most promising and in-demand career paths for skilled professionals. Learn what data science is and how to become a data scientist.},
	language = {en-US},
	urldate = {2021-06-25},
	journal = {UCB-UMT},
	author = {{Berkeley School of Information}},
	month = mar,
	year = {2021},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ZBQP5HMR/what-is-data-science.html:text/html},
}

@article{fayyad_toward_2020,
	title = {Toward {Foundations} for {Data} {Science} and {Analytics}: {A} {Knowledge} {Framework} for {Professional} {Standards}},
	volume = {2},
	issn = {,},
	shorttitle = {Toward {Foundations} for {Data} {Science} and {Analytics}},
	url = {https://hdsr.mitpress.mit.edu/pub/6wx0qmkl/release/3},
	doi = {10.1162/99608f92.1a99e67a},
	abstract = {As the industry is racing to harness the power of data, demand for data science professionals is growing at an increasing rate. However, almost every organization has a unique way of defining roles in data science and associated skills and knowledge. This has resulted in a confusing industry landscape for employers, academic and training institutions, and existing and aspiring data science professionals. This article is the first in a series authored by Initiative for Analytics and Data Science Standards (IADSS). We review the history of data science, which we trace back to 1974, and the emergence of data science as a profession in the industry, followed by a classification of knowledge and skills commonly associated with data science professionals, pointing to a lack of detailed and consistent treatment of the topic. We then present a Data Science Knowledge Framework, that we believe can support industry standardization and building measurement and assessment methodologies for data science professionals.},
	language = {en},
	number = {2},
	urldate = {2021-06-30},
	journal = {Harvard Data Science Review},
	author = {Fayyad, Usama and Hamutcu, Hamit},
	month = jun,
	year = {2020},
	note = {Publisher: PubPub},
	file = {Fayyad and Hamutcu - 2020 - Toward Foundations for Data Science and Analytics.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2ZDG52Y2/Fayyad and Hamutcu - 2020 - Toward Foundations for Data Science and Analytics.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/N8CI9X9R/3.html:text/html},
}

@article{nilsson_approaches_1993,
	title = {Approaches to {Artificial} {Intelligence}},
	journal = {Santa Fe Institute, NM},
	author = {Nilsson, N. J. and Rumelhart, David},
	year = {1993},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/YL6P436J/Nilsson and Rumelhart - 1993 - Approaches to Artificial Intelligence.pdf:application/pdf},
}

@article{russell_artificial_2002,
	title = {Artificial intelligence: a modern approach},
	shorttitle = {Artificial intelligence},
	author = {Russell, Stuart and Norvig, Peter},
	year = {2002},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/AWEDLRBU/Russell and Norvig - 2002 - Artificial intelligence a modern approach.pdf:application/pdf},
}

@book{russell_artificial_1995,
	title = {Artificial {Intelligence}: {A} {Modern} {Approach}},
	isbn = {978-0-13-103805-9},
	shorttitle = {Artificial {Intelligence}},
	abstract = {Intelligent Agents - Stuart Russell and Peter Norvig show how intelligent agents can be built using AI methods, and explain how different agent designs are appropriate depending on the nature of the task and environment. Artificial Intelligence: A Modern Approach is the first AI text to present a unified, coherent picture of the field. The authors focus on the topics and techniques that are most promising for building and analyzing current and future intelligent systems. The material is comprehensive and authoritative, yet cohesive and readable. State of the Art - This book covers the most effective modern techniques for solving real problems, including simulated annealing, memory-bounded search, global ontologies, dynamic belief networks, neural networks, adaptive probabilistic networks, inductive logic programming, computational learning theory, and reinforcement learning. Leading edge AI techniques are integrated into intelligent agent designs, using examples and exercises to lead students from simple, reactive agents to advanced planning agents with natural language capabilities.},
	language = {en},
	publisher = {Prentice Hall},
	author = {Russell, Stuart Jonathan and Norvig, Peter},
	year = {1995},
	note = {Google-Books-ID: CUVeMwAACAAJ},
	file = {Russell and Norvig - 1995 - Artificial Intelligence A Modern Approach.pdf:/Users/rca2t1/Dropbox/Zotero/storage/DXF2CVUG/Russell and Norvig - 1995 - Artificial Intelligence A Modern Approach.pdf:application/pdf},
}

@article{hsu_algorithms_2004,
	title = {Algorithms for mining association rules in bag databases},
	volume = {166},
	number = {1-4},
	journal = {Information Sciences},
	author = {Hsu, Ping-Yu and Chen, Yen-Liang and Ling, Chun-Ching},
	year = {2004},
	note = {Publisher: Elsevier},
	pages = {31--47},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QWFZBS6B/S0020025503004079.html:text/html},
}

@inproceedings{tsai_new_2002,
	title = {A new fast algorithms for mining association rules in large databases},
	volume = {7},
	booktitle = {{IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	publisher = {IEEE},
	author = {Tsai, Cheng-Fa and Lin, Yi-Chau and Chen, Chi-Pin},
	year = {2002},
	pages = {6--pp},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/2WXDZ8Z7/1175703.html:text/html},
}

@article{usharani_fast_2013,
	title = {Fast algorithms for mining association rules in datamining},
	volume = {23},
	journal = {Int J Sci Technol Res},
	author = {Usharani, P.},
	year = {2013},
	note = {Publisher: Citeseer},
	pages = {21--30},
	file = {Usharani - 2013 - Fast algorithms for mining association rules in da.pdf:/Users/rca2t1/Dropbox/Zotero/storage/57IRGXBN/Usharani - 2013 - Fast algorithms for mining association rules in da.pdf:application/pdf},
}

@inproceedings{bailey_fast_2002,
	title = {Fast {Algorithms} for {Mining} {Emerging} {Patterns}},
	booktitle = {European {Conference} on {Principles} of {Data} {Mining} and {Knowledge} {Discovery}},
	publisher = {Springer},
	author = {Bailey, James and Manoukian, Thomas and Ramamohanarao, Kotagiri},
	year = {2002},
	pages = {39--50},
	file = {Bailey et al. - 2002 - Fast algorithms for mining emerging patterns.pdf:/Users/rca2t1/Dropbox/Zotero/storage/P5JA8YW4/Bailey et al. - 2002 - Fast algorithms for mining emerging patterns.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/PIGKCJFG/3-540-45681-3_4.html:text/html},
}

@inproceedings{agrawal_fast_1994,
	title = {Fast algorithms for mining association rules},
	volume = {1215},
	booktitle = {Proc. 20th int. conf. very large data bases, {VLDB}},
	publisher = {Citeseer},
	author = {Agrawal, Rakesh and Srikant, Ramakrishnan},
	year = {1994},
	pages = {487--499},
	file = {Agrawal and Srikant - 1994 - Fast algorithms for mining association rules.pdf:/Users/rca2t1/Dropbox/Zotero/storage/7Q5IF2WK/Agrawal and Srikant - 1994 - Fast algorithms for mining association rules.pdf:application/pdf},
}

@article{cui_algorithms_2000,
	title = {Algorithms for mining constrained association rules},
	volume = {23},
	number = {2},
	journal = {CHINESE JOURNAL OF COMPUTERS-CHINESE EDITION-},
	author = {Cui, Lixin and Yuan, Senmiao and Zhao, Chunxi},
	year = {2000},
	note = {Publisher: SCIENCE PRESS},
	pages = {216--220},
}

@book{srikant_fast_1996,
	title = {Fast algorithms for mining association rules and sequential patterns},
	publisher = {The University of Wisconsin-Madison},
	author = {Srikant, Ramakrishnan},
	year = {1996},
}

@inproceedings{terrizzano_datawrangling_2015,
	address = {Asilomar, California, USA},
	title = {{DataWrangling}: {The} {Challenging} {Journey} from the {Wild} to the {Lake}},
	author = {Terrizzano, Ignacio and Schwarz, Peter and Roth, Mary and Colino, John E.},
	month = jan,
	year = {2015},
	file = {Terrizzano et al. - 2015 - DataWrangling The Challenging Journey from the Wi.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2JN7B572/Terrizzano et al. - 2015 - DataWrangling The Challenging Journey from the Wi.pdf:application/pdf},
}

@article{wickham_tidy_2014,
	title = {Tidy {Data}},
	volume = {59},
	copyright = {Copyright (c) 2013 Hadley  Wickham},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v059i10},
	doi = {10.18637/jss.v059.i10},
	language = {en},
	number = {1},
	urldate = {2021-07-13},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	month = sep,
	year = {2014},
	note = {Number: 1},
	pages = {1--23},
	file = {Wickham - 2014 - Tidy Data.pdf:/Users/rca2t1/Dropbox/Zotero/storage/A6GHW3M4/Wickham - 2014 - Tidy Data.pdf:application/pdf},
}

@article{douglas-jones_introduction_2021,
	title = {Introduction: {Towards} an {Anthropology} of {Data}},
	volume = {27},
	issn = {1467-9655},
	shorttitle = {Introduction},
	url = {https://rai.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9655.13477},
	doi = {10.1111/1467-9655.13477},
	abstract = {The world is talking ‘data’. The early cross-disciplinary, business-orientated hype around the potential of ‘big’ data, with its promises of unprecedented insight into social life, has given way. Data now motivates a sweep of dystopian visions, from rampant commodification to the invasion of privacy, political manipulation, and shadowy data doubles. Yet anthropologists have been cautious in taking data itself as their object, even as the social life of data practices becomes manifest in our ethnographies. In this introduction, we argue for an anthropology of data that is ethnographically specific and theoretically ambitious, putting forward a case for why anthropological engagements with the data moment might be not only politically important but also conceptually generative.},
	language = {en},
	number = {S1},
	urldate = {2021-07-14},
	journal = {Journal of the Royal Anthropological Institute},
	author = {Douglas-Jones, Rachel and Walford, Antonia and Seaver, Nick},
	year = {2021},
	note = {\_eprint: https://rai.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9655.13477},
	pages = {9--25},
	file = {Douglas-Jones et al. - 2021 - Introduction Towards an Anthropology of Data.pdf:/Users/rca2t1/Dropbox/Zotero/storage/VUGZM7QU/Douglas-Jones et al. - 2021 - Introduction Towards an Anthropology of Data.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3SYSKLHC/1467-9655.html:text/html},
}

@misc{noauthor_fourth_nodate,
	title = {Fourth {Paradigm} {\textbar} {NNLM}},
	url = {https://nnlm.gov/data/thesaurus/fourth-paradigm},
	urldate = {2021-07-18},
	file = {Fourth Paradigm | NNLM:/Users/rca2t1/Dropbox/Zotero/storage/2M43FQDC/fourth-paradigm.html:text/html},
}

@article{agrawal_perspective_2016,
	title = {Perspective: {Materials} {Informatics} and {Big} {Data}: {Realization} of the “{Fourth} {Paradigm}” of {Science} in {Materials} {Science}},
	volume = {4},
	shorttitle = {Perspective},
	url = {https://aip.scitation.org/doi/10.1063%2F1.4946894},
	doi = {10.1063/1.4946894},
	abstract = {Our ability to collect “big data” has greatly surpassed our capability to analyze it, underscoring the emergence of the fourth paradigm of science, which is data-driven discovery. The need for data informatics is also emphasized by the Materials Genome Initiative (MGI), further boosting the emerging field of materials informatics. In this article, we look at how data-driven techniques are playing a big role in deciphering processing-structure-property-performance relationships in materials, with illustrative examples of both forward models (property prediction) and inverse models (materials discovery). Such analytics can significantly reduce time-to-insight and accelerate cost-effective materials discovery, which is the goal of MGI.},
	number = {5},
	urldate = {2021-07-18},
	journal = {APL Materials},
	author = {Agrawal, Ankit and Choudhary, Alok},
	month = may,
	year = {2016},
	note = {Publisher: American Institute of Physics},
	pages = {053208},
	file = {Agrawal and Choudhary - 2016 - Perspective Materials Informatics and Big Data R.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NH7SZ6CS/Agrawal and Choudhary - 2016 - Perspective Materials Informatics and Big Data R.pdf:application/pdf},
}

@article{agrawal_exploration_2014,
	title = {Exploration of {Data} {Science} {Techniques} to {Predict} {Fatigue} {Strength} of {Steel} from {Composition} and {Processing} {Parameters}},
	volume = {3},
	issn = {2193-9772},
	url = {https://doi.org/10.1186/2193-9772-3-8},
	doi = {10.1186/2193-9772-3-8},
	abstract = {This paper describes the use of data analytics tools for predicting the fatigue strength of steels. Several physics-based as well as data-driven approaches have been used to arrive at correlations between various properties of alloys and their compositions and manufacturing process parameters. Data-driven approaches are of significant interest to materials engineers especially in arriving at extreme value properties such as cyclic fatigue, where the current state-of-the-art physics based models have severe limitations. Unfortunately, there is limited amount of documented success in these efforts. In this paper, we explore the application of different data science techniques, including feature selection and predictive modeling, to the fatigue properties of steels, utilizing the data from the National Institute for Material Science (NIMS) public domain database, and present a systematic end-to-end framework for exploring materials informatics. Results demonstrate that several advanced data analytics techniques such as neural networks, decision trees, and multivariate polynomial regression can achieve significant improvement in the prediction accuracy over previous efforts, with R2 values over 0.97. The results have successfully demonstrated the utility of such data mining tools for ranking the composition and process parameters in the order of their potential for predicting fatigue strength of steels, and actually develop predictive models for the same.},
	language = {en},
	number = {1},
	urldate = {2021-07-18},
	journal = {Integrating Materials and Manufacturing Innovation},
	author = {Agrawal, Ankit and Deshpande, Parijat D. and Cecen, Ahmet and Basavarsu, Gautham P. and Choudhary, Alok N. and Kalidindi, Surya R.},
	month = dec,
	year = {2014},
	pages = {90--108},
	file = {Agrawal et al. - 2014 - Exploration of Data Science Techniques to Predict .pdf:/Users/rca2t1/Dropbox/Zotero/storage/M4CCUCK2/Agrawal et al. - 2014 - Exploration of Data Science Techniques to Predict .pdf:application/pdf},
}

@article{chen_big_2014,
	title = {Big {Data}: {A} {Survey}},
	volume = {19},
	issn = {1572-8153},
	shorttitle = {Big {Data}},
	url = {https://doi.org/10.1007/s11036-013-0489-0},
	doi = {10.1007/s11036-013-0489-0},
	abstract = {In this paper, we review the background and state-of-the-art of big data. We first introduce the general background of big data and review related technologies, such as could computing, Internet of Things, data centers, and Hadoop. We then focus on the four phases of the value chain of big data, i.e., data generation, data acquisition, data storage, and data analysis. For each phase, we introduce the general background, discuss the technical challenges, and review the latest advances. We finally examine the several representative applications of big data, including enterprise management, Internet of Things, online social networks, medial applications, collective intelligence, and smart grid. These discussions aim to provide a comprehensive overview and big-picture to readers of this exciting area. This survey is concluded with a discussion of open problems and future directions.},
	language = {en},
	number = {2},
	urldate = {2021-07-18},
	journal = {Mobile Networks and Applications},
	author = {Chen, Min and Mao, Shiwen and Liu, Yunhao},
	month = apr,
	year = {2014},
	pages = {171--209},
	file = {Chen et al. - 2014 - Big Data A Survey.pdf:/Users/rca2t1/Dropbox/Zotero/storage/7E6QDZ5T/Chen et al. - 2014 - Big Data A Survey.pdf:application/pdf},
}

@article{philip_chen_data-intensive_2014,
	title = {Data-{Intensive} {Applications}, {Challenges}, {Techniques} and {Technologies}: {A} {Survey} on {Big} {Data}},
	volume = {275},
	issn = {0020-0255},
	shorttitle = {Data-{Intensive} {Applications}, {Challenges}, {Techniques} and {Technologies}},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025514000346},
	doi = {10.1016/j.ins.2014.01.015},
	abstract = {It is already true that Big Data has drawn huge attention from researchers in information sciences, policy and decision makers in governments and enterprises. As the speed of information growth exceeds Moore’s Law at the beginning of this new century, excessive data is making great troubles to human beings. However, there are so much potential and highly useful values hidden in the huge volume of data. A new scientific paradigm is born as data-intensive scientific discovery (DISD), also known as Big Data problems. A large number of fields and sectors, ranging from economic and business activities to public administration, from national security to scientific researches in many areas, involve with Big Data problems. On the one hand, Big Data is extremely valuable to produce productivity in businesses and evolutionary breakthroughs in scientific disciplines, which give us a lot of opportunities to make great progresses in many fields. There is no doubt that the future competitions in business productivity and technologies will surely converge into the Big Data explorations. On the other hand, Big Data also arises with many challenges, such as difficulties in data capture, data storage, data analysis and data visualization. This paper is aimed to demonstrate a close-up view about Big Data, including Big Data applications, Big Data opportunities and challenges, as well as the state-of-the-art techniques and technologies we currently adopt to deal with the Big Data problems. We also discuss several underlying methodologies to handle the data deluge, for example, granular computing, cloud computing, bio-inspired computing, and quantum computing.},
	language = {en},
	urldate = {2021-07-18},
	journal = {Information Sciences},
	author = {Philip Chen, C. L. and Zhang, Chun-Yang},
	month = aug,
	year = {2014},
	keywords = {Big Data, Cloud computing, Data-intensive computing, e-Science, Parallel and distributed computing},
	pages = {314--347},
	file = {ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/7CJ388ER/S0020025514000346.html:text/html},
}

@misc{noauthor_is_nodate,
	title = {Is the {Fourth} {Paradigm} {Really} {New}?},
	url = {https://serc.carleton.edu/earthandmind/posts/4thpardigm.html},
	abstract = {Author suggests that the so-called \&quot;Fourth Paradigm\&quot; of Science, in which insights are development through examination of vast troves of already existing data, has been in use in geosciences for ...},
	language = {en},
	urldate = {2021-07-18},
	journal = {Posts},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JQXNW48F/4thpardigm.html:text/html},
}

@article{goble_impact_nodate,
	title = {The {Impact} of {Workflow} {Tools} on {Data}-centric {Research}},
	language = {en},
	author = {Goble, Carole and Roure, David De},
	pages = {4},
	file = {Goble and Roure - The Impact of Workflow Tools on Data-centric Resea.pdf:/Users/rca2t1/Dropbox/Zotero/storage/EFJY3NWF/Goble and Roure - The Impact of Workflow Tools on Data-centric Resea.pdf:application/pdf},
}

@misc{noauthor_impact_nodate,
	title = {"{The} {Impact} of {Workflow} {Tools} on {Data}-centric {Research}" - {Google} {Search}},
	url = {https://www.google.com/search?q=%22The+Impact+of+Workflow+Tools+on+Data-centric+Research%22&client=firefox-b-1-d&sxsrf=ALeKk02k2gS-OOrFfgs674x68JI68AdcMA%3A1626704305668&ei=sYn1YLijKN6v5NoPkZyjgAs&oq=%22The+Impact+of+Workflow+Tools+on+Data-centric+Research%22&gs_lcp=Cgdnd3Mtd2l6EAMyBQghEKABOgcIIxCwAxAnOgcIABBHELADOgcIABCwAxBDOgUIABCxAzoHCAAQsQMQQzoICAAQsQMQgwE6AggAOgQIIxAnOgoIABCHAhCxAxAUOgcIABCHAhAUOgQIABBDOgcIIxDqAhAnOgcILhDqAhAnOgQILhAnSgQIQRgAULuTJFjjoyRgvqYkaAJwAngAgAGPAYgByQeSAQMzLjaYAQCgAQGgAQKqAQdnd3Mtd2l6sAEKyAEKwAEB&sclient=gws-wiz&ved=0ahUKEwj4v6ziqe_xAhXeF1kFHRHOCLAQ4dUDCA0&uact=5},
	urldate = {2021-07-19},
	file = {"The Impact of Workflow Tools on Data-centric Research" - Google Search:/Users/rca2t1/Dropbox/Zotero/storage/AJXHXNAA/search.html:text/html},
}

@article{de_roure_anchors_2010,
	title = {Anchors in {Shifting} {Sand}: {The} {Primacy} of {Method} in the {Web} of {Data}},
	shorttitle = {Anchors in {Shifting} {Sand}},
	author = {De Roure, David and Goble, Carole},
	year = {2010},
	file = {De Roure and Goble - 2010 - Anchors in Shifting Sand The Primacy of Method in.pdf:/Users/rca2t1/Dropbox/Zotero/storage/UST6JB6U/De Roure and Goble - 2010 - Anchors in Shifting Sand The Primacy of Method in.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/T3KBIXTP/270817.html:text/html},
}

@article{roure_impact_nodate,
	title = {The {Impact} of {Workflow} {Tools} on {Data}-centric {Research}},
	journal = {F our T h P aradigm},
	author = {RoURE, DAvID DE},
	pages = {137},
	file = {Full Text:/Users/rca2t1/Dropbox/Zotero/storage/T8V6PQKD/RoURE - The Impact of Workflow Tools on Data-centric Resea.pdf:application/pdf},
}

@article{regan_fourth_2012,
	title = {The {Fourth} {Paradigm} by {Tony} {Hey}, {Stewart} {Tansley}, and {Kristin} {Tolle}},
	volume = {8},
	number = {1},
	journal = {InterActions: UCLA Journal of Education and Information Studies},
	author = {Regan, Clinton Joseph},
	year = {2012},
	file = {Regan - 2012 - The Fourth Paradigm by Tony Hey, Stewart Tansley, .pdf:/Users/rca2t1/Dropbox/Zotero/storage/DCNT3SCE/Regan - 2012 - The Fourth Paradigm by Tony Hey, Stewart Tansley, .pdf:application/pdf},
}

@article{goble_impact_2009,
	title = {The {Impact} of {Workflow} {Tools} on {Data}-{Centric} {Research}},
	author = {Goble, Carole and De Roure, David},
	year = {2009},
	file = {Goble and De Roure - 2009 - The Impact of Workflow Tools on Data-Centric Resea.pdf:/Users/rca2t1/Dropbox/Zotero/storage/IT3CY3Y2/Goble and De Roure - 2009 - The Impact of Workflow Tools on Data-Centric Resea.pdf:application/pdf},
}

@article{subramanian_pipelined_2013,
	title = {Pipelined {Data}-{Flow} {Delegated} {Orchestration} for {Data}-{Intensive} {Escience} {Workflows}},
	journal = {International Journal of Web Information Systems},
	author = {Subramanian, Sattanathan and Sztromwasser, Pawe{\textbackslash}l and Puntervoll, P{\textbackslash}aal and Petersen, Kjell},
	year = {2013},
	note = {Publisher: Emerald Group Publishing Limited},
}

@article{hey_fourth_2020,
	title = {The fourth paradigm 10 years on},
	volume = {42},
	number = {6},
	journal = {Informatik Spektrum},
	author = {Hey, Tony and Trefethen, Anne},
	year = {2020},
	note = {Publisher: Springer},
	pages = {441--447},
}

@misc{gray_escience_2007,
	address = {Mountain View, CA},
	title = {{eScience} – {A} {Transformed} {Scientific} {Method}},
	author = {Gray, Jim},
	collaborator = {Szalay, Alex},
	month = jan,
	year = {2007},
	file = {nrc-cstb_escience.ppt:/Users/rca2t1/Dropbox/Zotero/storage/CLPGWDDL/nrc-cstb_escience.ppt:application/msword},
}

@misc{hey_jim_2009,
	title = {Jim {Gray} on {eScience}: {A} {Transformed} {Scientific} {Method}},
	shorttitle = {Jim {Gray} on {eScience}},
	author = {Hey, Tony and Tansley, Stewart and Tolle, Kristin M.},
	year = {2009},
	file = {Hey et al. - 2009 - Jim Gray on eScience A Transformed Scientific Met.pdf:/Users/rca2t1/Dropbox/Zotero/storage/V5GATCR2/Hey et al. - 2009 - Jim Gray on eScience A Transformed Scientific Met.pdf:application/pdf},
}

@article{bourne_reaming_2013,
	title = {The reaming of life: based on the 2010 {Jim} {Gray} {eScience} {Award} {Lecture}},
	volume = {25},
	shorttitle = {The reaming of life},
	number = {4},
	journal = {Concurrency and Computation: Practice and Experience},
	author = {Bourne, Philip E.},
	year = {2013},
	note = {Publisher: Wiley Online Library},
	pages = {445--453},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/C9ARB4T4/cpe.html:text/html},
}

@incollection{abbot_new_2009,
	address = {Redmond, WA},
	title = {A {New} {Path} for {Science}?},
	booktitle = {The {Fourth} {Paradigm}: {Data}-{Intensive} {Scientific} {Discovery}},
	publisher = {Microsoft Research},
	author = {Abbot, Mark R.},
	year = {2009},
	pages = {111--116},
}

@inproceedings{blackwell_dealing_2000,
	title = {Dealing with {New} {Cognitive} {Dimensions}},
	booktitle = {Workshop on {Cognitive} {Dimensions}: {Strengthening} the {Cognitive} {Dimensions} {Research} {Community}., {University} of {Hertfordshire}},
	author = {Blackwell, Alan F.},
	year = {2000},
	file = {Blackwell - 2000 - Dealing with New Cognitive Dimensions.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LWECWJYX/Blackwell - 2000 - Dealing with New Cognitive Dimensions.pdf:application/pdf},
}

@article{green_cognitive_1989,
	title = {Cognitive {Dimensions} of {Notations}},
	journal = {People and computers V},
	author = {Green, Thomas RG},
	year = {1989},
	pages = {443--460},
	file = {Green - 1989 - Cognitive Dimensions of Notations.pdf:/Users/rca2t1/Dropbox/Zotero/storage/GGW7VVDR/Green - 1989 - Cognitive Dimensions of Notations.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/YP46ACB4/BTxOtt4X920C.html:text/html},
}

@book{turner_cognitive_2001,
	title = {Cognitive {Dimensions} of {Social} {Science}},
	publisher = {Oxford University Press on Demand},
	author = {Turner, Mark},
	year = {2001},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/QJMEJZE7/8trnCwAAQBAJ.html:text/html},
}

@article{moirand_communicative_2003,
	title = {Communicative and {Cognitive} {Dimensions} of {Discourse} on {Science} in the {French} {Mass} {Media}},
	volume = {5},
	number = {2},
	journal = {Discourse studies},
	author = {Moirand, Sophie},
	year = {2003},
	note = {Publisher: Sage Publications London},
	pages = {175--206},
	file = {Moirand - 2003 - Communicative and Cognitive Dimensions of Discours.pdf:/Users/rca2t1/Dropbox/Zotero/storage/T6UQBP5L/Moirand - 2003 - Communicative and Cognitive Dimensions of Discours.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/KN2XWDB5/1461445603005002003.html:text/html},
}

@misc{weng_exploratory_2021,
	title = {Exploratory {Data} {Analysis} ({EDA}): {A} {Practical} {Guide} and {Template} for {Structured} {Data}},
	shorttitle = {Exploratory {Data} {Analysis} ({EDA})},
	url = {https://towardsdatascience.com/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9},
	abstract = {Using a code template, EDA is never easier to get started},
	language = {en},
	urldate = {2021-07-28},
	journal = {Medium},
	author = {Weng, Jiahao},
	month = apr,
	year = {2021},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Q4PNAV6V/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9.html:text/html},
}

@book{snow_two_2013,
	title = {The {Two} {Cultures} and the {Scientific} {Revolution}},
	isbn = {978-1-61427-547-3},
	abstract = {2013 Reprint of 1959 Edition. Exact facsimile of the original edition, not reproduced with Optical Recognition Software. This is the publication of the influential 1959 Rede Lecture by British scientist and novelist C. P. Snow. Its thesis was that "the intellectual life of the whole of western society" was split into the titular two cultures - namely the sciences and the humanities - and that this was a major hindrance to solving the world's problems. Published in book form, Snow's lecture was widely read and discussed on both sides of the Atlantic, leading him to write a 1963 follow-up, "The Two Cultures: And a Second Look: An Expanded Version of The Two Cultures and the Scientific Revolution."},
	language = {en},
	publisher = {Martino Fine Books},
	author = {Snow, C. P.},
	month = dec,
	year = {2013},
	note = {Google-Books-ID: fMx0ngEACAAJ},
}

@article{leong-hong_technical_1977,
	title = {Technical {Profile} of {Seven} {Data} {Element} {Dictionary}/{Directory} {Systems}},
	url = {https://www.nist.gov/publications/technical-profile-seven-data-element-dictionarydirectory-systems},
	language = {en},
	urldate = {2021-10-01},
	author = {Leong-hong, B. and Marron, B.},
	month = feb,
	year = {1977},
	note = {Last Modified: 2008-10-16T14:10-04:00},
	file = {Leong-hong and Marron - 1977 - Technical Profile of Seven Data Element Dictionary.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RRETV7BW/Leong-hong and Marron - 1977 - Technical Profile of Seven Data Element Dictionary.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BLEPWGJ3/technical-profile-seven-data-element-dictionarydirectory-systems.html:text/html},
}

@book{department_navy_1967,
	title = {Navy {Management} {Review}},
	language = {en},
	author = {Department, United States Navy},
	year = {1967},
	note = {Google-Books-ID: ZMtHAQAAIAAJ},
}

@book{noauthor_american_1942,
	title = {American {Scientist}},
	language = {en},
	publisher = {Sigma Xi},
	year = {1942},
	note = {Google-Books-ID: jgBVAAAAMAAJ},
	file = {data-deluge-1947.png:/Users/rca2t1/Dropbox/Zotero/storage/8YR3FDWI/data-deluge-1947.png:image/png},
}

@misc{gannon_how_2014,
	title = {How {Scientists} {Tackle} {NASA}'s {Big} {Data} {Deluge}},
	url = {https://www.space.com/23330-nasa-big-data-jet-propulsion-laboratory.html},
	abstract = {The deluge of mission data poses some big challenges for NASA. But a team at the Jet Propulsion Laboratory is coming up with new strategies to tackle problems of information storage, processing and access.},
	language = {en},
	urldate = {2021-10-09},
	journal = {Space.com},
	author = {Gannon, Megan},
	month = jan,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/G2QA4VLD/23330-nasa-big-data-jet-propulsion-laboratory.html:text/html},
}

@book{noauthor_illinois_1916,
	title = {Illinois {Alumni} {News}},
	language = {en},
	publisher = {University of Illinois at Urbana-Champaign, for members of the Alumni Association.},
	year = {1916},
	note = {Google-Books-ID: rKxGAQAAMAAJ},
	file = {data-deluge-1914.png:/Users/rca2t1/Dropbox/Zotero/storage/SW3732YZ/data-deluge-1914.png:image/png},
}

@article{noauthor_hot_2014,
	title = {Hot {Commodity}: {The} {Data} {Scientist}},
	shorttitle = {Video},
	url = {https://www.nytimes.com/video/multimedia/100000003081122/hot-commodity-the-data-scientist.html},
	abstract = {Competition for data scientists is heating up as their skills become increasingly important to the world's tech companies. Lily Jamali reports.},
	language = {en-US},
	urldate = {2021-10-14},
	month = aug,
	year = {2014},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/EZAD4U2U/hot-commodity-the-data-scientist.html:text/html},
}

@article{lohr_for_2014,
	chapter = {Technology},
	title = {For {Big}-{Data} {Scientists}, ‘{Janitor} {Work}’ {Is} {Key} {Hurdle} to {Insights}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html},
	abstract = {The analysis of giant data sets promises unique business insights, but much manual effort is still required to prepare the information for parsing.},
	language = {en-US},
	urldate = {2021-10-14},
	journal = {The New York Times},
	author = {Lohr, Steve},
	month = aug,
	year = {2014},
	keywords = {Data-Mining and Database Marketing, ClearStory Data, Iodine Inc, Lohr, Steve, Paxata Inc, Start-ups},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/GMP4W3HN/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html:text/html},
}

@article{lohr_as_2015,
	chapter = {Technology},
	title = {As {Tech} {Booms}, {Workers} {Turn} to {Coding} for {Career} {Change}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2015/07/29/technology/code-academy-as-career-game-changer.html},
	abstract = {Schools that offer accelerated training in digital skills are drawing more and more “career changers,” and graduates can make six-figure base salaries.},
	language = {en-US},
	urldate = {2021-10-14},
	journal = {The New York Times},
	author = {Lohr, Steve},
	month = jul,
	year = {2015},
	keywords = {Computers and the Internet, Colleges and Universities, Careers and Professions, Lohr, Steve, Hiring and Promotion, Labor and Jobs, Vocational Training, Wages and Salaries},
}

@article{lohr_sure_2012,
	chapter = {Technology},
	title = {Sure, {Big} {Data} {Is} {Great}. {But} {So} {Is} {Intuition}.},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2012/12/30/technology/big-data-is-great-but-dont-forget-intuition.html},
	abstract = {It is easier than ever to measure and monitor people and machines, but the technology of Big Data is not without its shortcomings.},
	language = {en-US},
	urldate = {2021-10-14},
	journal = {The New York Times},
	author = {Lohr, Steve},
	month = dec,
	year = {2012},
	keywords = {Computers and the Internet, Mathematics, Massachusetts Institute of Technology, Science and Technology, Artificial Intelligence, Data-Mining and Database Marketing, Data Storage},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/AV3J3JAX/big-data-is-great-but-dont-forget-intuition.html:text/html},
}

@misc{miller_site_2011,
	title = {A {Site} for {Data} {Scientists} to {Prove} {Their} {Skills} and {Make} {Money}},
	url = {https://bits.blogs.nytimes.com/2011/11/03/a-site-for-data-scientists-to-prove-their-skills-and-make-money/},
	abstract = {Kaggle connects data scientists with organizations that need someone to extract meaning from their data, like insurance companies that want to know the likelihood that a patient will be hospitalized.},
	language = {en-US},
	urldate = {2021-10-14},
	journal = {Bits Blog},
	author = {Miller, Claire Cain},
	month = nov,
	year = {2011},
	note = {Cad: 0
Section: Technology},
	keywords = {Computers and the Internet, Internet, Big Data, Start-ups, Contests and Prizes, Enterprise Computing},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/B6VQA37L/a-site-for-data-scientists-to-prove-their-skills-and-make-money.html:text/html},
}

@misc{woods_linkedins_2011,
	title = {{LinkedIn}'s {Monica} {Rogati} {On} "{What} {Is} {A} {Data} {Scientist}?"},
	shorttitle = {{LinkedIn}'s {Monica} {Rogati} {On} "{What} {Is} {A} {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2011/11/27/linkedins-monica-rogati-on-what-is-a-data-scientist/},
	abstract = {To continue our series on the emerging role of the data scientist in today’s data-driven organizations, we spoke with Monica Rogati, Senior Data Scientist at LinkedIn, for her views on the subject.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = nov,
	year = {2011},
	note = {Section: Data Driven},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ILL39BEZ/linkedins-monica-rogati-on-what-is-a-data-scientist.html:text/html},
}

@misc{woods_bitlys_2012,
	title = {bitly's {Hilary} {Mason} on "{What} is {A} {Data} {Scientist}?"},
	shorttitle = {bitly's {Hilary} {Mason} on "{What} is {A} {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2012/03/08/hilary-mason-what-is-a-data-scientist/},
	abstract = {Mason divides data science into two halves. The one half is analytics. The other half is the invention of new techniques to draw insights from data that were not possible before.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = mar,
	year = {2012},
	note = {Section: Enterprise \& Cloud},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JACGA93K/hilary-mason-what-is-a-data-scientist.html:text/html},
}

@misc{noauthor_growing_2017,
	title = {Growing {Your} {Own} {Data} {Scientists}},
	url = {https://earlyadopter.com/2017/12/09/growing-your-own-data-scientists/},
	abstract = {CIOs and CTOs must learn to address a challenge, involving the divide between the people who know about the vast amount of new sources of data emanating from machines and other devices (“big data”) and the questions in the enterprise whose answers can be monetized. CIOs and CTOs must learn to address a challenge, involving […]},
	language = {en-US},
	urldate = {2021-10-14},
	journal = {Early Adopter},
	month = dec,
	year = {2017},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CTUMFKGN/growing-your-own-data-scientists.html:text/html},
}

@misc{woods_what_2012,
	title = {What {Is} a {Data} {Scientist}?: {Michael} {Rappa}, {Institute} for {Advanced} {Analytics}},
	shorttitle = {What {Is} a {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2012/03/05/what-is-a-data-scientist-michael-rappa-north-carolina-state-university/},
	abstract = {NC State's Michael Rappa on What is a Data Scientist?: “Any time you put ‘science’ in a label, science invokes certain very real concepts within it, like the notion of public knowledge and peer review and so forth,” Rappa says. “And it’s safe to say that the ‘data scientist’ in places like Silicon Valley aren’t publishing their algorithms and putting them out to peer review scrutiny and making it all public knowledge. And within the university environment we’re naturally a little bit more sensitized to the notion of what a ‘science’ is.”},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = mar,
	year = {2012},
	note = {Section: Data Driven},
}

@misc{woods_ibms_2012,
	title = {{IBM}'s {Anjul} {Bhambhri} on {What} {Is} a {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2012/02/16/ibms-anjul-bhambhri-on-what-is-a-data-scientist/},
	abstract = {To continue my series of articles on “What is a Data Scientist?” I interviewed Anjul Bhambhri, vice president of development for big data projects at IBM, about her vision for creating business value from big data. “The enterprises that will achieve a competitive edge and win will have a blend of a healthy data-science culture, enterprising data scientists who can bend the ear of C-level decision makers, and the right combination of technology that will surface the data that make sense in the context of the business,” says Bhambhri.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = feb,
	year = {2012},
	note = {Section: Data Driven},
}

@misc{woods_what_2012-1,
	title = {What {Is} a {Data} {Scientist}?: {Michael} {O}'{Connell} of {TIBCO} {Spotfire}},
	shorttitle = {What {Is} a {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2012/01/25/what-is-a-data-scientist-michael-oconnell-of-tibco-spotfire/},
	abstract = {We continue our series, “What Is a Data Scientist?” by speaking with Michael O’Connell, senior director of analytics of TIBCO Spotfire, TIBCO Software Inc. O’Connell is working at TIBCO to create real-time data distribution and analysis platforms that help users get to the heart of the question more quickly, and with better outcomes of value for the business. In this role, O’Connell has arrived at several maxims that can help the data scientist become most valuable to the business, and at practices that can best create a data-driven culture at an organization.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = jan,
	year = {2012},
	note = {Section: Data Driven},
}

@misc{woods_tableau_2011,
	title = {Tableau {Software}'s {Pat} {Hanrahan} on "{What} {Is} a {Data} {Scientist}?"},
	shorttitle = {Tableau {Software}'s {Pat} {Hanrahan} on "{What} {Is} a {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2011/11/30/tableau-softwares-pat-hanrahan-on-what-is-a-data-scientist/},
	abstract = {We continue our series on the emerging role of the data scientist, by talking to Pat Hanrahan, chief scientist and co-founder of Tableau Software. Hanrahan received a PhD in biophysics from the University of Wisconsin in 1985 and joined the faculty at Princeton University in 1989. In the late 1980s he worked for Digital Equipment Corp. and directed the 3D computer graphics laboratory at the New York Institute of Technology. At Stanford University since 1996, he is now the CANON Professor of Computer Science and Electrical Engineering.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = nov,
	year = {2011},
	note = {Section: Data Driven},
}

@misc{woods_linkedins_2011-1,
	title = {{LinkedIn}'s {Daniel} {Tunkelang} {On} "{What} {Is} a {Data} {Scientist}?"},
	shorttitle = {{LinkedIn}'s {Daniel} {Tunkelang} {On} "{What} {Is} a {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2011/10/24/linkedins-daniel-tunkelang-on-what-is-a-data-scientist/},
	abstract = {Daniel Tunkelang, principal data scientist at LinkedIn, joined LinkedIn in December 2010 and oversees the data science team, which analyzes terabytes of data to produce products and insights that serve LinkedIn's members. In this article he explains his definition of a data scientist.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = oct,
	year = {2011},
	note = {Section: Data Driven},
}

@misc{press_supply_2015,
	title = {The {Supply} {And} {Demand} {Of} {Data} {Scientists}: {What} {The} {Surveys} {Say}},
	shorttitle = {The {Supply} {And} {Demand} {Of} {Data} {Scientists}},
	url = {https://www.forbes.com/sites/gilpress/2015/04/30/the-supply-and-demand-of-data-scientists-what-the-surveys-say/},
	abstract = {The results of two surveys about data scientists were released this week, covering both the supply and demand sides of this hot new profession, “the sexiest job of the 21st Century.”},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Press, Gil},
	month = apr,
	year = {2015},
	note = {Section: Tech},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/FVH7X4SY/the-supply-and-demand-of-data-scientists-what-the-surveys-say.html:text/html},
}

@misc{woods_emc_2011,
	title = {{EMC} {Greenplum}'s {Steven} {Hillion} on {What} {Is} a {Data} {Scientist}?},
	url = {https://www.forbes.com/sites/danwoods/2011/10/11/emc-greenplums-steven-hillion-on-what-is-a-data-scientist/},
	abstract = {As the mounds of data pile up from every direction, businesses are going to be differentiated increasingly by how they use that data. The essential skill set needed for the enterprise of the 21st century is that of the “data scientist,” a role dedicated to understanding and making use of data to help a business or other organization. Steven Hillion is vice president of analytics at EMC Greenplum explains his vision for the role.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Forbes},
	author = {Woods, Dan},
	month = oct,
	year = {2011},
	note = {Section: Data Driven},
}

@article{mnookin_bumbling_2020,
	chapter = {Books},
	title = {The {Bumbling} 1960s {Data} {Scientists} {Who} {Anticipated} {Facebook} and {Google}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2020/09/15/books/review/if-then-jill-lepore.html},
	abstract = {In “If Then,” the historian Jill Lepore recounts the story of the Simulmatics Corporation, which tried to use primitive computing power to shape Americans’ behavior.},
	language = {en-US},
	urldate = {2021-10-14},
	journal = {The New York Times},
	author = {Mnookin, Seth},
	month = sep,
	year = {2020},
	keywords = {Books and Literature, Computers and the Internet, If Then: How the Simulmatics Corporation Invented the Future (Book), Lepore, Jill, Nineteen Hundred Sixties, Politics and Government, Presidential Election of 1960, Vietnam War},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/NB6BN9YN/if-then-jill-lepore.html:text/html},
}

@article{heracleous_conceptualizing_2004,
	title = {Conceptualizing organizational discourse as situated symbolic action},
	volume = {57},
	issn = {0018-7267},
	url = {https://doi.org/10.1177/0018726704048356},
	doi = {10.1177/0018726704048356},
	abstract = {This article presents a conceptualization of organizational discourse as situated symbolic action, drawing from the fields of speech act theory, rhetoric, ethnography of communication and social constructionism. This conceptualization is illustrated through analysis of an episode of negotiated order accessed through an organization development intervention; a meeting of senior managers of Systech, a major IT organization, to decide on a new business model. This perspective helps to respond to some of the key challenges facing the organizational discourse field in terms of developing more clearly specified conceptualizations of discourse suited to the organizational level of analysis, achieving a more holistic and discourse-sensitive understanding of empirical contexts by organizational researchers, and illustrating that organizational discourse analysis is not simply an intellectual luxury but can have pragmatic, relevant implications.},
	language = {en},
	number = {10},
	urldate = {2021-10-17},
	journal = {Human Relations},
	author = {Heracleous, Loizos and Marshak, Robert J.},
	month = oct,
	year = {2004},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {action research, organizational discourse, situated symbolic action},
	pages = {1285--1312},
	file = {SAGE PDF Full Text:/Users/rca2t1/Dropbox/Zotero/storage/4II8V6SS/Heracleous and Marshak - 2004 - Conceptualizing organizational discourse as situat.pdf:application/pdf},
}

@book{edwards_closed_1997,
	address = {Cambridge, Mass.},
	edition = {Reprint edition},
	title = {The {Closed} {World}: {Computers} and the {Politics} of {Discourse} in {Cold} {War} {America}},
	isbn = {978-0-262-55028-4},
	shorttitle = {The {Closed} {World}},
	abstract = {The Closed World offers a radically new alternative to the canonical histories of computers and cognitive science. Arguing that we can make sense of computers as tools only when we simultaneously grasp their roles as metaphors and political icons, Paul Edwards shows how Cold War social and cultural contexts shaped emerging computer technology―and were transformed, in turn, by information machines.The Closed World explores three apparently disparate histories―the history of American global power, the history of computing machines, and the history of subjectivity in science and culture―through the lens of the American political imagination. In the process, it reveals intimate links between the military projects of the Cold War, the evolution of digital computers, and the origins of cybernetics, cognitive psychology, and artificial intelligence.Edwards begins by describing the emergence of a "closed-world discourse" of global surveillance and control through high-technology military power. The Cold War political goal of "containment" led to the SAGE continental air defense system, Rand Corporation studies of nuclear strategy, and the advanced technologies of the Vietnam War. These and other centralized, computerized military command and control projects―for containing world-scale conflicts―helped closed-world discourse dominate Cold War political decisions. Their apotheosis was the Reagan-era plan for a "Star Wars" space-based ballistic missile defense.Edwards then shows how these military projects helped computers become axial metaphors in psychological theory. Analyzing the Macy Conferences on cybernetics, the Harvard Psycho-Acoustic Laboratory, and the early history of artificial intelligence, he describes the formation of a "cyborg discourse." By constructing both human minds and artificial intelligences as information machines, cyborg discourse assisted in integrating people into the hyper-complex technological systems of the closed world.Finally, Edwards explores the cyborg as political identity in science fiction―from the disembodied, panoptic AI of 2001: A Space Odyssey, to the mechanical robots of Star Wars and the engineered biological androids of Blade Runner―where Information Age culture and subjectivity were both reflected and constructed.Inside Technology series},
	language = {English},
	publisher = {The MIT Press},
	author = {Edwards, Paul N.},
	month = aug,
	year = {1997},
	file = {Edwards - 1997 - The Closed World Computers and the Politics of Di.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ITXA6C9B/Edwards - 1997 - The Closed World Computers and the Politics of Di.pdf:application/pdf},
}

@book{altshuler_rise_2013-1,
	title = {The {Rise} and {Fall} of {Air} {Force} {Cambridge} {Research} {Laboratories}},
	isbn = {978-1-4818-3251-9},
	abstract = {This monograph provides a chronological account of how a fledgling research laboratory, which evolved from the MIT Radiation Laboratory and the Harvard Radio Research Laboratory after World War II, rose to become one of the premier research laboratories in the world as evidenced by its major accomplishments throughout its 66 year history. After many years of outstanding productivity the laboratory began to slowly decline. Even though the downsizing began in1974, the Hanscom Field Site continued to be very productive until its final days. In 2005 it was placed on the Base Realignment And Closure (BRAC) list and in August 2011 it was closed. Many of the major events that led to this decline were politically motivated. I had the privilege of collaborating with outstanding scientists from May 1960 to May 2011 and was blessed with a very rewarding career. One of the most ironic outcomes of the AFCRL history was the fact that when the laboratory was first established, the original plan was to move the new laboratory to Wright Field in Dayton, Ohio in 1946; this move actually occurred 65 years later. Also, after the Geophysics Research Directorate (GRD), was moved from New Jersey to Cambridge, MA in July 1948, there were numerous attempts to move GRD to Kirtland AFB. This also occurred in 2011.},
	language = {English},
	publisher = {CreateSpace Independent Publishing Platform},
	author = {Altshuler, Edward E.},
	month = jan,
	year = {2013},
}

@book{howe_compatibility_1962,
	address = {L. G. Hanscom Field, Massachusetts},
	series = {{AFCRL} ;62-1108},
	title = {Compatibility {Evaluation} of {Data} {Handling} {Subsystem}},
	url = {https://catalog.hathitrust.org/Record/102197492},
	urldate = {2021-10-17},
	publisher = {Air Force Cambridge Research Laboratories, Office of Aerospace Research, United States Air Force},
	author = {Howe, H. R. and Griffin, J. R. and Weppner, W. G. and Hershberg, P. I. and {Air Force Cambridge Research Laboratories (U.S.)}},
	year = {1962},
	keywords = {Data processing, Weather},
	annote = {"December 1962."},
	annote = {"H. R. Howe, 1/LT, USAF."},
	annote = {Includes bibliographical references (page 51)},
	annote = {"J. R. Griffin, MSGT, USAF."},
	annote = {"Meteorological Development Laboratory Project 433L."},
	annote = {"P. I. Hershberg, 1/LT, USAF."},
	annote = {"Research Note."},
	annote = {"W. G. Weppner, 1/LT, USAF."},
}

@book{schaffel_emerging_1991,
	title = {The {Emerging} {Shield}: {The} {Air} {Force} and the {Evolution} of {Continental} {Air} {Defense}, 1945-1960},
	copyright = {http://creativecommons.org/publicdomain/mark/1.0/},
	isbn = {978-0-912799-60-5 978-0-912799-61-2},
	shorttitle = {The {Emerging} {Shield}},
	url = {http://archive.org/details/TheEmergingShield},
	abstract = {Contents
Foreword v
Preface vii
Acknowledgments x i
Chapters
1. Genesis of the Air Defense Mission 1
The United States and Air Defense: The Early Years 6
Defining the Mission 8 
Development of Air Defense Doctrine and Tactics 9 
Gordon P. Saville 13 
2. Air Defense in World War II 21 
The First Air Defense Command, 1940-1941 24
Air Defense in Wartime 36
3. Planning for Air Defense in the Postwar Era 47
Establishment of the Air Defense Command 50
Early Planning Efforts 59
The Radar Fence Plan 67
Attempts to Come to Terms with the Mission 73
Active Operations Begin 76
4. Saville Takes Charge 83
Revision of the Radar Fence Plan 87
Establishment of the Continental Air Command 95 
Taking the Case to Congress 97
Fighter Aircraft for Air Defense 98
Further Organizational Changes 102
5. Broadening Dimensions: Air Defense as a Public Issue 107 
The Revolt of the Admirals 108
Impact of the Soviet Atomic Bomb 111
Roles and Missions Dilemmas 115
Air Defense Forces in the Field 122 
6. Continental Air Defense in the Korean War Period 129 
Reorganization and the Impact of the Chinese Intervention 139 
Confronting Realities 152
Status of the Fighter-Interceptor Forces 160 
7. An Integrated, Efficient, Highly Potent Air Defense System 169
Next to the Real Thing 169
East River 172
The Summer Study Group 174
The Decision to Proceed 191
8. Defensive Systems Become Operational 197
SAGE: A Command and Control Network for Air Defense 197 
Warning Lines 209 
Other Warning Systems 217 
The Air Defense Weapons Force 224 
BOMARC 235 
9. Organizing to Meet the Threat 241 
Continental Air Defense Command: A Joint Command for Air Defense 241 
North American Air Defense Command 246 
10. Epilogue: Impact of a New Threat 255 
Effects of the ICBM Threat on the Air Defenses 260 
Aftermath: Deterioration of the Air Defenses 266 
Appendices
1. Milestones in U.S. Air Defense to 1960 277 
2. ADC Assigned Personnel Strength and Commanders, to 1960 286 
3. ADC Commanders 287 
Notes 289 
Glossary 317 
Bibliography 323 
Index 335 
Photographs 
Capt. Gordon P. Saville 15 
General George C. Marshall 24 
Maj. Gen. James E. Chaney 25 
Plotting board, Watertown maneuvers, August 1940 26 
Information center and Air Defense Headquarters, Watertown maneuvers 28
Filter board staffed by civilians, January 1941 31 
Moored barrage balloon of the type used by the Antiaircraft Artillery Command 34 
Antiaircraft artillery searchlights, circa 1940 35 
Maj. Gen. Muir S. Fairchild 42 
Brig. Gen. Gordon P. Saville 44 
General of the Army, Henry H. Arnold 51 
General Carl A. Spaatz 53 
Maj. Gen. George E. Stratemeyer 55 
P-61 Black Widow 60 
Brig. Gen. Earle E. Partridge 66 
W. Stuart Symington becomes Secretary of the Air Force 70 
P-82 Twin Mustang 78 
Tu-4 Bull 85 
P-80 Shooting Star and B-29 Superfortress 88 
AN/CPS-5 search radar 94 
F-89 Scorpion 100 
F-86 Sabre 101 
F-102 Delta Dagger 102 
General Hoyt S. Vandenberg becomes Chief of Staff, U.S. 
Air Force 108 
Lt. Gen. Ennis C. Whitehead 123 
F-86D Sabre 124 
F-94Starfire 125 
General Benjamin W. Chidlaw 149 
Plexiglass plotting board, mid-1950s 151 
Early computer patch panel and component parts 153 
General Frederic H. Smith 154 
Tu-95 Bear and Tu-16 Badger 182 
General Nathan F. Twining accepting second tour as Chief of Staff 192 
SAGE 64X64 magnetic core memory 198 
AN/FSQ-7 radar 205 
SAGE direction center, Stewart Air Force Base, New York 208
Pinetree Line 210 
DEW Line module 213
DEW Line site 214
DEW Line tower 215
DEW Line post 216
Texas Tower 218
RC-121C 221
F-106A Delta Dart 228
F-101B Voodoo 232
GAR-1 Falcon 233
IM-99 BOM ARC 237
NORAD site and Cheyenne Mountain 262
NORAD COC dining room 263
SAGE post, Syracuse, New York 265
Charts 
Fighter-Interceptor Squadrons Assigned, December 1946-June 1954 162
Fighter-Interceptor Aircraft on Hand, December 1950- June 1954 163
ADC Day Conventional Fighters (Jet) Interceptors Possessed, 1951-1954 165
Combat-Ready Aircraft and Aircrews 225
ADC Jet All-Weather Interceptors Possessed (Century Series) 1956-1973 (as of December 31) 231
Maps
Air Defense Command Long-Term Plan 64
Areas of Responsibility for Air Defense, July 1948-March 1949 89
Deployment of Air Defense Radar, June 1948 91
Deployment of ADC Lashup Radar Network, December 1950 93
Air Defense Identification Zones, 1952 134 
Areas of Responsibility for Air Defense, November 1950 139
Air Force Areas of Responsibility for Air Defense, July 1951 146 
Army Antiaircraft Artillery Command Subdivisions and Battalions Assigned, December 31, 1953 147 
Ground Observer Corps Program, 1952 158 
Fighter Forces Available for Air Defense in an Emergency, December 15, 1952 164
The DEW Line 211
Texas Tower Stations 219
Operational Interceptor Force, December 31, 1959 230
NORAD Operational Missile/Gun Force, July 1, 1959 248
NORAD Operational Interceptor Force, July 1, 1959 249
Region Configuration, End of 1983 266
Tables
ADC Day Fighters (Jet) Possessed 166
Interceptor Squadrons Assigned ADC, by Type 166
Air Defense Aircraft 227
Comparison of Defense Department, Air Force, and ADC Budgets 269
Air Defense Matrix 270
Digitized by http://www.afhso.af.mil/; Includes bibliographical references (p. 323-333) and index},
	language = {eng},
	urldate = {2021-10-18},
	publisher = {Washington, D.C. : Office of Air Force History, United States Air Force},
	author = {Schaffel, Kenneth and {United States. Air Force. Office of Air Force History}},
	year = {1991},
	keywords = {United States. -- Air Force -- Air Defense Command},
	file = {Schaffel and United States. Air Force. Office of Air Force History - 1991 - The Emerging Shield The Air Force and the Evoluti.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HK2KCDGF/Schaffel and United States. Air Force. Office of Air Force History - 1991 - The Emerging Shield The Air Force and the Evoluti.pdf:application/pdf},
}

@book{appropriations_second_1958,
	title = {Second {Supplemental} {Appropriation} {Bill}: 1958, {Hearings} ... 85th {Congress}, 2d {Session}},
	shorttitle = {Second {Supplemental} {Appropriation} {Bill}},
	language = {en},
	author = {Appropriations, United States Congress House},
	year = {1958},
	annote = {26 "Data processing systems scientists" are itemized on page 147.
National Advisory Committee for Aeronautics
General Doolittle and General Dryden
Request for a supplemental appropriation of \$11,780,000  as contained in House Document 313.
"research program in aircraft, missiles, satellites, and manned and unmanned space vehicles."
Data Reduction Center
"The data processing function is much more complex than the mere production line job of translating raw data into usable form . Each new research project must be reviewed to determine how the data will be obtained , what type and volume of calculations are required , and what modifications must be made to the recording instruments and data - processing apparatus to meet the requirements. It may even be necessary for the data-processing scientist to design and construct new equipment for a new type of problem. Some projects cannot be undertaken until the specific means of obtaining and handling the data have been worked out . In some research areas , on - line service to a data processing center saves considerable time by allowing the project engineer to obtain a spot check on the computed results while the facility is in operation . This permits him to make an immediate change in the test conditions to obtain the results that he wants .},
}

@techreport{afcrl_report_1975,
	title = {Report on {Research} at {AFCRL}: {July} 1972 - {June} 1974},
	url = {https://www.google.com/books/edition/Report_on_Research_at_AFCRL/46omSJZFGBoC?hl=en},
	urldate = {2021-10-20},
	author = {{AFCRL}},
	month = may,
	year = {1975},
	file = {AFCRL - 1975 - Report on Research at AFCRL July 1972 - June 1974.pdf:/Users/rca2t1/Dropbox/Zotero/storage/UWMZ9JGN/AFCRL - 1975 - Report on Research at AFCRL July 1972 - June 1974.pdf:application/pdf;Report on Research at AFCRL. - Google Books:/Users/rca2t1/Dropbox/Zotero/storage/9EK3ZP7Y/46omSJZFGBoC.html:text/html},
}

@techreport{afcrl_report_1973,
	title = {Report on {Research} at {AFCRL}: {July} 1970 - {June} 1972},
	language = {en},
	author = {{AFCRL}},
	month = feb,
	year = {1973},
	note = {Google-Books-ID: MF2dExiimrsC},
	file = {AFCRL - 1973 - Report on Research at AFCRL July 1970 - June 1972.pdf:/Users/rca2t1/Dropbox/Zotero/storage/8IDDRAEQ/AFCRL - 1973 - Report on Research at AFCRL July 1970 - June 1972.pdf:application/pdf},
}

@article{backus_report_1960,
	title = {Report on the algorithmic language {ALGOL} 60},
	volume = {3},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/367236.367262},
	doi = {10.1145/367236.367262},
	number = {5},
	urldate = {2021-10-23},
	journal = {Communications of the ACM},
	author = {Backus, J. W. and Bauer, F. L. and Green, J. and Katz, C. and McCarthy, J. and Perlis, A. J. and Rutishauser, H. and Samelson, K. and Vauquois, B. and Wegstein, J. H. and van Wijngaarden, A. and Woodger, M. and Naur, Peter},
	month = may,
	year = {1960},
	pages = {299--314},
	file = {Backus et al. - 1960 - Report on the algorithmic language ALGOL 60.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NQM2HRIC/Backus et al. - 1960 - Report on the algorithmic language ALGOL 60.pdf:application/pdf},
}

@article{venkateswaran_news_1963,
	title = {News and {Notes}: {Reorganization} of {AFCRL}},
	volume = {44},
	issn = {0003-0007},
	url = {https://www.jstor.org/stable/26247218},
	number = {9},
	urldate = {2021-10-23},
	journal = {Bulletin of the American Meteorological Society},
	author = {Venkateswaran, S. V.},
	year = {1963},
	note = {Publisher: American Meteorological Society},
	pages = {548--629},
	annote = {Reports on reorganization of AFCRL in 1963. DSL was created from two other labs.
Data Sciences Laboratory. Formed from the Computer and Mathematical Sciences Laboratory and the Communications Sciences Laboratory, this new unit is charged with responsibility for research in speech, data coding techniques, microcircuit development, computer languages, biophysics, and logical circuit techniques. The laboratory is headed by Robert M. Alexander. },
	file = {Venkateswaran - 1963 - News and Notes Reorganization of AFCRL.pdf:/Users/rca2t1/Dropbox/Zotero/storage/4S7B4VNW/Venkateswaran - 1963 - News and Notes Reorganization of AFCRL.pdf:application/pdf},
}

@article{grace_computer-based_1964,
	title = {Computer-{Based} {Methodology} for {System} {Development}: {Site} {Production} and {Reduction} {System}},
	volume = {6},
	url = {https://journals.sagepub.com/doi/abs/10.1177/001872086400600301},
	doi = {https://doi.org/10.1177%2F001872086400600301},
	number = {3},
	urldate = {2021-10-23},
	journal = {Human Factors},
	author = {Grace, G. L. and Newlands, E.},
	month = jun,
	year = {1964},
	pages = {227--232},
	file = {Computer-Based Methodology for System Development\: Site Production and Reduction System - G. L. Grace, E. Newlands, 1964:/Users/rca2t1/Dropbox/Zotero/storage/QN3YB7BD/001872086400600301.html:text/html;Grace and Newlands - 1964 - Computer-Based Methodology for System Development.pdf:/Users/rca2t1/Dropbox/Zotero/storage/EDR4T3MV/Grace and Newlands - 1964 - Computer-Based Methodology for System Development.pdf:application/pdf},
}

@article{griffiths_relative_1965,
	title = {On the {Relative} {Efficiencies} of {Context}-{Free} {Grammar}},
	volume = {8},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/364914.364943},
	doi = {10.1145/364914.364943},
	number = {5},
	urldate = {2021-10-23},
	journal = {Communications of the ACM},
	author = {Griffiths, T. V. and Petrick, S. R.},
	month = may,
	year = {1965},
	pages = {289--300},
	file = {Griffiths and Petrick - 1965 - On the Relative Efficiencies of Context-Free Gramm.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LG7CFMM6/Griffiths and Petrick - 1965 - On the Relative Efficiencies of Context-Free Gramm.pdf:application/pdf},
}

@article{backus_revised_1963,
	title = {Revised {Report} on the {Algorithmic} {Language} {ALGOL} 60},
	volume = {5},
	issn = {0010-4620},
	url = {https://doi.org/10.1093/comjnl/5.4.349},
	doi = {10.1093/comjnl/5.4.349},
	abstract = {The report gives a complete defining description of the international algorithmic language ALGOL 60. This is a language suitable for expressing a large class of numerical processes in a form sufficiently concise for direct automatic translation into the language of programmed automatic computers.The introduction contains an account of the preparatory work leading up to the final conference, where the language was defined. In addition the notions reference language, publication language, and hardware representations are explained.In the first chapter a survey of the basic constituents and features of the language is given, and the formal notation, by which the syntactic structure is defined, is explained.The second chapter lists all the basic symbols, and the syntactic units know as identifiers, numbers, and strings are defined. Further, some important notions such as quantity and value are defined.The third chapter explains the rules for forming expressions, and the means of these expressions. Three different types of expressions exist: arithmetic, Boolean (logical), and designational.The fourth chapter describes the operational units of the language, known and statements. The basic statements are: assignment statements (evaluation of a formula), go to statements (explicit break of the sequence of execution of statements), dummy statements, and procedure statements (call for execution of a closed process, defined by a procedure declaration). The formation of more complex structures, having statement character, is explained. Thes include: conditional statements, for statements, compound statements, and blocks.In the fifth chapter the units known as declarations, serving for defining permanent properties of the units entering into a process described in the language, are defined.The report ends with two detailed examples of the use of the language, and an alphabetic index of definitions.},
	number = {4},
	urldate = {2021-10-23},
	journal = {The Computer Journal},
	author = {Backus, J. W. and Bauer, F. L. and Green, J. and Katz, C. and McCarthy, J. and Naur, P. and Perlis, A. J. and Rutishauser, H. and Samelson, K. and Vauquois, B. and Wegstein, J. H. and van Wijngaarden, A. and Woodger, M.},
	month = jan,
	year = {1963},
	pages = {349--367},
	file = {Backus et al. - 1963 - Revised Report on the Algorithmic Language ALGOL 6.pdf:/Users/rca2t1/Dropbox/Zotero/storage/J7FPL2FU/Backus et al. - 1963 - Revised Report on the Algorithmic Language ALGOL 6.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/RAXXS9HJ/316410.html:text/html},
}

@book{wathen-dunn_models_1967,
	title = {Models for the {Perception} of {Speech} and {Visual} {Form}},
	isbn = {978-0-262-23026-1},
	url = {http://archive.org/details/Modelsfort_00_Wath},
	abstract = {"Sponsored by the Data Sciences Laboratory, Air Force Cambridge Research Laboratories [and held in] Boston, Massachusetts, November 11-14, 1964."; commitment to retain},
	language = {eng},
	urldate = {2021-10-23},
	publisher = {Cambridge, Mass., M.I.T. Press},
	author = {Wathen-Dunn, Weiant and {Air Force Cambridge Research Laboratories (U.S.). Data Sciences Laboratory}},
	collaborator = {{MIT Press}},
	year = {1967},
	note = {Proceedings of a Symposium},
	keywords = {PSYCHOLOGY / Cognitive Psychology},
}

@book{noauthor_american_1942-1,
	title = {American {Scientist}},
	language = {en},
	publisher = {Sigma Xi},
	year = {1942},
	note = {Google-Books-ID: jgBVAAAAMAAJ},
	file = {data-deluge-1942.png:/Users/rca2t1/Dropbox/Zotero/storage/L3Z498NJ/data-deluge-1942.png:image/png},
}

@book{glick_methods_1954,
	title = {Methods of {Biochemical} {Analysis}},
	isbn = {978-0-471-20200-4},
	language = {en},
	publisher = {Wiley},
	author = {Glick, David and Suelter, Clarence H.},
	year = {1954},
	note = {Google-Books-ID: XUeTclJJVC8C},
	file = {data-deluge-1954.png:/Users/rca2t1/Dropbox/Zotero/storage/PVTLQHRL/data-deluge-1954.png:image/png},
}

@book{noauthor_alumni_1916,
	title = {The {Alumni} {Quarterly} and {Fortnightly} {Notes}},
	language = {en},
	publisher = {Alumni Association of the University of Illinois},
	year = {1916},
	note = {Google-Books-ID: hqrOAAAAMAAJ},
}

@book{noauthor_sci-tech_1963-1,
	title = {Sci-tech {News}},
	language = {en},
	publisher = {Sci-Tech News},
	year = {1963},
	note = {Google-Books-ID: MVfpAAAAMAAJ},
	file = {data-deluge-1963.png:/Users/rca2t1/Dropbox/Zotero/storage/4X3WXLZ4/data-deluge-1963.png:image/png},
}

@book{noauthor_electronic_1961-1,
	title = {Electronic {Age}: {Research}, {Manufacturing}, {Communications}, {Broadcasting}, {Television}},
	shorttitle = {Electronic {Age}},
	language = {en},
	publisher = {Radio Corporation of America.},
	year = {1961},
	note = {Google-Books-ID: cHc1AQAAIAAJ},
	file = {data-deluge-1961.jpg:/Users/rca2t1/Dropbox/Zotero/storage/Y3E57C7M/data-deluge-1961.jpg:image/jpeg},
}

@book{noauthor_nasa_1962-1,
	title = {{NASA} {SP}.},
	language = {en},
	publisher = {Scientific and Technical Information Office, National Aeronautics and Space Administration [available from National Technical Information Service, Springfield, Va.]},
	year = {1962},
}

@book{corliss_scientific_1967,
	title = {Scientific {Satellites}},
	language = {en},
	publisher = {Scientific and Technical Information Division, National Aeronautics and Space Administration},
	author = {Corliss, William R.},
	year = {1967},
	note = {Google-Books-ID: LyfUW7D\_VOIC},
	file = {Corliss - 1967 - Scientific Satellites.pdf:/Users/rca2t1/Dropbox/Zotero/storage/KSFTHUT7/Corliss - 1967 - Scientific Satellites.pdf:application/pdf},
}

@book{department_navy_1967-1,
	title = {Navy {Management} {Review}},
	language = {en},
	author = {Department, United States Navy},
	year = {1967},
	note = {Google-Books-ID: ZMtHAQAAIAAJ},
	file = {Department - 1967 - Navy Management Review.pdf:/Users/rca2t1/Dropbox/Zotero/storage/F4RN59JY/Department - 1967 - Navy Management Review.pdf:application/pdf},
}

@techreport{laemmel_pattern_1963,
	title = {Pattern {Recognition} and {Detection} by {Machine}},
	url = {https://apps.dtic.mil/sti/citations/AD0418387},
	abstract = {Pattern recognition is considered generally, but emphasis is placed on the following points optimum estimation of statistical parameters so as to minimize the probability of incorrect classification, non-Gaussian and non-stationary situations, pattern detection in a continuing time series and calculation of error probabilities. Some of the work is specifically directed toward the problem of radio station recognition. A design procedure for pattern recognizing machines is suggested which uses results from this report and other referenced sources.},
	language = {en},
	urldate = {2021-10-26},
	institution = {POLYTECHNIC INST OF BROOKLYN NY MICROWAVE RESEARCH INST},
	author = {Laemmel, Arthur E.},
	month = mar,
	year = {1963},
	note = {Section: Technical Reports},
	annote = {Published before the formation of the DSL, which took place in April 1963 (Altshuler 27).},
	file = {Laemmel - 1963 - Pattern Recognition and Detection by Machine.pdf:/Users/rca2t1/Dropbox/Zotero/storage/4UB7AAQN/Laemmel - 1963 - Pattern Recognition and Detection by Machine.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CMEAI8KG/AD0418387.html:text/html},
}

@misc{noauthor_afosr_nodate,
	title = {{AFOSR} - {History}},
	url = {http://www.afrl.af.mil/About-Us/Fact-Sheets/Fact-Sheet-Display/Article/2282094/afosr-history/},
	abstract = {A Brief Organizational HistoryDownload the AFOSR 60th Anniversary Monograph for a comprehensive history of AFOSR and its contributions to scientific advancement.The wide-ranging and highly successful},
	language = {en-US},
	urldate = {2021-10-26},
	journal = {Air Force Research Laboratory},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/FC48ZXVK/afosr-history.html:text/html},
}

@article{kirby_operations_2008,
	title = {Operations {Research} in {World} {War} {Two}: {Its} {Role} in {RAF} {Fighter} {Command}},
	volume = {13},
	issn = {1082-5983},
	shorttitle = {Operations {Research} in {World} {War} {Two}},
	url = {https://www.jstor.org/stable/43941099},
	abstract = {The role of Operations Research (OR) in informing British tactics and strategy in World War Two is well known in relation to the anti-U boat war in the North Atlantic and the area bombing of Germany. Published sources have also identified the formal origins of OR in the radar-based man-machine system that was devised as a critical component of the Air Defence of Great Britain in the late 1930s. The purpose of this paper is to put on record the role and organisation of OR in RAF Fighter Command over the divide of the Battle of Britain in 1940. Based upon hitherto unpublished sources, the paper offers insights into wartime perceptions of the role of OR in terms of its remit and organisation. In this respect, it serves as an essential complement to Patrick Blackett's wartime commentaries on the ideal functions of OR and its status within the military hierarchy.},
	number = {1},
	urldate = {2021-10-26},
	journal = {Military Operations Research},
	author = {Kirby, M. W.},
	year = {2008},
	note = {Publisher: Military Operations Research Society},
	pages = {65--72},
	file = {Kirby - 2008 - Operations Research in World War Two Its Role in .pdf:/Users/rca2t1/Dropbox/Zotero/storage/3FJERJD2/Kirby - 2008 - Operations Research in World War Two Its Role in .pdf:application/pdf},
}

@article{noauthor_back_1963,
	title = {Back {Matter}},
	volume = {11},
	issn = {0368-4245},
	url = {https://www.jstor.org/stable/2098948},
	number = {2},
	urldate = {2021-10-26},
	journal = {Journal of the Society for Industrial and Applied Mathematics},
	year = {1963},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {data processing scientistst},
	annote = {Ad for Data Processing Scientist on page 8.},
	file = {1963 - Back Matter.pdf:/Users/rca2t1/Dropbox/Zotero/storage/U4TBXCF5/1963 - Back Matter.pdf:application/pdf},
}

@article{boffey_mansfield_1970,
	title = {Mansfield {Amendment} {Not} {Yet} {Dead}},
	url = {https://www.science.org/doi/abs/10.1126/science.170.3958.613},
	doi = {10.1126/science.170.3958.613},
	language = {EN},
	urldate = {2021-10-27},
	journal = {Science},
	author = {Boffey, Philip M.},
	month = nov,
	year = {1970},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/JEI6GWIN/science.170.3958.html:text/html},
}

@book{appropriations_department_1970,
	title = {Department of {Defense} {Appropriations} for 1971: {Hearings} ... {Ninety}-first {Congress}, {Second} {Session}},
	shorttitle = {Department of {Defense} {Appropriations} for 1971},
	language = {en},
	publisher = {U.S. Government Printing Office},
	author = {Appropriations, United States Congress House Committee on},
	year = {1970},
	note = {Google-Books-ID: CYC2AAAAIAAJ},
}

@article{kroeber_structure_1943,
	title = {Structure, {Function} and {Pattern} in {Biology} and {Anthropology}},
	volume = {56},
	issn = {0096-3771},
	url = {https://www.jstor.org/stable/17783},
	number = {2},
	urldate = {2021-11-02},
	journal = {The Scientific Monthly},
	author = {Kroeber, A. L.},
	year = {1943},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {105--113},
	file = {Kroeber - 1943 - Structure, Function and Pattern in Biology and Ant.pdf:/Users/rca2t1/Dropbox/Zotero/storage/JUX4K3JA/Kroeber - 1943 - Structure, Function and Pattern in Biology and Ant.pdf:application/pdf},
}

@article{botelho_medicine_1965,
	title = {Medicine in the {Year} 2000},
	volume = {147},
	issn = {0036-8075},
	url = {https://www.jstor.org/stable/1715791},
	number = {3662},
	urldate = {2021-11-02},
	journal = {Science},
	author = {Botelho, Stella Y.},
	year = {1965},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1164--1168},
	file = {Botelho - 1965 - Medicine in the Year 2000.pdf:/Users/rca2t1/Dropbox/Zotero/storage/3PYC42H8/Botelho - 1965 - Medicine in the Year 2000.pdf:application/pdf},
}

@article{simon_does_1973,
	title = {Does {Scientific} {Discovery} {Have} a {Logic}?},
	volume = {40},
	issn = {0031-8248},
	url = {https://www.jstor.org/stable/186282},
	abstract = {It is often claimed that there can be no such thing as a logic of scientific discovery, but only a logic of verification. By 'logic of discovery' is usually meant a normative theory of discovery processes. The claim that such a normative theory is impossible is shown to be incorrect; and two examples are provided of domains where formal processes of varying efficacy for discovering lawfulness can be constructed and compared. The analysis shows how one can treat operationally and formally phenomena that have usually been dismissed with fuzzy labels like 'intuition' and 'creativity'.},
	number = {4},
	urldate = {2021-11-02},
	journal = {Philosophy of Science},
	author = {Simon, Herbert A.},
	year = {1973},
	note = {Publisher: [The University of Chicago Press, Philosophy of Science Association]},
	pages = {471--480},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/4LC68CHG/Simon - 1973 - Does Scientific Discovery Have a Logic.pdf:application/pdf},
}

@book{noauthor_technical_1959,
	title = {Technical {News} {Bulletin}},
	language = {en},
	publisher = {The Bureau},
	year = {1959},
	annote = {See page 181.},
}

@article{samuel_artificial_1962,
	title = {Artificial {Intelligence}: {A} {Frontier} of {Automation}},
	volume = {340},
	issn = {0002-7162},
	shorttitle = {Artificial {Intelligence}},
	url = {https://www.jstor.org/stable/1033694},
	abstract = {Artificial intelligence is neither a myth nor a threat to man. It relates to a serious attempt to develop machine methods for dealing with some of the perplexing problems that should, in all justice, be delegated to machines but which now seem to require the exercise of human intelligence. Two fundamentally different approaches to the problem are being explored, the one aimed at a complete understanding of the intellectual processes involved and the other aimed at duplicating the assumed specific behavior of the brain. The first approach concerns itself with such matters as search, pattern recognition, learning, planning, and induction; the second approach involves a study of the behavior of random nets. It is fair to conclude that artificial intelligence promises to reduce rather than to augment technological unemployment.},
	urldate = {2021-11-02},
	journal = {The Annals of the American Academy of Political and Social Science},
	author = {Samuel, Arthur L.},
	year = {1962},
	note = {Publisher: [Sage Publications, Inc., American Academy of Political and Social Science]},
	pages = {10--20},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/84KVFGGE/Samuel - 1962 - Artificial Intelligence A Frontier of Automation.pdf:application/pdf},
}

@article{iivari_pioco_1987,
	title = {The {PIOCO} {Model} for {Information} {Systems} {Design}},
	volume = {11},
	issn = {0276-7783},
	url = {https://www.jstor.org/stable/248688},
	doi = {10.2307/248688},
	abstract = {The PIOCO model is a comprehensive methodology for information systems (IS) design consisting of a metamodel for an information system, the corresponding description languages, a process model for information systems design, and a model for choice and quality criteria. The metamodel for an information system consists of three levels of abstraction and forms a profound and articulated conceptual basis for the PIOCO model for the IS design process. The article gives an overview of the PIOCO approach from a management perspective, emphasizing the role of IS design as an inquiry process supporting the decision-making concerning the information system, the quality criteria related to the IS design, and the use of the PIOCO model as a macro-framework which integrates more detailed micro-level methodologies, methods, techniques and tools.},
	number = {3},
	urldate = {2021-11-02},
	journal = {MIS Quarterly},
	author = {Iivari, Juhani and Koskela, Erkki},
	year = {1987},
	note = {Publisher: Management Information Systems Research Center, University of Minnesota},
	pages = {401--419},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/MTHRWLNS/Iivari and Koskela - 1987 - The PIOCO Model for Information Systems Design.pdf:application/pdf},
}

@techreport{rosenfeld_image_1998,
	address = {College Park, MD},
	title = {From {Image} {Analysis} to {Computer} {Vision}: {Motives}, {Methods}, and {Milestones}},
	institution = {Center for Automation Research, University of Maryland},
	author = {Rosenfeld, Azriel},
	month = jul,
	year = {1998},
	note = {CAR-TR-892 
N00014-95-1-0521
CS-TR-3920},
	file = {Rosenfeld - 1998 - From Image Analysis to Computer Vision Motives, M.pdf:/Users/rca2t1/Dropbox/Zotero/storage/D2NN8XEM/Rosenfeld - 1998 - From Image Analysis to Computer Vision Motives, M.pdf:application/pdf},
}

@article{noauthor_back_1957,
	title = {Back {Matter}},
	volume = {126},
	issn = {0036-8075},
	url = {https://www.jstor.org/stable/1752180},
	number = {3270},
	urldate = {2021-11-04},
	journal = {Science},
	year = {1957},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {data processing scientistst},
	pages = {417--422},
	file = {1957 - Back Matter.pdf:/Users/rca2t1/Dropbox/Zotero/storage/I58MCTW4/1957 - Back Matter.pdf:application/pdf},
}

@book{egan_message_1957,
	title = {Message {Repetition}, {Operating} {Characteristics}, and {Confusion} {Matrices} in {Speech} {Communication}},
	language = {en},
	publisher = {Indiana University Hearing and Communication Laboratory},
	author = {Egan, James P.},
	year = {1957},
	note = {Google-Books-ID: iUhPAQAAMAAJ},
}

@misc{lincoln_laboratory_sage_2018,
	title = {{SAGE}: {Semi}-{Automatic} {Ground} {Environment} {Air} {Defense} {System} {\textbar} {MIT} {Lincoln} {Laboratory}},
	url = {https://www.ll.mit.edu/about/history/sage-semi-automatic-ground-environment-air-defense-system},
	urldate = {2021-11-04},
	journal = {Lincoln Laboratory, MIT},
	author = {{Lincoln Laboratory}},
	month = jul,
	year = {2018},
	file = {SAGE Semi-Automatic Ground Environment Air Defens.pdf:/Users/rca2t1/Dropbox/Zotero/storage/ZVYGIWVZ/SAGE Semi-Automatic Ground Environment Air Defens.pdf:application/pdf;SAGE\: Semi-Automatic Ground Environment Air Defense System | MIT Lincoln Laboratory:/Users/rca2t1/Dropbox/Zotero/storage/J8TX9VUC/sage-semi-automatic-ground-environment-air-defense-system.html:text/html},
}

@incollection{bhowmik_data_2021,
	address = {Cham},
	series = {Springer {Aerospace} {Technology}},
	title = {Data {Reduction} {Strategies}},
	isbn = {978-3-030-72192-3},
	url = {https://doi.org/10.1007/978-3-030-72192-3_9},
	abstract = {Based on the variety of methods available for gathering data for the aircraft health status, the challenge is to reduce the overall amount of data in a trackable and safe manner to ensure that the remaining data are characteristic of the current aircraft status. This chapter will cover available data reduction strategies for this task and discuss the data intensity of the SHM methods of Chaps. 5 to 8 and established approaches to deal with the acquired data. This includes aspects of algorithms and legal issues arising in this context.},
	language = {en},
	urldate = {2021-11-04},
	booktitle = {Structural {Health} {Monitoring} {Damage} {Detection} {Systems} for {Aerospace}},
	publisher = {Springer International Publishing},
	author = {Bhowmik, Basuraj and Quqa, Said and Sause, Markus G. R. and Pakrashi, Vikram and Droubi, Mohamad Ghazi},
	editor = {Sause, Markus G. R. and Jasiūnienė, Elena},
	year = {2021},
	doi = {10.1007/978-3-030-72192-3_9},
	keywords = {Data management, Compressed sensing, Data rate, Data reduction, Model order reduction, Real-time, Sampling rate, Wavelet transform, Wireless sensing},
	pages = {243--272},
	file = {Springer Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/4RZPJ8IX/Bhowmik et al. - 2021 - Data Reduction Strategies.pdf:application/pdf},
}

@misc{noauthor_air_2020,
	title = {The {Air} {Force} {Cambridge} {Research} {Laboratories} and the {New} {Manhattan} {Project}},
	url = {https://www.activistpost.com/2020/08/the-air-force-cambridge-research-laboratories-and-the-new-manhattan-project.html},
	abstract = {If one searches for the term ‘Project Cloverleaf,’ one will find very little credible documentation. But the author has uncovered something...},
	language = {en-US},
	urldate = {2021-11-04},
	journal = {Activist Post},
	month = aug,
	year = {2020},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TNXIU4FV/the-air-force-cambridge-research-laboratories-and-the-new-manhattan-project.html:text/html},
}

@book{loukides_what_2011-2,
	title = {What {Is} {Data} {Science}?},
	isbn = {978-1-4493-3608-0},
	url = {https://learning.oreilly.com/library/view/what-is-data/9781449336080/},
	abstract = {We've all heard it: according to Hal Varian, statistics is the next sexy job. Five years ago, in What is Web 2.0, Tim O'Reilly said that "data is the next Intel Inside." But what does that...},
	language = {en},
	urldate = {2022-01-16},
	publisher = {O'Reilly Media, Inc.},
	author = {Loukides, Mike},
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/J8WQS5SP/9781449336080.html:text/html},
}

@article{toonders_data_2014,
	title = {Data {Is} the {New} {Oil} of the {Digital} {Economy}},
	url = {https://www.wired.com/insights/2014/07/data-new-oil-digital-economy/},
	urldate = {2022-01-16},
	journal = {WIRED},
	author = {Toonders, Joris},
	month = jul,
	year = {2014},
	note = {JORIS TOONDERS, YONEGO},
	file = {Data Is the New Oil of the Digital Economy | WIRED:/Users/rca2t1/Dropbox/Zotero/storage/U6YVFVLL/data-new-oil-digital-economy.html:text/html},
}

@article{bhageshpur_data_2019,
	title = {Data {Is} {The} {New} {Oil} -- {And} {That}'s {A} {Good} {Thing}},
	shorttitle = {Council {Post}},
	url = {https://www.forbes.com/sites/forbestechcouncil/2019/11/15/data-is-the-new-oil-and-thats-a-good-thing/},
	abstract = {We must manage the dark side of data, but the advances in data fuels are worth the effort.},
	language = {en},
	urldate = {2022-01-16},
	journal = {Forbes},
	author = {Bhageshpur, Kiran},
	month = nov,
	year = {2019},
	note = {Section: Innovation},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6RZS6K2V/data-is-the-new-oil-and-thats-a-good-thing.html:text/html},
}

@article{noauthor_worlds_2017,
	title = {The {World}’s {Most} {Valuable} {Resource} {Is} {No} {Longer} {Oil}, but {Data}},
	url = {https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data},
	urldate = {2022-01-16},
	journal = {The Economist},
	month = may,
	year = {2017},
	file = {The world’s most valuable resource is no longer oil, but data | The Economist:/Users/rca2t1/Dropbox/Zotero/storage/X8QIQD8M/the-worlds-most-valuable-resource-is-no-longer-oil-but-data.html:text/html},
}

@article{cai_statistical_2019,
	title = {Statistical {Theory} {Powering} {Data} {Science}},
	volume = {34},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-34/issue-4/Statistical-Theory-Powering-Data-Science/10.1214/19-STS754.full},
	doi = {10.1214/19-STS754},
	abstract = {Statisticians are finding their place in the emerging field of data science. However, many issues considered “new” in data science have long histories in statistics. Examples of using statistical thinking are illustrated, which range from exploratory data analysis to measuring uncertainty to accommodating nonrandom samples. These examples are then applied to service networks, baseball predictions and official statistics.},
	number = {4},
	urldate = {2022-01-18},
	journal = {Statistical Science},
	author = {Cai, Junhui and Mandelbaum, Avishai and Nagaraja, Chaitra H. and Shen, Haipeng and Zhao, Linda},
	month = nov,
	year = {2019},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {decennial census, Empirical Bayes, house price index, nonparametric estimation, Queueing theory, Service networks, sports statistics},
	pages = {669--691},
	file = {Cai et al. - 2019 - Statistical Theory Powering Data Science.pdf:/Users/rca2t1/Dropbox/Zotero/storage/LPJSBPD7/Cai et al. - 2019 - Statistical Theory Powering Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3YV3MSR2/19-STS754.html:text/html},
}

@book{helvey_age_1971,
	title = {The {Age} of {Information}: {An} {Interdisciplinary} {Survey} of {Cybernetics}},
	isbn = {978-0-87778-008-3},
	shorttitle = {The {Age} of {Information}},
	language = {en},
	publisher = {Educational Technology},
	author = {Helvey, T. C.},
	year = {1971},
	note = {Google-Books-ID: L8YxYRSZYCkC},
}

@book{information_new_1985,
	title = {New {Scientist}},
	abstract = {New Scientist magazine was launched in 1956 "for all those men and women who are interested in scientific discovery, and in its industrial, commercial and social consequences". The brand's mission is no different today - for its consumers, New Scientist reports, explores and interprets the results of human endeavour set in the context of society and culture.},
	language = {en},
	publisher = {Reed Business Information},
	author = {Information, Reed Business},
	month = sep,
	year = {1985},
	note = {Google-Books-ID: Z3S9oWs189EC},
}

@article{ogaz_telemetry_1989,
	title = {Telemetry {Data} {Processing} at {White} {Sands} {Missile} {Range}},
	issn = {0884-5123},
	url = {https://repository.arizona.edu/handle/10150/614840},
	abstract = {Prior to 1985 the National Range had, for a number of years, serious and recurring mission support problems with the IBM 360 Telemetry Data Processing System due to equipment reliability and obsolescence of the system which was installed in 1968. These problems became particularly acute when higher data rate requirements and the need for reliable telemetry data processing dictated that prompt and unusual action was necessary if WSMR was to continue to provide telemetry data processing support. Realizing that the above cited problems of reliability and obsolescence would continue in detriment to the mission of WSMR, Department of Defense (DOD) and the nation, coupled with the loss of thousands of dollars in reimbursables due to WSMR’s inability to support missile test requirements, the Systems Engineering Branch was tasked by the Director of National Range to lead a study, and propose and implement solutions to meet current and future requirements in telemetry data processing support. With the explosion in PCM data rates, it had become obvious that WSMR could not continue to upgrade existing systems and meet the demands of the future. More data parameters at higher data rates were being processed in PCM, FM, and PAM. Telemetry formats were becoming more complicated, such as embedded asynchronous subcomms and dynamic format changes. More real-time decisions had to be made for mission safety, verification of location, and mission success. WSMR needed a more versatile system that would synchronize, process and display higher data rates with more accuracy than it had at this time. This paper describes a historical perspective of steps WSMR has taken to satisfy present and future test vehicle telemetry data processing requirements.},
	language = {en\_US},
	urldate = {2022-03-03},
	author = {Ogaz, Juan A.},
	month = nov,
	year = {1989},
	note = {Accepted: 2016-06-27T18:42:50Z
Publisher: International Foundation for Telemetering},
	annote = {The history of telemetry data processing at WSMR begins with the installation of the IBM 360 based system in the Telemetry Data Center (TDC) that went into operation in 1968. This system was able to process data at a rate of 50K samples per second. These samples could come from six PAM streams, four FM streams, two PCM streams, or a combination of these inputs as long as the total rate of data was 50K or less.
Telemetry (TM) data of this era was fairly simple consisting of standard measurements of pressure, vibration, attitude, voltages, and events. Data rates used by projects were well below the 50K limitation of the IBM 360 TM system.
Telemetry technology began to change in the early 70’s as electronics began to shrink in size and grow in capability. Telemetry test packages began using onboard microprocessors which allowed them to respond to changes in mission profiles in real-time. The need to monitor these changes led to an increase in measured parameters with a corresponding increase in data rates. One of the first projects to severely tax the IBM 360 TM system was an Army missile system. It used a 100K sample PAM for its TM. TDC support was limited to recording the data in real-time, then making reduced speed playbacks to slow down the rate to a speed the IBM 360 TM system could handle. The rule of thumb became for every hour of real-time, two and one half hours of playback time were required. With this system being just one of many projects to support, there literally was not enough time in a day for TDC to support the range. It became necessary to run a second shift crew, whose sole purpose was to catch up on playbacks.

},
	file = {Ogaz - 1989 - Telemetry Data Processing at White Sands Missile R.pdf:/Users/rca2t1/Dropbox/Zotero/storage/L64I6T86/Ogaz - 1989 - Telemetry Data Processing at White Sands Missile R.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/Z57AVZ66/614840.html:text/html},
}

@misc{noauthor_proceedings_nodate,
	title = {Proceedings - {Google} {Books}},
	url = {https://www.google.com/books/edition/Proceedings/nm7xAAAAMAAJ?hl=en&gbpv=0},
	urldate = {2022-03-03},
	file = {Proceedings - Google Books:/Users/rca2t1/Dropbox/Zotero/storage/TMH366LX/nm7xAAAAMAAJ.html:text/html},
}

@book{noauthor_proceedings_1983,
	title = {Proceedings},
	language = {en},
	publisher = {U. S. Army Research Office},
	year = {1983},
	note = {Google-Books-ID: nm7xAAAAMAAJ},
}

@book{noauthor_development_2009,
	title = {Development and {Implementation} of {Range}-wide {Mission} and {Major} {Capabilities} at {White} {Sands} {Missile} {Range}, {New} {Mexico}: {Environmental} {Impact} {Statement}},
	shorttitle = {Development and {Implementation} of {Range}-wide {Mission} and {Major} {Capabilities} at {White} {Sands} {Missile} {Range}, {New} {Mexico}},
	language = {en},
	year = {2009},
	note = {Google-Books-ID: INU3AQAAMAAJ},
	annote = {Reference to Data Sciences Directorate},
}

@misc{noauthor_white_2011,
	title = {White {Sands} {Missile} {Range} {Factbook}},
	url = {https://docplayer.net/89767060-Land-airspace-and-terrain.html},
	abstract = {Where We Are Introduction White Sands Missile Range (WSMR ) is a unique tri-service installation, dedicated to Test and Evaluation (T\&E) to assess military systems and commercial products. As the largest},
	urldate = {2022-03-04},
	year = {2011},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/GY58IC65/89767060-Land-airspace-and-terrain.html:text/html},
}

@book{noauthor_proceedings_1980,
	title = {Proceedings of the ... {Conference} on the {Design} of {Experiments}},
	language = {en},
	publisher = {U.S. Army Research Office},
	year = {1980},
	note = {Google-Books-ID: 0LsrAQAAMAAJ},
}

@incollection{noauthor_white_nodate,
	title = {White {Sands} {Administrative} {History}},
	url = {http://www.nps.gov/archive/whsa/adhi/adhi4d.htm},
	booktitle = {Chapter {Four}: {Global} {War} at {White} {Sands} 1940–1945},
	publisher = {National Park Service},
	note = {Context Object: ctx\_ver=Z39.88-2004\&rft\_val\_fmt=info\%3Aofi\%2Ffmt\%3Akev\%3Amtx\%3Abook\&rft.genre=bookitem\&rft.btitle=Chapter+Four\%3A+Global+War+at+White+Sands+1940\%E2\%80\%931945\&rft.atitle=White+Sands+Administrative+History\&rft.pub=National+Park+Service\&rft\_id=http\%3A\%2F\%2Fwww.nps.gov\%2Farchive\%2Fwhsa\%2Fadhi\%2Fadhi4d.htm\&rfr\_id=info:sid/en.wikipedia.org:White\_Sands\_Missile\_Range},
	file = {White Sands Missile Range | Military Wiki | Fandom:/Users/rca2t1/Dropbox/Zotero/storage/S747LD6G/White_Sands_Missile_Range.html:text/html},
}

@misc{white_sands_missile_range_museum_white_2021,
	title = {White {Sands} {Missile} {Range} {Hall} of {Fame}},
	url = {https://wsmrmuseum.com/wsmr-historical-foundation-hall-of-fame/},
	abstract = {The White Sands Missile Range Hall of Fame was founded in 1980 by Major General Duard D. Ball to recognize Missile Range civilian, military, and contractor personnel for outstanding contributions m…},
	language = {en-US},
	urldate = {2022-03-04},
	journal = {White Sands Missile Range Museum},
	author = {{White Sands Missile Range Museum}},
	month = jan,
	year = {2021},
	annote = {Data Sciences Division in 1974
"Higgins came to White Sands in 1950 as a physical science aide. As his career progressed, he worked as a mathematician, supervisory mathematician and supervisory physical scientist in the Data Reduction Division of what is now the National Range Operations Directorate. In the late 1960s he served as chief of the support branch of the Analysis and Computation Division and later as chief of the Operations branch of the same division. He assumed the duties as chief of the Data Sciences Division in 1974."},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/35TE3EY9/30.html:text/html},
}

@article{noauthor_about_1975,
	title = {about our members},
	volume = {56},
	issn = {0003-0007},
	url = {https://www.jstor.org/stable/26215937},
	number = {3},
	urldate = {2022-03-04},
	journal = {Bulletin of the American Meteorological Society},
	year = {1975},
	note = {Publisher: American Meteorological Society},
	pages = {384--385},
}

@article{breiman_general_1976,
	title = {General {Estimates} of the {Intrinsic} {Variability} of {Data} in {Nonlinear} {Regression} {Models}},
	volume = {71},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2285301},
	doi = {10.2307/2285301},
	abstract = {A dependent variable is some unknown function of independent variables plus an error component. If the magnitude of the error could be estimated with minimal assumptions about the underlying functional dependence, then this could be used to judge goodness-of-fit and as a means of selecting a subset of the independent variables which best determine the dependent variable. We propose a procedure for this purpose which is based on a data-directed partitioning of the space into subregions and a fitting of the function in each subregion. The behavior of the procedure is heuristically discussed and illustrated by some simulation examples.},
	number = {354},
	urldate = {2022-03-04},
	journal = {Journal of the American Statistical Association},
	author = {Breiman, L. and Meisel, W. S.},
	year = {1976},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {301--307},
	annote = {Meisel worked for the Data Sciences Division of the Technology Services Corporation.},
	file = {Breiman and Meisel - 1976 - General Estimates of the Intrinsic Variability of .pdf:/Users/rca2t1/Dropbox/Zotero/storage/UERDZM3N/Breiman and Meisel - 1976 - General Estimates of the Intrinsic Variability of .pdf:application/pdf},
}

@misc{noauthor_technology_2022,
	title = {Technology {Service} {Corporation}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Technology_Service_Corporation&oldid=1066387237},
	abstract = {Technology Service Corporation (TSC) is an American engineering company headquartered in Arlington, Virginia, providing services and specialized products to the U.S. government agencies and private industry.},
	language = {en},
	urldate = {2022-03-04},
	journal = {Wikipedia},
	month = jan,
	year = {2022},
	note = {Page Version ID: 1066387237},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/DPCC2XIH/Technology_Service_Corporation.html:text/html},
}

@book{appropriations_independent_1965,
	title = {Independent {Offices} {Appropiations} for 1966: {Hearings} ... 89th {Congress}, 1st {Session}, {Part} 3},
	shorttitle = {Independent {Offices} {Appropiations} for 1966},
	language = {en},
	author = {Appropriations, United States Congress House},
	year = {1965},
	note = {Google-Books-ID: vkaereBadBMC},
}

@misc{noauthor_woce_nodate,
	title = {{WOCE} findings on the {Atlantic} now available as a printed {Atlas}},
	url = {https://www.clisap.de/clisap/about-us/news/woce-findings-on-the-atlantic-now-available-as-a-printed-atlas/},
	abstract = {The World Ocean Circulation Experiment (WOCE) is the most extensive endeavor to investigate and measure the world ocean in our history. “It offers us a tremendous amount of data on temperatures, salinity, nutrient concentrations and water transport  in the ocean,” explains Viktor Gouretski from the Integrated Climate Data Center (ICDC). Together with colleagues from Hamburg and Moscow, he has now completed the third part of the WOCE Atlas in printed form: the most important findings on the Atlantic Ocean.},
	language = {en-GB},
	urldate = {2022-03-05},
	annote = { Kai Jancke},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/UZT2873S/woce-findings-on-the-atlantic-now-available-as-a-printed-atlas.html:text/html},
}

@misc{noauthor_nara_nodate,
	title = {{NARA} - {AAD} - {Series} {Description} - {Records} of {Prime} {Contracts} {Awarded} by the {Military} {Services} and {Agencies}, created, 7/1/1965 - 6/30/1975, documenting the period 7/1/1965 - 6/30/1975},
	url = {https://aad.archives.gov/aad/series-description.jsp?s=492&cat=GS29&q=%22data+science%22&popup=Y},
	urldate = {2022-03-07},
	file = {NARA - AAD - Series Description - Records of Prime Contracts Awarded by the Military Services and Agencies, created, 7/1/1965 - 6/30/1975, documenting the period 7/1/1965 - 6/30/1975:/Users/rca2t1/Dropbox/Zotero/storage/EQBQ84B4/series-description.html:text/html},
}

@article{miller_cri_nodate,
	title = {{CRI}: {A} {Western} {New} {York} {Computational} and {Data} {Science} {Grid}},
	shorttitle = {{CRI}},
	url = {https://grantome.com/grant/NSF/CNS-0454114},
	abstract = {CRI: Developing the Lemur Toolkit into a Community Resource Proposal: CNS 0454114 PI: Russ Miller Institution: SUNY at BuffaloThis project builds on the Western New York Bio-informatics and Life Scien...},
	language = {en},
	urldate = {2022-03-07},
	author = {Miller, Russ and McCourt, Mary and Farian, Homma and Weeks, Charles and Green, Mark},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/9Z3SDWGV/CNS-0454114.html:text/html},
}

@article{noauthor_impact_1985,
	title = {Impact of withdrawal and disinvestment from {South} {Africa} on the {U}.{S}. {Economy} : hearing before the {Subcommittee} on {Domestic} {Monetary} {Policy} of the {Committee} on {Banking}, {Finance}, and {Urban} {Affairs}, {House} of {Representatives}, {Ninety}-ninth {Congress}, first session, {September} 26, 1985.   {Note}},
	shorttitle = {Impact of withdrawal and disinvestment from {South} {Africa} on the {U}.{S}. {Economy}},
	url = {https://heinonline.org/HOL/P?h=hein.cbhear/iwdsa0001&i=167},
	language = {eng},
	urldate = {2022-03-07},
	journal = {Impact of withdrawal and disinvestment from South Africa on the U.S. Economy : hearing before the Subcommittee on Domestic Monetary Policy of the Committee on Banking, Finance, and Urban Affairs, House of Representatives, Ninety-ninth Congress, first session, September 26, 1985.},
	year = {1985},
	pages = {I--268},
	file = {1985 - Impact of withdrawal and disinvestment from South .pdf:/Users/rca2t1/Dropbox/Zotero/storage/PSA88KIX/1985 - Impact of withdrawal and disinvestment from South .pdf:application/pdf},
}

@article{noauthor_dioxin_1984,
	title = {Dioxin - {The} {Impact} on {Human} {Health} {Note}},
	url = {https://heinonline.org/HOL/P?h=hein.cbhear/cbhearings1627&i=240},
	language = {eng},
	urldate = {2022-03-07},
	journal = {Dioxin--the impact on human health : hearings before the Subcommittee on Natural Resources, Agriculture Research, and Environment of the Committee on Science and Technology, U.S. House of Representatives, Ninety-eighth Congress, first session, June 30; July 13, 28, 1983.},
	year = {1984},
	pages = {I--252},
}

@article{noauthor_use_1982,
	title = {The use of animals in medical research and testing : hearings before the {Subcommittee} on {Science}, {Research}, and {Technology} of the {Committee} on {Science} and {Technology}, {U}.{S}. {House} of {Representatives}, {Ninety}-seventh {Congress}, first session, {October} 13, 14, 1981.   {Note}},
	shorttitle = {The use of animals in medical research and testing},
	url = {https://heinonline.org/HOL/P?h=hein.cbhear/tuoaimrat0001&i=340},
	language = {eng},
	urldate = {2022-03-07},
	journal = {The use of animals in medical research and testing : hearings before the Subcommittee on Science, Research, and Technology of the Committee on Science and Technology, U.S. House of Representatives, Ninety-seventh Congress, first session, October 13, 14, 1981.},
	year = {1982},
	pages = {I--748},
}

@misc{noauthor_protocol_1979,
	title = {Protocol: {Project} {Ranch} {Hand} {II}, {Epidemiologic} {Investigation} of {Health} {Effects} in {Air} {Force} {Personnel} {Following} {Exposure} to "{Herbicide} {Orange}", {Matched} {Cohort} {Design}},
	shorttitle = {Protocol},
	url = {https://www.nal.usda.gov/exhibits/speccoll/items/show/2566},
	abstract = {Corporate Author: Epidemiology Division, Data Sciences Division, Clinical Sciences Division, USAF School of Aerospace Medicine (USAFSAM), Brooks AFB, Texas},
	urldate = {2022-03-07},
	month = dec,
	year = {1979},
	note = {Context Object: ctx\_ver=Z39.88-2004\&rft\_val\_fmt=info\%3Aofi\%2Ffmt\%3Akev\%3Amtx\%3Adc\&rfr\_id=info\%3Asid\%2Fomeka.org\%3Agenerator\&rft.subject=Air+Force+Health+Study\&rft.date=December+12+1979\&rft.title=Protocol\%3A+Project+Ranch+Hand+II\%2C+Epidemiologic+Investigation+of+Health+Effects+in+Air+Force+Personnel+Following+Exposure+to+\%22Herbicide+Orange\%22\%2C+Matched+Cohort+Design\&rft.description=Corporate+Author\%3A+Epidemiology+Division\%2C+Data+Sciences+Division\%2C+Clinical+Sciences+Division\%2C+USAF+School+of+Aerospace+Medicine+\%28USAFSAM\%29\%2C+Brooks+AFB\%2C+Texas\&rft.type=document\&rft.identifier=https\%3A\%2F\%2Fwww.nal.usda.gov\%2Fexhibits\%2Fspeccoll\%2Fitems\%2Fshow\%2F2566},
	keywords = {Air Force Health Study},
	file = {1979 - Protocol Project Ranch Hand II, Epidemiologic Inv.pdf:/Users/rca2t1/Dropbox/Zotero/storage/98EEWW2Q/1979 - Protocol Project Ranch Hand II, Epidemiologic Inv.pdf:application/pdf;Protocol\: Project Ranch Hand II, Epidemiologic Investigation of Health Effects in Air Force Personnel Following Exposure to "Herbicide Orange", Matched Cohort Design ·:/Users/rca2t1/Dropbox/Zotero/storage/HX2KGLXK/2566.html:text/html},
}

@article{engelken_application_1982,
	title = {Application of digital filters in the processing of eye movement data},
	volume = {14},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/BF03203222},
	doi = {10.3758/BF03203222},
	abstract = {Digital filter techniques have been applied to the analysis of eye movement data. Methods were developed to calculate eye velocity and eye acceleration in real-time from an electronystag-mogram (ENG) signal that was recorded using a one-pole RC high-pass filter in the preamplifier. Nonrecursive, finite impulse-response digital filters were designed to remove the effects of the RC high-pass filter and calculate the first and second time derivatives of the ENG signal, as well as remove high-frequency noise. Applying these new techniques to the analysis of vestibular nystagmus enables estimation of the transfer characteristics of the vestibuloocular system.},
	language = {en},
	number = {3},
	urldate = {2022-03-07},
	journal = {Behavior Research Methods \& Instrumentation},
	author = {Engelken, Edward J. and Stevens, Kennith W. and Wolfe, James W.},
	month = may,
	year = {1982},
	pages = {314--319},
	file = {Springer Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/LVITHY4H/Engelken et al. - 1982 - Application of digital filters in the processing o.pdf:application/pdf},
}

@techreport{samn_optimal_1981,
	title = {Optimal {Staging} and {Scheduling} in {Airlift} {Operations}.},
	url = {https://apps.dtic.mil/sti/citations/ADA107518},
	abstract = {This report shows that to achieve maximum aircraft utilization in airlift operations, optimal scheduling and staging can be formulated as a generalized network problem and solved using mixed-integer programming techniques. Author},
	language = {en},
	urldate = {2022-03-07},
	institution = {SCHOOL OF AEROSPACE MEDICINE BROOKS AFB TX},
	author = {Samn, Sherwood W.},
	month = sep,
	year = {1981},
	note = {Section: Technical Reports},
	file = {Samn - 1981 - Optimal Staging and Scheduling in Airlift Operatio.pdf:/Users/rca2t1/Dropbox/Zotero/storage/T3MIIXKZ/Samn - 1981 - Optimal Staging and Scheduling in Airlift Operatio.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/AU9NEB3D/ADA107518.html:text/html},
}

@article{gupta_exact_1985,
	title = {An exact test for the mean of a normal distribution with a known coefficient of variation},
	volume = {3},
	issn = {0167-9473},
	url = {https://www.sciencedirect.com/science/article/pii/0167947385900854},
	doi = {10.1016/0167-9473(85)90085-4},
	abstract = {Tables are presented for the critical value, power and sample size required to attain a given power at a given alternative for the likelihood ratio statistic for testing H0: θ = θ0 versus H1: θ = θ1 {\textgreater} θ0, where θ is the mean of a normal distribution having variance a2θ2 with the coefficient of variation, a, assumed known.},
	language = {en},
	urldate = {2022-03-07},
	journal = {Computational Statistics \& Data Analysis},
	author = {Gupta, Ramesh and Tripathi, Ram and Michalek, Joel and White, Thomas},
	month = may,
	year = {1985},
	keywords = {Coefficient of variation, Exact test, Normal distribution},
	pages = {219--226},
	file = {ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/J2ZGLM5Q/0167947385900854.html:text/html},
}

@article{wolfe_epidemiologic_1985,
	title = {An epidemiologic investigation of health effects in {Air} {Force} personnel following exposure to herbicides and associated dioxins},
	volume = {14},
	issn = {0045-6535},
	url = {https://www.sciencedirect.com/science/article/pii/004565358590178X},
	doi = {10.1016/0045-6535(85)90178-X},
	abstract = {In 1979 the United States Air Force (USAF) made the commitment to conduct an epidemiologic study of the possible health effects from chemical exposure in Air Force personnel who conducted aerial herbicide dissemination missions in Vietnam (Operation RANCH HAND). The purpose of this epidemiologic investigation is to determine whether long-term health effects exist and can be attributed to occupational exposure to herbicides. This study uses a matched cohort design in a nonconcurrent prospective setting, incorporating mortality, morbidity, and follow-up studies. This paper presents the results of the analysis of health information on 2706 Ranch Handers and comparison individuals obtained by questionnaire and 2269 Ranch Handers and comparison individuals undergoing an extensive physical examination. There is insufficient evidence to support a cause and effect relationship between herbicide exposure and adverse health in the Ranch Hand group at this time. The study has disclosed numerous medical findings, mostly of a minor or undetermined nature, that require detailed follow-up.},
	language = {en},
	number = {6},
	urldate = {2022-03-07},
	journal = {Chemosphere},
	author = {Wolfe, William H. and Lathrop, George D. and Albanese, Richard A. and Moynahan, Patricia M.},
	month = jan,
	year = {1985},
	pages = {707--716},
	file = {ScienceDirect Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/FIJIP5PF/Wolfe et al. - 1985 - An epidemiologic investigation of health effects i.pdf:application/pdf;ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/3U7TUZEF/004565358590178X.html:text/html},
}

@article{noauthor_agent_1988,
	title = {"{Agent} {Orange} {Legislation} and {Oversight}," {Hearing} before the {Veterans}' {Affairs} {Committee}, {May} 12, 1988. {S}. {Hrg}. 100-1025 {Senate} {Hearings}: 100th {Congress}: {Document} {No}. 25},
	volume = {5},
	shorttitle = {"{Agent} {Orange} {Legislation} and {Oversight}," {Hearing} before the {Veterans}' {Affairs} {Committee}, {May} 12, 1988. {S}. {Hrg}. 100-1025 {Senate} {Hearings}},
	url = {https://heinonline.org/HOL/P?h=hein.leghis/vjra0005&i=712},
	language = {eng},
	urldate = {2022-03-07},
	journal = {Legislative History of the Veterans' Judicial Review Act; Veteran's Benefits Improvement Act of 1988: P.L. 100-687, 102 Stat. 4105, November 18, 1988},
	year = {1988},
	pages = {I--712},
}

@article{noauthor_agent_1980,
	title = {Agent orange update and appendix, agent orange activities (part {II}) : hearing before the {Committee} on {Veterans}' {Affairs}, {United} {States} {Senate}, {Ninety}-sixth {Congress}, second session, {September} 10, 1980.   {Note}},
	shorttitle = {Agent orange update and appendix, agent orange activities (part {II})},
	url = {https://heinonline.org/HOL/P?h=hein.cbhear/agoraup0001&i=1},
	language = {eng},
	urldate = {2022-03-10},
	journal = {Agent orange update and appendix, agent orange activities (part II) : hearing before the Committee on Veterans' Affairs, United States Senate, Ninety-sixth Congress, second session, September 10, 1980.},
	year = {1980},
	pages = {I--1368},
}

@article{noauthor_data_1970-1,
	title = {Data {Science} {Division} {Losses} {Revealed} by {URS}},
	url = {http://archive.org/details/computerworld4125unse13},
	language = {English},
	urldate = {2022-03-11},
	journal = {Computerworld},
	month = apr,
	year = {1970},
	pages = {49},
}

@article{noauthor_note_1965,
	title = {Note},
	url = {https://heinonline.org/HOL/P?h=hein.cbhear/iofaprs0001&i=1},
	language = {eng},
	urldate = {2022-03-11},
	journal = {Independent Offices Appropriations for 1966, Hearings before a Subcommittee of the Committee on Appropriations, House of Representatives, Eighty-Ninth Congress, First Session, Pt. 3},
	year = {1965},
	pages = {I--1038},
}

@article{youngblood_vital_2005,
	address = {Minneapolis, MN},
	title = {Vital {Signs} {Good} for {Heart}-{Monitor} {Firm}},
	url = {https://advance.lexis.com/document/teaserdocument/?pdmfid=1516831&crid=41bb862e-47b7-49fb-95a3-5ae81d32f419&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4G3D-TM40-00J2-31K9-00000-00&pddocid=urn%3AcontentItem%3A4G3D-TM40-00J2-31K9-00000-00&pdcontentcomponentid=8384&pdteaserkey=h1&pditab=allpods&ecomp=wzvnk&earg=sr0&prid=b86e80c1-d1fc-4e23-8309-6c35e10d7a2b},
	urldate = {2022-03-11},
	journal = {Star Tribune},
	author = {Youngblood, Dick},
	month = may,
	year = {2005},
	annote = {Data Sciences Division of Transoma Medical Inc.
 },
	file = {Vital signs good for heart-monitor firm:/Users/rca2t1/Dropbox/Zotero/storage/RPWBUPNC/teaserdocument.html:text/html},
}

@article{noauthor_1259_1980,
	title = {\$12.59 {Million} {Federal} {Contract} {Awarded} to {IP} {Network} {Solutions}},
	url = {https://advance.lexis.com/document/?pdmfid=1516831&crid=7213c258-ef3a-4126-8db3-a0d7b37dc21c&pddocfullpath=%2Fshared%2Fdocument%2Fnews%2Furn%3AcontentItem%3A4V5D-Y7V0-TYCS-10RF-00000-00&pdcontentcomponentid=299219&pdteaserkey=sr1&pditab=allpods&ecomp=wzvnk&earg=sr1&prid=b86e80c1-d1fc-4e23-8309-6c35e10d7a2b},
	urldate = {2022-03-11},
	journal = {Wall Street Journal},
	month = apr,
	year = {1980},
	pages = {19},
}

@misc{noauthor_eric_nodate,
	title = {{ERIC} {ED215889}: {Only} {One} {Science}: {Twelfth} {Annual} {Report} of the {National} {Science} {Board}. : {ERIC} : {Free} {Download}, {Borrow}, and {Streaming}},
	shorttitle = {{ERIC} {ED215889}},
	url = {https://archive.org/details/ERIC_ED215889},
	abstract = {Departing markedly from previous reports to Congress by the National Science Board, this document presents in an informal, narrative style six stories...},
	language = {en},
	urldate = {2022-03-11},
	journal = {Internet Archive},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/YZDVKKJ3/2up.html:text/html},
}

@book{considine_handbook_1964,
	title = {Handbook of applied instrumentation},
	url = {http://archive.org/details/handbookofapplie00cons},
	abstract = {Includes bibliographies},
	language = {eng},
	urldate = {2022-03-11},
	publisher = {New York, McGraw-Hill},
	author = {Considine, Douglas M.},
	collaborator = {{Internet Archive}},
	year = {1964},
	keywords = {Measurement},
}

@misc{palmer_data_2006,
	title = {Data is the {New} {Oil}},
	url = {https://ana.blogs.com/maestros/2006/11/data_is_the_new.html},
	abstract = {By Michael Palmer "Data is the new oil!" Clive Humby, ANA Senior marketer’s summit, Kellogg School. Data is just like crude. It’s valuable, but if unrefined it cannot really be used. It has to be changed into gas, plastic, chemicals,...},
	urldate = {2022-03-28},
	journal = {ANA Marketing Maestros},
	author = {Palmer, Michael},
	month = nov,
	year = {2006},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/IUELAYV2/data_is_the_new.html:text/html},
}

@misc{noauthor_student_1967,
	title = {Student {Text} {Introduction} to {IBM} {System}/360 {Architecture}},
	publisher = {International Business Machines Corporation},
	year = {1967},
	file = {GC20-1667-1_intro360arch.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HFPRNST9/GC20-1667-1_intro360arch.pdf:application/pdf},
}

@inproceedings{shcherbakov_lean_2014,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Lean {Data} {Science} {Research} {Life} {Cycle}: {A} {Concept} for {Data} {Analysis} {Software} {Development}},
	isbn = {978-3-319-11854-3},
	shorttitle = {Lean {Data} {Science} {Research} {Life} {Cycle}},
	doi = {10.1007/978-3-319-11854-3_61},
	abstract = {Data Science is a new study that combines computer science, data mining, data engineering and software development. Based on the concept of lean software development we propose an idea of lean data science research as a technology for data analysis software development. This concept includes the mandatory stages of the life cycle that meet the lean manufacturing principles. We have defined the business understanding stage with defining the targeted questions, the set of lean data analysis sprints and a decision support stage. Each lean data analysis sprint contents of the task statement step, a step of data integration, a step of data analysis and the interpretation of the results. This approach allows to build data analysis software with iterative improvement quality of the results. Some case study have been suggested as examples of the proposed concept.},
	language = {en},
	booktitle = {Knowledge-{Based} {Software} {Engineering}},
	publisher = {Springer International Publishing},
	author = {Shcherbakov, Maxim and Shcherbakova, Nataliya and Brebels, Adriaan and Janovsky, Timur and Kamaev, Valery},
	editor = {Kravets, Alla and Shcherbakov, Maxim and Kultsova, Marina and Iijima, Tadashi},
	year = {2014},
	keywords = {data science, data analysis, software development},
	pages = {708--716},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/2NPHIPIW/Shcherbakov et al. - 2014 - Lean Data Science Research Life Cycle A Concept f.pdf:application/pdf},
}

@misc{wasserman_data_2013-1,
	title = {Data {Science}: {The} {End} of {Statistics}?},
	shorttitle = {Data {Science}},
	url = {https://normaldeviate.wordpress.com/2013/04/13/data-science-the-end-of-statistics/},
	abstract = {Data Science: The End of Statistics? As I see newspapers and blogs filled with talk of “Data Science” and “Big Data” I find myself filled with a mixture of optimism and drea…},
	language = {en},
	urldate = {2022-06-05},
	journal = {Normal Deviate},
	author = {Wasserman, Larry},
	month = apr,
	year = {2013},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/PDAKW8K7/data-science-the-end-of-statistics.html:text/html},
}

@misc{piatetsky_is_2013,
	title = {Is {Data} {Science} {The} {End} of {Statistics}? {A} {Discussion}},
	shorttitle = {Is {Data} {Science} {The} {End} of {Statistics}?},
	url = {https://www.kdnuggets.com/is-data-science-the-end-of-statistics-a-discussion.html/},
	abstract = {Here is an interesting discussion on LinkedIn, started by a provocative post "Data Science: The End of Statistics?" What is the relationship between Data Science and Statistics and in what sense are "Statistics" ending?},
	language = {en-US},
	urldate = {2022-06-05},
	journal = {KDnuggets},
	author = {Piatetsky, Gregory},
	month = oct,
	year = {2013},
	note = {Section: Apr Publications},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/CKPIEB34/data-science-end-statistics-discussion.html:text/html},
}

@misc{broman_data_2013-1,
	title = {Data science is statistics},
	url = {https://kbroman.wordpress.com/2013/04/05/data-science-is-statistics/},
	abstract = {When physicists do mathematics, they don’t say they’re doing “number science”. They’re doing math. If you’re analyzing data, you’re doing statistics. You c…},
	language = {en},
	urldate = {2022-06-05},
	journal = {The stupidest thing...},
	author = {Broman, Karl},
	month = apr,
	year = {2013},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/4HH8QXME/data-science-is-statistics.html:text/html},
}

@misc{broman_i_2016-1,
	title = {I am a data scientist},
	url = {https://kbroman.wordpress.com/2016/04/08/i-am-a-data-scientist/},
	abstract = {Three years ago this week, I wrote a blog post, “Data science is statistics”. I was fiercely against the term at that time, as I felt that we already had a data science, and it was called Statistic…},
	language = {en},
	urldate = {2022-06-05},
	journal = {The stupidest thing...},
	author = {Broman, Karl},
	month = apr,
	year = {2016},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6A8SS3X4/i-am-a-data-scientist.html:text/html},
}

@inproceedings{menzies_data_2013,
	title = {Data science for software engineering},
	doi = {10.1109/ICSE.2013.6606752},
	abstract = {Target audience: Software practitioners and researchers wanting to understand the state of the art in using data science for software engineering (SE). Content: In the age of big data, data science (the knowledge of deriving meaningful outcomes from data) is an essential skill that should be equipped by software engineers. It can be used to predict useful information on new projects based on completed projects. This tutorial offers core insights about the state-of-the-art in this important field. What participants will learn: Before data science: this tutorial discusses the tasks needed to deploy machine-learning algorithms to organizations (Part 1: Organization Issues). During data science: from discretization to clustering to dichotomization and statistical analysis. And the rest: When local data is scarce, we show how to adapt data from other organizations to local problems. When privacy concerns block access, we show how to privatize data while still being able to mine it. When working with data of dubious quality, we show how to prune spurious information. When data or models seem too complex, we show how to simplify data mining results. When data is too scarce to support intricate models, we show methods for generating predictions. When the world changes, and old models need to be updated, we show how to handle those updates. When the effect is too complex for one model, we show how to reason across ensembles of models. Pre-requisites: This tutorial makes minimal use of maths of advanced algorithms and would be understandable by developers and technical managers.},
	booktitle = {2013 35th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Menzies, Tim and Kocaguneli, Ekrem and Peters, Fayola and Turhan, Burak and Minku, Leandro L.},
	month = may,
	year = {2013},
	note = {ISSN: 1558-1225},
	keywords = {Predictive models, Software, Tutorials, Data models, Educational institutions, Data mining, Software engineering},
	pages = {1484--1486},
	file = {IEEE Xplore Abstract Record:/Users/rca2t1/Dropbox/Zotero/storage/3RMVM2HI/6606752.html:text/html;IEEE Xplore Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/GWV3H7YX/Menzies et al. - 2013 - Data science for software engineering.pdf:application/pdf},
}

@misc{grometstein_mit_2018,
	title = {{MIT} {Lincoln} {Laboratory}: {Technology} in {Support} of {National} {Security}},
	language = {en},
	author = {Grometstein, Alan},
	year = {2018},
	file = {Grometstein - MIT Lincoln Laboratory Technology in Support of N.pdf:/Users/rca2t1/Dropbox/Zotero/storage/9WI53UUJ/Grometstein - MIT Lincoln Laboratory Technology in Support of N.pdf:application/pdf},
}

@book{green_bright_2010,
	title = {Bright {Boys}: {The} {Making} of {Information} {Technology}},
	isbn = {978-1-4398-6522-4},
	shorttitle = {Bright {Boys}},
	abstract = {Everything has a beginning. None was more profound-and quite as unexpected-than Information Technology. Here for the first time is the untold story of how our new age came to be and the bright boys who made it happen. What began on the bare floor of an old laundry building eventually grew to rival in size the Manhattan Project. The unexpected},
	language = {en},
	publisher = {CRC Press},
	author = {Green, Tom},
	month = mar,
	year = {2010},
	note = {Google-Books-ID: uEzNBQAAQBAJ},
	keywords = {Mathematics / General, Mathematics / Recreations \& Games},
	annote = {The Air Defense Engineering Committee (ADSEC) cranked up for  business on January 20, 1950, six weeks before Valley’s big day at the  Barta Building, and a full five months before that watershed moment in  preparedness, the outbreak of the Korean War. It was a Friday; ADSEC  would continue meeting on Fridays for the next two years. Very quickly,  the ADSEC acronym was dropped in favor of the Valley Committee: it was  easier to say and more direct, so it stuck. Besides, the looming figure of  George Valley was associated with every aspect of the air defense group  and made his name a natural and convenient reference. Much like the wartime Sunday Soviets at the Grosvenor Hotel, these Friday Soviets similarly  consisted of civilian scientists, engineers, and the military informally yet  formally mingling together all bent on the very same challenge: air defense.  Accommodations were far less posh: the Valley Committee met in a rather  spartan room at the AFCRL on Albany Street. But it was a handy place to  get to for all involved and, better still, was located at the spiritual center of  the newly emergent digital electronics. As a practical matter, the ADSEC  site was also selected so as to be near a large city, “so the final product  could be used to defend that city as well as to serve as a model for the other  installations.”43 
Green, Tom. Bright Boys (p. 185). CRC Press. Kindle Edition. 
},
}

@article{burkett_burkett_2003,
	title = {Burkett {Announces} {His} {Retirement} as {Director} of {Museum}},
	volume = {3},
	language = {en},
	number = {3},
	journal = {A Newsletter for the White Sands Missile Range Historical Foundation},
	author = {Burkett, Ron},
	year = {2003},
	pages = {5},
	annote = {The Data Sciences Division had responsibility for both real-time and post-test data acquisition and processing at White Sands. The real-time responsibility included the critical data (radar, telemetry, optics, etc.) acquisition, development of real-time algorithms, data processing, and display support for missile flight safety officers and project engineers - a Range Control Center operation.
},
	file = {Burkett - 2003 - Burkett Announces His Retirement as Director of Mu.pdf:/Users/rca2t1/Dropbox/Zotero/storage/539UUR3N/Burkett - 2003 - Burkett Announces His Retirement as Director of Mu.pdf:application/pdf},
}

@article{noauthor_hands_2005,
	title = {Hands {Across} {History}},
	language = {en},
	year = {2005},
	pages = {4},
	annote = {Has contact info for Jim Eckles who may be of help.
},
	file = {Hands Across History.pdf:/Users/rca2t1/Dropbox/Zotero/storage/4Z6EB46Z/Hands Across History.pdf:application/pdf},
}

@misc{noauthor_white_nodate-1,
	title = {White {Sands} {Missile} {Range}- 60 {Years} of {Making} {History} {Every} {Day}, 2005 {\textbar} {ArchivesSpace} {Public} {Interface}},
	url = {https://usu.libraryhost.com/repositories/2/archival_objects/69907},
	urldate = {2022-06-16},
	file = {White Sands Missile Range- 60 Years of Making History Every Day, 2005 | ArchivesSpace Public Interface:/Users/rca2t1/Dropbox/Zotero/storage/QBF4X4BY/69907.html:text/html},
}

@article{office_of_naval_research_mathematical_sciences_division_computing_1959,
	title = {Computing {Centers}},
	volume = {11},
	abstract = {COMPUTER AND MATHEMATICAL SCIENCES LABORATORY - AIR IFORCE CAMBRIDGE RESEARCH CENTER - L. G. HANSCOM FIELD, BEDFORD, MASSACHUSETTS

A detailed evaluation of radar detection and position location schemes is being carried out on the AFCRC Magnetic Computer (see Digital Computer Newsletter, January 1959). A library of target blip samples characterized by stochastic signals imbedded in noise has been generated on the computer for this purpose.

The simulation technique employed is particularly useful in assessing not only the validity of the end results obtained from the theoretical model, such as detection efficiencies, false alarm rates, and position accuracies, as functions of the data processor and target parameters, but also the validity of intermediate assumptions on the nature of the various probability
distributions and how they are transformed.

The approach makes use of analog simulation techniques for data generation and digital simulation on a general purpose computer of the data processing schemes.},
	language = {en},
	number = {3},
	journal = {Digital Computer Newsletter},
	author = {{Office of Naval Research, Mathematical Sciences Division}},
	month = jul,
	year = {1959},
	pages = {2},
	file = {AD0694658.pdf:/Users/rca2t1/Dropbox/Zotero/storage/XDFZXVS4/AD0694658.pdf:application/pdf},
}

@book{national_science_foundation_scientific_1962,
	title = {Scientific {Information} {Activities} of {Federal} {Agencies}},
	language = {en},
	number = {15},
	author = {{National Science Foundation}},
	year = {1962},
	note = {Google-Books-ID: opQbAAAAMAAJ},
	file = {National Science Foundation - 1962 - Scientific Information Activities of Federal Agenc.pdf:/Users/rca2t1/Dropbox/Zotero/storage/NISPZNBL/National Science Foundation - 1962 - Scientific Information Activities of Federal Agenc.pdf:application/pdf},
}

@techreport{bastian_phrase-structure_1962,
	title = {A {Phrase}-{Structure} {Language} {Translator}},
	url = {https://apps.dtic.mil/sti/citations/AD0293843},
	abstract = {A syntax-directed translator is described with several new features which result in much faster running time and the ability to handle longer input strings. The computer pro ram for the translator is describe in detail, and an example of its operation i provided.},
	language = {en},
	urldate = {2022-07-27},
	institution = {AIR FORCE CAMBRIDGE RESEARCH LABS HANSCOM AFB MA},
	author = {Bastian, Jr},
	month = aug,
	year = {1962},
	note = {Section: Technical Reports},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/9SMDASVI/Bastian - 1962 - A PHRASE-STRUCTURE LANGUAGE TRANSLATOR.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/TCWWR24R/AD0293843.html:text/html},
}

@techreport{sherry_syntactic_1960,
	title = {Syntactic {Analysis} in {Automatic} {Translation}},
	url = {https://apps.dtic.mil/sti/citations/AD0253273},
	abstract = {A method for the syntactic analysis of Russian sentences, applied to automatic translation, is divided into a morphological word-by-word phase and a syntactical sentence-by-sentence phase. An idealized canonical stem dictionary is presented, and its significant lexicographic properties are pointed out. This idealized dictionary then serves AS A BASIS FOR EVALUATING THE ACTUAL Harvard Automatic Dictionary. Aspects of morphological analysis of the Russian language and a series of programs written to carry it out are described. To explain the practical problems encountered in an experimental syntactic analysis program, of which a detailed description is given, a new model of natural language is introduced.},
	language = {en},
	urldate = {2022-07-27},
	institution = {HARVARD COLL CAMBRIDGE MA MUSEUM OF COMPARATIVE ZOOLOGY},
	author = {Sherry, Murray E.},
	month = aug,
	year = {1960},
	note = {Section: Technical Reports},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/RFXNJRT8/Sherry - 1960 - SYNTACTIC ANALYSIS IN AUTOMATIC TRANSLATION.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/ZU2FI4D9/AD0253273.html:text/html},
}

@book{resnik_formalization_1961,
	title = {The {Formalization} of the {Foundations} of {Geometry} {Within} the {System} of {Symbolic} {Logic}},
	language = {en},
	publisher = {Electronics Research Directorate, Air Force Cambridge Research Laboratories, Office of Aerospace Research, U. S. Air Force},
	author = {Resnik, Michael D.},
	year = {1961},
	note = {Google-Books-ID: IaxFAAAAYAAJ},
	file = {Resnik - 1961 - The Formalization of the Foundations of Geometry W.pdf:/Users/rca2t1/Dropbox/Zotero/storage/2M9JGDUQ/Resnik - 1961 - The Formalization of the Foundations of Geometry W.pdf:application/pdf},
}

@misc{prange_use_1959,
	title = {The {Use} of {Coset} {Equivalence} in the {Analysis} and {Decoding} of {Group} {Codes}},
	url = {https://apps.dtic.mil/sti/pdfs/AD0226767.pdf},
	urldate = {2022-07-27},
	publisher = {Defense Documentation Center for Scientific and Technical Information},
	author = {Prange, Eugene},
	month = jun,
	year = {1959},
	note = {AD-226 767},
	annote = {Product of the AFCRL, Electronic Research Directorate, Communication Sciences Lab.

},
	file = {Prange - 1959 - The Use of Coset Equivalence in the Analysis and D.pdf:/Users/rca2t1/Dropbox/Zotero/storage/9L25PYP8/Prange - 1959 - The Use of Coset Equivalence in the Analysis and D.pdf:application/pdf},
}

@article{king_project_2010,
	title = {Project {SAGE}, a {Half}-{Century} {On}},
	volume = {17},
	issn = {1072-5520, 1558-3449},
	url = {https://dl.acm.org/doi/10.1145/1836216.1836230},
	doi = {10.1145/1836216.1836230},
	abstract = {John Leslie King's interest in history was evident at the first CSCW conference in 1986. His review of 15 years of research with technology to support real-time collocated interaction, then called Group Decision Support Systems, revealed that we sometimes learn more slowly from experience than we could. In this article, he describes the little-known system that pioneered real-time human-computer interaction in the 1950s, created the computing profession, and trained hundreds of its earliest practitioners.---Jonathan Grudin},
	language = {en},
	number = {5},
	urldate = {2022-08-03},
	journal = {Interactions},
	author = {King, John Leslie},
	month = sep,
	year = {2010},
	pages = {53--55},
	annote = {The Committee determined that the weakest link in the nation's air defenses was the radars that were supposed to detect low-flying aircraft. Each radar's range was limited by its horizon. By flying at low altitude, aircraft could hide from the widely spaced GCI radars. Since air-based or space-based surveillance was not an option in 1950, the only solution was to install ground-based radar systems close together.
In 1950, this solution was ambitious. But fortunately for the future Lincoln Laboratory, the Committee continued to evaluate the problem and reduced it to two major issues.  First, in order to interpret the signals from a large number of radars, there had to be a way to transmit the radar data to a central computer at which the data could be aggregated. Second, since the objective was to detect and intercept the hostile aircraft, the computer had to analyze the data in real time.
},
}

@misc{mitre_semi-automatic_2001,
	title = {Semi-{Automatic} {Ground} {Environment} ({SAGE})},
	url = {https://web.archive.org/web/20110716081954/http://www.mitre.org/about/sage.html},
	urldate = {2022-08-04},
	journal = {MITRE History},
	author = {{MITRE}},
	month = jan,
	year = {2001},
	annote = {Semi-Automatic Ground Environment (SAGE)
Beginnings
In the 1950's MITRE's founders played a key role in the development of the Semi-Automatic Ground Environment (SAGE) system, the first major real-time, computer-based command and control system. Designed as a new air defense system to protect the United States from long-range bombers and other weapons, the SAGE system sent information from geographically dispersed radars over telephone lines and gathered it at a central location for processing by a newly designed, large-scale digital computer. As the system evolved, SAGE broke new ground in radar, communications, computer, information display, and computer programming technologies.
Developing a system of SAGE's size required a novel organization that could examine all facets of the problem without regard to the traditional boundaries between the military, industry and academia. In 1958, in response to this need, The MITRE Corporation was formed out of the Computer System Division of the Massachusetts Institute of Technology (MIT) Lincoln Laboratories. Much of MITRE's initial work focused on the software development of SAGE's digital computer system, radar surveillance, communications, and weapons integration. More importantly however, MITRE had the role of integrating many elements of the SAGE system—this experience established MITRE as a leader in the new discipline of systems engineering.









SAGE correlated target information from search, height finder and gap-filler radars. Texas Towers similar to off-shore oil rigs, extended the system's radar horizon even farther out to sea.




The SAGE system was fully deployed in 1963; the 24 SAGE Direction Centers and three SAGE Combat Centers were spread throughout the U.S. Each was linked by long-distance telephone lines to more than 100 interoperating air defense elements, requiring system integration on a scale previously unimagined. At the heart of each center was a new large-scale digital computer that had evolved from MIT's experimental Whirlwind computer of the 1950's. The largest real-time computer program of that time, it automated information flow, processed and presented data to 100 operator stations, and provided control information to the weapons systems. This processed information, including aircraft tracks and identification, was presented to operators on a cathode ray tube—one of the first uses of this device to display computer-generated data.
In spite of this complexity, remarkable for its time, SAGE exceeded virtually all the original stringent requirements, and was continuously in operation for more than 25 years. The system engineering expertise MITRE developed in the SAGE program laid the groundwork for modern command and control systems and led to a long-term collaborative partnership between the Air Force and MITRE. In addition, MITRE's SAGE work was directly applicable to another important mission—air traffic control. Through our partnership with the FAA, MITRE continues to contribute to the development of a safe, efficient and collaborative worldwide air traffic management system.
SAGE: The System in Action





An early warning radar searches for approaching aircraft.


The radar detects an enemy bomber approaching North America.


Telephone lines carry information from the radar to the SAGE Direction Center.


The SAGE Direction Center processes the information.


The Direction Center notifies interceptors of the target.


The Direction Center notifies higher headquarters.


The radar updates the position and course of the intruding aircraft.


The Direction Center notifies the appropriate surface-to-air missile batteries.


The Direction Center receives information from adjoining centers.


The Direction Center vectors interceptors to target.


The Direction Center receives status reports and other information.


The Direction Center provides final guidance to interceptors.


Interceptors destroy intruding enemy bombers.


The Direction Center receives raid assessment from interceptors.


The Direction Center apprises headquarters of status and results.


SAGE System maintains alert for additional hostile aircraft.











SAGE pioneers John F. Jacobs (left) and Robert R. Everett




SAGE: The People Behind It

"I was struck at the time and have been struck since by how much a group of really smart, dedicated people with adequate resources can do toward solving problems. You put them to work on a program, and if you don't box them with too many restrictions, you get a solution."

Robert R. EverettFormer President and Chief Executive OfficerThe MITRE Corporation

"One of the outstanding things... was the esprit de corps—the spirit that pervaded the operation. Everyone had a sense of purpose—a sense of doing something important. People felt the pressure and had the desire to solve the air defense problem, although there was often disagreement as to how to achieve that end. Energy was directed more toward solving individual problems, such as making a workable high-speed memory or a useable data link, than it was toward solving the problem of the value of the finished product. It was an engineer's dream."

John F. JacobsFormer Senior Vice PresidentThe MITRE Corporation









SAGE demonstrated pioneering solutions to the problem of the user interface. The System displayed extremely large amounts of information to its operators using the then-new cathode ray tube; operators could then obtain additional information on aircraft tracks by selecting them with a light gun. Similar techniques are still in use today.




SAGE: Im(Adams, 2010)pact on the Computers of Today
SAGE had a fundamental impact on the development of computers and the computer industry. When the program began, work on the first digital computer, MIT's Whirlwind, was in progress. Key to the success of SAGE was the development of a production version of MIT's prototype Whirlwind computer. A little known company called IBM won the contract to design and build the Whirlwind II, otherwise known as AN/FSQ-7, for the proposed new air defense system. When complete, the AN/FSQ-7 weighed 250 tons, and required a 3,000kW power supply and over 49,000 vacuum tubes. When SAGE became fully operational, it relied on 24 AN/FSQ-7s; they remained in service until the Air Force ended the SAGE program in 1983.
Looking back at the development of the computers supporting the SAGE, the origins of many key computer innovations are readily apparent. SAGE's use of telephone lines to communicate from computer to computer and computer to radar laid the groundwork for modern-day modems. Former MITRE President Bob Everett's invention of the light gun is often referred to as one of the precursor's to today's computer mouse. Whirlwind's control program, the largest real-time computer program written at that time, spawned a new profession, software development engineers and programmers.
Many other computer breakthroughs such as magnetic-core storage, modular design, interactive graphic displays, on-line common databases, and continuous and reliable operation can also be traced to the development of Whirlwind. In addition, software innovations like the ability to accommodate multiple, simultaneous users, the use of advanced data system structures, structured program modules, and global data definitions grew out of SAGE's development.
Clearly, these early advances in computers, software and networking that evolved from the SAGE system had a powerful impact on today's computers and the computer industry as a whole.
 Page last updated: January 25, 2005  
},
	file = {MITRE - 2001 - Semi-Automatic Ground Environment (SAGE).pdf:/Users/rca2t1/Dropbox/Zotero/storage/NJTX9F9Y/MITRE - 2001 - Semi-Automatic Ground Environment (SAGE).pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/VHQVWNAC/sage.html:text/html},
}

@article{heumann_data_1956,
	title = {Data {Processing} for {Scientists}},
	volume = {124},
	issn = {0036-8075},
	url = {https://www.jstor.org/stable/1751044},
	number = {3226},
	urldate = {2022-09-09},
	journal = {Science},
	author = {Heumann, Karl F.},
	year = {1956},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {773--777},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/M2B5BAHM/Heumann - 1956 - Data Processing for Scientists.pdf:application/pdf},
}

@misc{nsf_mansfield_2003,
	title = {The {Mansfield} {Amendment}},
	url = {https://web.archive.org/web/20030321112517/https://www.nsf.gov/nsb/documents/2000/nsb00215/nsb50/1970/mansfield.html},
	urldate = {2022-09-10},
	journal = {NSF: NSB 50th Anniversary},
	author = {{NSF}},
	month = oct,
	year = {2003},
	note = {Date inferred through Wayback Machine.},
	file = {NSF\: NSB 50th Anniversary:/Users/rca2t1/Dropbox/Zotero/storage/TAG9S3HZ/mansfield.html:text/html},
}

@book{russell_mining_2011,
	title = {Mining the {Social} {Web}: {Analyzing} {Data} from {Facebook}, {Twitter}, {LinkedIn}, and {Other} {Social} {Media} {Sites}},
	isbn = {978-1-4493-8834-8},
	shorttitle = {Mining the {Social} {Web}},
	abstract = {Facebook, Twitter, and LinkedIn generate a tremendous amount of valuable social data, but how can you find out who's making connections with social media, what they’re talking about, or where they’re located? This concise and practical book shows you how to answer these questions and more. You'll learn how to combine social web data, analysis techniques, and visualization to help you find what you've been looking for in the social haystack, as well as useful information you didn't know existed. Each standalone chapter introduces techniques for mining data in different areas of the social Web, including blogs and email. All you need to get started is a programming background and a willingness to learn basic Python tools. Get a straightforward synopsis of the social web landscape Use adaptable scripts on GitHub to harvest data from social network APIs such as Twitter, Facebook, and LinkedIn Learn how to employ easy-to-use Python tools to slice and dice the data you collect Explore social connections in microformats with the XHTML Friends Network Apply advanced mining techniques such as TF-IDF, cosine similarity, collocation analysis, document summarization, and clique detection Build interactive visualizations with web technologies based upon HTML5 and JavaScript toolkits "Let Matthew Russell serve as your guide to working with social data sets old (email, blogs) and new (Twitter, LinkedIn, Facebook). Mining the Social Web is a natural successor to Programming Collective Intelligence: a practical, hands-on approach to hacking on data from the social Web with Python."  --Jeff Hammerbacher, Chief Scientist, Cloudera  "A rich, compact, useful, practical introduction to a galaxy of tools, techniques, and theories for exploring structured and unstructured data."  --Alex Martelli, Senior Staff Engineer, Google},
	language = {en},
	publisher = {"O'Reilly Media, Inc."},
	author = {Russell, Matthew},
	month = jan,
	year = {2011},
	note = {Google-Books-ID: SYM1lrQdrdsC},
	keywords = {Computers / Software Development \& Engineering / General, Computers / Programming / General, Computers / Data Science / Data Analytics, Computers / Internet / Social Media, Computers / Internet / Web Programming},
}

@techreport{bishop_jimmy_2015,
	address = {Fort Belvoir, VA},
	title = {Jimmy {Doolittle}: {The} {Commander} behind the {Legend}:},
	shorttitle = {Jimmy {Doolittle}},
	url = {http://www.dtic.mil/docs/citations/ADA618925},
	language = {en},
	urldate = {2022-09-11},
	institution = {Defense Technical Information Center},
	author = {Bishop, Benjamin W.},
	month = feb,
	year = {2015},
	doi = {10.21236/ADA618925},
	file = {Bishop - 2015 - Jimmy Doolittle The Commander behind the Legend.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RGV36MC9/Bishop - 2015 - Jimmy Doolittle The Commander behind the Legend.pdf:application/pdf},
}

@misc{noauthor_hidden_nodate,
	title = {Hidden {Figures} and {Human} {Computers}},
	url = {https://airandspace.si.edu/stories/editorial/hidden-figures-and-human-computers},
	abstract = {The breakout movie Hidden Figures tells the story of three African American women who worked as mathematicians at NASA. The story sheds light on the significant contributions of the three women—Katherine Johnson, Dorothy Vaughan, and Mary Jackson—but also the broader impact that women had behind the scenes at NASA.

Johnson, Vaughan, and Jackson all began their careers at the National Advisory Committee for Aeronautics (NACA)—which later became NASA—working as “computers.” Computers were not what we think of them today. They were people, primarily women, who reduced or analyzed data using mechanical calculators—we’ve previously explored the role of computers in astronomy.},
	language = {en},
	urldate = {2022-09-11},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/9TBR5MLH/hidden-figures-and-human-computers.html:text/html},
}

@techreport{glennan_first_1959,
	title = {First {Semiannual} {Report} of the {National} {Aeronautics} and {Space} {Administration}},
	url = {https://ntrs.nasa.gov/citations/20150018535},
	abstract = {The First Semiannual Report of the National Aeronautics and Space Administration (NASA) is submitted to Congress pursuant to section 206 (a) of the National Aeronautics and Space Act of 1958 (Public Law 85-568) to provide for research into problems of flight within and outside the Earth's atmosphere, which states: The Administration shall submit to the President for transmittal to Congress, semiannually and at such other times as it deems desirable, a report on its activities and accomplishments.},
	urldate = {2022-09-11},
	author = {Glennan, T. Keith},
	month = jun,
	year = {1959},
	note = {NTRS Author Affiliations: NASA Headquarters
NTRS Document ID: 20150018535
NTRS Research Center: Headquarters (HQ)},
	keywords = {Administration and Management, Law, Political Science and Space Policy},
	file = {20150018535.pdf:/Users/rca2t1/Dropbox/Zotero/storage/RDMZD5Z7/Glennan - 1959 - First Semiannual Report of the National Aeronautic.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/BYTJAF4U/20150018535.html:text/html},
}

@book{ehrenberg_primer_1982,
	title = {A {Primer} in {Data} {Reduction}: {An} {Introductory} {Statistics} {Textbook}},
	isbn = {978-0-471-10134-5},
	shorttitle = {A {Primer} in {Data} {Reduction}},
	abstract = {A concise, easy to understand introduction that emphasizes the relevance of statistics to real world problems. Describes traditional statistical methods, their uses and limitations, and explains how to reduce numerical data to statistical summaries, how to interpret the results, and how to present the data clearly. Minimizes mathematics without oversimplification and illustrates theories with practical, varied examples. Statistical tables and answers to the exercises are included.},
	language = {en},
	publisher = {Wiley},
	author = {Ehrenberg, A. S. C.},
	year = {1982},
	note = {Google-Books-ID: DchwQgAACAAJ},
}

@misc{noauthor_google_nodate,
	title = {Google {Books} {Ngram} {Viewer}: data reduction},
	url = {https://books.google.com/ngrams/graph?content=data+reduction&year_start=1800&year_end=2019&corpus=en-2019&smoothing=3},
	abstract = {Google Books Ngram Viewer},
	language = {en},
	urldate = {2022-09-11},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/S2W4DML3/graph.html:text/html},
}

@book{walton_data_1970,
	title = {The {Data} {Reduction} {Laboratory}: {An} {Aid} to the {Space} {Scientist}},
	shorttitle = {The {Data} {Reduction} {Laboratory}},
	abstract = {Data reduction facility for rapid analysis of space flight telemetry data.},
	language = {en},
	publisher = {National Aeronautics and Space Administration},
	author = {Walton, Barbara A. and Keipert, Frank A. and Quann, John J.},
	year = {1970},
	note = {Google-Books-ID: QG8JEbkt49UC},
	file = {Walton et al. - 1970 - The Data Reduction Laboratory An Aid to the Space.pdf:/Users/rca2t1/Dropbox/Zotero/storage/23DN9T5X/Walton et al. - 1970 - The Data Reduction Laboratory An Aid to the Space.pdf:application/pdf},
}

@book{johnson_data_1961,
	title = {Data {Reduction} {Instrumentation} for {Radio} {Propagation} {Research}},
	language = {en},
	publisher = {U.S. Department of Commerce, Office of Technical Services},
	author = {Johnson, Walter E.},
	year = {1961},
	note = {Google-Books-ID: ga4F03lpmv8C},
}

@article{mottley_application_1954,
	title = {The {Application} of {Operations}-{Research} {Methods} to {Athletic} {Games}},
	volume = {2},
	issn = {0096-3984},
	url = {https://www.jstor.org/stable/166647},
	number = {3},
	urldate = {2022-09-11},
	journal = {Journal of the Operations Research Society of America},
	author = {Mottley, Charles M.},
	year = {1954},
	note = {Publisher: INFORMS},
	pages = {335--338},
	file = {Mottley - 1954 - The Application of Operations-Research Methods to .pdf:/Users/rca2t1/Dropbox/Zotero/storage/BIK3IR9J/Mottley - 1954 - The Application of Operations-Research Methods to .pdf:application/pdf},
}

@article{chapanis_psychology_1953,
	title = {Psychology and the {Instrument} {Panel}},
	volume = {188},
	issn = {0036-8733},
	url = {https://www.jstor.org/stable/24944192},
	number = {4},
	urldate = {2022-09-11},
	journal = {Scientific American},
	author = {Chapanis, Alphonse},
	year = {1953},
	note = {Publisher: Scientific American, a division of Nature America, Inc.},
	pages = {74--84},
	file = {Chapanis - 1953 - Psychology and the Instrument Panel.pdf:/Users/rca2t1/Dropbox/Zotero/storage/9Q987EVY/Chapanis - 1953 - Psychology and the Instrument Panel.pdf:application/pdf},
}

@article{lowe_automatic_1951,
	title = {Automatic {Computation} as an {Aid} in {Aeronautical} {Engineering}},
	volume = {25},
	issn = {0025-570X},
	url = {https://www.jstor.org/stable/3029572},
	doi = {10.2307/3029572},
	number = {1},
	urldate = {2022-09-11},
	journal = {Mathematics Magazine},
	author = {Lowe, John},
	year = {1951},
	note = {Publisher: Mathematical Association of America},
	pages = {37--42},
	annote = {“If data in graphical form are to be introduced into a computation, these data must be translated to numerical form, perhaps by some curve fitting method.” (Lowe, 1951, p. 4)
},
	file = {Lowe - 1951 - Automatic Computation as an Aid in Aeronautical En.pdf:/Users/rca2t1/Dropbox/Zotero/storage/HXLQ322M/Lowe - 1951 - Automatic Computation as an Aid in Aeronautical En.pdf:application/pdf},
}

@article{reuyl_stalking_1951,
	title = {Stalking the {Guided} {Missile}: {New} {Instruments} {Track} and {Report} the {Performance} of {Long}-{Range} {Rockets}},
	volume = {36},
	issn = {0030-4557},
	shorttitle = {Stalking the {Guided} {Missile}},
	url = {https://www.jstor.org/stable/45359885},
	number = {188},
	urldate = {2022-09-11},
	journal = {Ordnance},
	author = {Reuyl, Dirk and de Bey, L. G.},
	year = {1951},
	note = {Publisher: National Defense Industrial Association},
	pages = {237--241},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/UKWB74V9/Reuyl and de Bey - 1951 - Stalking the Guided Missile New Instruments Track.pdf:application/pdf},
}

@article{ehrenberg_appraisal_1965,
	title = {An {Appraisal} of {Markov} {Brand}-{Switching} {Models}},
	volume = {2},
	issn = {0022-2437},
	url = {https://doi.org/10.1177/002224376500200402},
	doi = {10.1177/002224376500200402},
	abstract = {Using no mathematics other than a simple arithmetical example, this article reviews fundamental difficulties in applying Markov theory to brand-switching data. No successful practical applications of the theory appear to be available.},
	language = {en},
	number = {4},
	urldate = {2022-09-11},
	journal = {Journal of Marketing Research},
	author = {Ehrenberg, A. S. C.},
	month = nov,
	year = {1965},
	note = {Publisher: SAGE Publications Inc},
	pages = {347--362},
	file = {Ehrenberg - 1965 - An Appraisal of Markov Brand-Switching Models.pdf:/Users/rca2t1/Dropbox/Zotero/storage/R9YDEBB5/Ehrenberg - 1965 - An Appraisal of Markov Brand-Switching Models.pdf:application/pdf},
}

@article{goodhardt_dirichlet_1984,
	title = {The {Dirichlet}: {A} {Comprehensive} {Model} of {Buying} {Behaviour}},
	volume = {147},
	issn = {0035-9238},
	shorttitle = {The {Dirichlet}},
	url = {https://www.jstor.org/stable/2981696},
	doi = {10.2307/2981696},
	abstract = {The Dirichlet is a stochastic model of purchase incidence and brand choice which parsimoniously integrates a wide range of already well-established empirical regularities.},
	number = {5},
	urldate = {2022-09-11},
	journal = {Journal of the Royal Statistical Society. Series A (General)},
	author = {Goodhardt, G. J. and Ehrenberg, A. S. C. and Chatfield, C.},
	year = {1984},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {621--655},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/KEHNGQ3U/Goodhardt et al. - 1984 - The Dirichlet A Comprehensive Model of Buying Beh.pdf:application/pdf},
}

@book{appropriations_department_1959,
	title = {Department of {Defense} {Appropriations}},
	language = {en},
	publisher = {U.S. Government Printing Office},
	author = {Appropriations, United States Congress Senate Committee on},
	year = {1959},
	note = {Google-Books-ID: TGwhAAAAMAAJ},
	annote = {Discusses data reduction in context of missile tracking, etc. E.g. pg. 1399.
Also references to Lincoln Lab.
},
}

@article{ladd_non-real-time_1959,
	title = {A {Non}-{Real}-{Time} {Simulation} of {SAGE} {Tracking} and {BOMARC} {Guidance}},
	volume = {EC-8},
	issn = {0367-9950},
	doi = {10.1109/TEC.1959.5222759},
	abstract = {The addition of facilities to the SAGE system for control of a new defensive weapon, such as the BOMARC missile, requires extensive modifications to the SAGE computer program. To obtain a better understanding of BOMARC control problems, a program has been written for the IBM Type 704 computer to simulate the proposed employment of BOMARC in the SAGE system. Such a simulation is flexible enough to optimize and evaluate a large range of parameters. On three separate passes through the 704 (with tape storage of intermediate results) the program simulates radar, target, and missile performance, as well as SAGE tracking and missile guidance. A fourth program presents the desired output data in the form of frequency distributions and detailed results pertaining to selected target or missile tracks.},
	number = {1},
	journal = {IRE Transactions on Electronic Computers},
	author = {Ladd, D. W. and Wolf, E. W.},
	month = mar,
	year = {1959},
	note = {Conference Name: IRE Transactions on Electronic Computers},
	keywords = {Computational modeling, Computer simulation, Frequency, Employment, Missiles, Packaging, Radar tracking, System testing, Target tracking, Weapons},
	pages = {36--41},
	file = {IEEE Xplore Abstract Record:/Users/rca2t1/Dropbox/Zotero/storage/VQHR6QGD/5222759.html:text/html;IEEE Xplore Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/EC5AR9X4/Ladd and Wolf - 1959 - A Non-Real-Time Simulation of SAGE Tracking and BO.pdf:application/pdf},
}

@book{office_forecast_1976,
	title = {A {Forecast} of {Space} {Technology}, 1980-2000},
	language = {en},
	publisher = {U.S. National Aeronautics and Space Administration, Scientific and Technical Information Office},
	author = {Office, United States National Aeronautics {and} Space Administration Scientific {and} Technical Information},
	year = {1976},
	note = {Google-Books-ID: cmexTKefXQAC},
}

@book{noauthor_scientific_1968,
	title = {Scientific and {Technical} {Aerospace} {Reports}},
	language = {en},
	publisher = {Scientific and Technical Information Branch, National Aeronautics and Space Administration},
	year = {1968},
	note = {Google-Books-ID: I4ZrQg86C7kC},
	annote = {Human Machine Communication
},
}

@book{affairs_hearings_1969,
	title = {Hearings},
	language = {en},
	author = {Affairs, United States Congress House Committee on Foreign},
	year = {1969},
	note = {Google-Books-ID: tRIaAQAAMAAJ},
	annote = {data deluge and pattern recognition 
},
}

@misc{noauthor_cpsc_nodate,
	title = {{CPSC} 437/537: {Database} {Systems} ({Fall} 2022)},
	url = {https://zoo.cs.yale.edu/classes/cs437/index.html},
	urldate = {2022-09-13},
	file = {CPSC 437/537\: Database Systems (Fall 2022):/Users/rca2t1/Dropbox/Zotero/storage/U49U4ZK6/index.html:text/html},
}

@article{dodge_flying_2004,
	title = {Flying {Through} {Code}/{Space}: {The} {Real} {Virtuality} of {Air} {Travel}},
	volume = {36},
	shorttitle = {Flying {Through} {Code}/{Space}},
	doi = {10.1068/a3698},
	abstract = {Commercial air travel is a key global industry facilitating the complex daily movements of planes, people, goods, and services across the world. In this paper we analyse contemporary air travel through the conceptualisation of a culture of real virtuality. We contend that air travel now consists of passage through 'code/space'. Such code/space includes travel websites, check-in, security checkpoints, flight decks, air-traffic control, immigration, and customs checkpoints, which together form assemblages that define the practices and experiences of air travel. Code/space is qualitatively different to coded space, in which software influences the production of space, in that code and space are mutually constituted -- produced through one another. This mutual constitution is dyadic so that if either the code or space 'fail', the production of space 'fails'. Our formulation of code/space is nondeterministic and nonuniversal, and how code/space operates and is experienced is embodied through the performances and interactions of the people within the space (between people, and between people and code). In this sense, code/space is constantly in a state of becoming. We illustrate the nature of code/space, and the discursive regimes that support its production, and demonstrate how the code/spaces of an air travel are simultaneously local and global and induce Castells' notions of 'space of flows' and 'timeless time'.},
	journal = {Environment and Planning A},
	author = {Dodge, Martin and Kitchin, Rob},
	month = feb,
	year = {2004},
	pages = {195--211},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/PR34CNMZ/Dodge and Kitchin - 2004 - Flying Through CodeSpace The Real Virtuality of .pdf:application/pdf},
}

@misc{noauthor_introduction_1965,
	title = {Introduction to {AN}/{FSQ}-7 {Combat} {Direction} {Central} and {AN}/{FSQ}-8 {Combat} {Control} {Central}},
	url = {http://ed-thelen.org/SageIntro.html#3.2.2},
	urldate = {2022-09-13},
	year = {1965},
	note = {1 January 1959 - 15 March 1965},
	file = {ed-thelen.org/SageIntro.html#3.2.2:/Users/rca2t1/Dropbox/Zotero/storage/8HEAQPHN/SageIntro.html:text/html},
}

@book{winkler_searching_1997,
	title = {Searching the {Skies}: {The} {Legacy} of the {United} {States} {Cold} {War} {Defense} {Radar} {Program}},
	isbn = {978-1-907521-91-1},
	shorttitle = {Searching the {Skies}},
	abstract = {Originally published in 1997, this hitherto hard-to-find study examines the impact that construction of radar stations and command facilities had on the American landscape. With accompanying black and white photographs throughout, the author explores patterns, themes, and trends that created, influenced, and formed the backdrop to the Cold War defense radar program. This study provides an in-depth look at the radar systems, a state by state listing of the infrastructure that supported the systems, and an extensive bibliography. This historic content can be used to understand and evaluate properties associated with America's detection and command and control system.},
	language = {en},
	publisher = {Headquarters Air Combat Command},
	author = {Winkler, David Frank and Command, Air Com Headquarters Air Combat and Force, United States Air},
	year = {1997},
	note = {Google-Books-ID: iXrfAAAAMAAJ},
}

@book{defense_technical_information_center_dtic_1997,
	title = {{DTIC} {ADA331231}: {Searching} the {Skies}: the {Legacy} of the {United} {States} {Cold} {War} {Defense} {Radar} {Program}},
	shorttitle = {{DTIC} {ADA331231}},
	url = {http://archive.org/details/DTIC_ADA331231},
	abstract = {The Department of Defense (DOD) Legacy Resource Management Program was established under the Defense Appropriations Act of 1991 to determine how to better integrate the conservation of irreplaceable biological, cultural, and geophysical resources with the dynamic requirements of military missions. One task area of the Legacy Program focused on property associated with the Cold War. This study examines the impact that construction of radar stations and command facilities had on the American landscape. The author explores patterns, themes, and trends that created, influenced, and formed the backdrop to the Cold War defense radar program. The study provides an in-depth look at the radar systems, a state by state listing of the infrastructure that supported the systems, and an extensive bibliography. This historic content can be used to understand and evaluate properties associated with America's detection and command and control system.},
	language = {english},
	urldate = {2022-09-13},
	author = {{Defense Technical Information Center}},
	month = jun,
	year = {1997},
	keywords = {DTIC Archive, *AIR DEFENSE, *EARLY WARNING SYSTEMS, *SEARCH RADAR, AIRCRAFT INTERCEPT CONTROL SYSTEMS, BALLISTIC MISSILE INTERCEPT SYSTEMS, COLD WAR, COMBAT SURVEILLANCE, COMMAND AND CONTROL SYSTEMS, CONSTRUCTION ENGINEERING RESEARCH LAB (ARMY)  CHAMPAIGN IL, MILITARY HISTORY, NATIONAL DEFENSE, RADAR EQUIPMENT, RADAR INTERCEPTION., RADAR STATIONS, RESOURCE MANAGEMENT, Winkler, David F.},
	file = {Defense Technical Information Center - 1997 - DTIC ADA331231 Searching the Skies the Legacy of.pdf:/Users/rca2t1/Dropbox/Zotero/storage/XVWZLIXU/Defense Technical Information Center - 1997 - DTIC ADA331231 Searching the Skies the Legacy of.pdf:application/pdf},
}

@incollection{cao_data_2018-1,
	address = {Cham},
	series = {Data {Analytics}},
	title = {Data {Science} {Thinking}},
	isbn = {978-3-319-95092-1},
	url = {https://doi.org/10.1007/978-3-319-95092-1_3},
	abstract = {What makes data science essential and different from existing developments in data mining, machine learning, statistics, and information science?},
	language = {en},
	urldate = {2022-09-15},
	booktitle = {Data {Science} {Thinking}: {The} {Next} {Scientific}, {Technological} and {Economic} {Revolution}},
	publisher = {Springer International Publishing},
	author = {Cao, Longbing},
	editor = {Cao, Longbing},
	year = {2018},
	doi = {10.1007/978-3-319-95092-1_3},
	keywords = {Complex Data Problems, Data-driven Discovery, Scientific Thought, Thinking Habits, Unscientific Thinking},
	pages = {59--90},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/JU9EFIWS/Cao - 2018 - Data Science Thinking.pdf:application/pdf},
}

@article{zhu_towards_2015,
	title = {Towards {Data} {Science}},
	volume = {14},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {1683-1470},
	url = {http://datascience.codata.org/articles/10.5334/dsj-2015-008/print/},
	doi = {10.5334/dsj-2015-008},
	abstract = {The CODATA\&nbsp;Data Science Journal\&nbsp;is a peer-reviewed, open access, electronic journal, publishing papers on the management, dissemination, use and reuse of research data and databases across all research domains, including science, technology, the humanities and the arts. The scope of the journal includes descriptions of data systems, their implementations and their publication, applications, infrastructures, software, legal, reproducibility and transparency issues, the availability and usability of complex datasets, and with a particular focus on the principles, policies and practices for open data.All data is in scope, whether born digital or converted from other sources.},
	language = {en},
	number = {0},
	urldate = {2022-09-15},
	journal = {Data Science Journal},
	author = {Zhu, Yangyong and Xiong, Yun},
	month = may,
	year = {2015},
	note = {Number: 0
Publisher: Ubiquity Press},
	pages = {8},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/GF4XVW7Y/Zhu and Xiong - 2015 - Towards Data Science.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/KAK2IAG5/print.html:text/html},
}

@article{emmert-streib_defining_2019,
	title = {Defining {Data} {Science} by a {Data}-{Driven} {Quantification} of the {Community}},
	volume = {1},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2504-4990},
	url = {https://www.mdpi.com/2504-4990/1/1/15},
	doi = {10.3390/make1010015},
	abstract = {Data science is a new academic field that has received much attention in recent years. One reason for this is that our increasingly digitalized society generates more and more data in all areas of our lives and science and we are desperately seeking for solutions to deal with this problem. In this paper, we investigate the academic roots of data science. We are using data of scientists and their citations from Google Scholar, who have an interest in data science, to perform a quantitative analysis of the data science community. Furthermore, for decomposing the data science community into its major defining factors corresponding to the most important research fields, we introduce a statistical regression model that is fully automatic and robust with respect to a subsampling of the data. This statistical model allows us to define the ‘importance’ of a field as its predictive abilities. Overall, our method provides an objective answer to the question ‘What is data science?’.},
	language = {en},
	number = {1},
	urldate = {2022-09-15},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Emmert-Streib, Frank and Dehmer, Matthias},
	month = mar,
	year = {2019},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {statistics, data science, computational social science, dataology, digital society, scientometrics},
	pages = {235--251},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/UET6QVE8/Emmert-Streib and Dehmer - 2019 - Defining Data Science by a Data-Driven Quantificat.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/E5YRF28E/15.html:text/html},
}

@misc{noauthor_building_nodate,
	title = {Building a {Community} of {Data} {Scientists}: {An} {Explorative} {Analysis}},
	url = {https://www.jstage.jst.go.jp/article/dsj/8/0/8_008-004/_article/-char/ja/},
	urldate = {2022-09-15},
	file = {Building a Community of Data Scientists\: An Explorative Analysis:/Users/rca2t1/Dropbox/Zotero/storage/FREXMN2Y/ja.html:text/html},
}

@book{c_w_besserer_and_hazel_c_besserer_guide_1959,
	title = {Guide to the {Space} {Age}},
	url = {http://archive.org/details/guidetospaceage0000cwbe},
	language = {ENG},
	urldate = {2022-09-26},
	publisher = {PRENTICE HALL, INC.},
	author = {{C. W. BESSERER AND HAZEL C. BESSERER}},
	collaborator = {{Internet Archive}},
	year = {1959},
	annote = {Has definitions of data reduction, data reduction equipment, etc. (p. 66).
},
}

@book{noauthor_dimensions_1958,
	title = {Dimensions: {The} {Magazine} of the {National} {Bureau} of {Standards}, {U}.{S}. {Department} of {Commerce}},
	shorttitle = {Dimensions},
	language = {en},
	publisher = {U.S. Department of Commerce, National Bureau of Standards},
	year = {1958},
	annote = {See “Black Box Computer” image on page 7.
},
	annote = {See “High Speed Computers in Radio Propagation Research”, pp. 10-12.
Describes the pipeline


Data Collection and Preparation 


Data Reduction




Data Analysis


Improvement in Prediction Services


Tables and Graphs


Scheduling of Equipment


},
	file = {content (2).jpeg:/Users/rca2t1/Dropbox/Zotero/storage/WCAZEE3N/content (2).jpeg:image/jpeg},
}

@book{house_hearings_1958,
	title = {Hearings},
	language = {en},
	publisher = {U.S. Government Printing Office},
	author = {House, United States Congress},
	year = {1958},
	annote = {p. 807: “Data Reduction and Publication”


Describes nature of DR; also World Data Center A


“The problems of data reduction are complex and very in each field and in each experiment.”


See also p. 814.
See also p. 822: “… ‘data reduction,’ which means mechanical handling.”
},
}

@book{noauthor_naval_1954,
	title = {Naval {Aviation} {News}},
	language = {en},
	publisher = {Chief of Naval Operations},
	year = {1954},
	note = {Google-Books-ID: xGFGAQAAMAAJ},
	annote = {p. 17: “Data Reduction for Guided Missiles”
“Raw missile data is like primitive hieroglyphics …”
},
}

@article{habib_how_1966,
	title = {How to {Handle} 200 {Million} {Data} {Points} a {Day}},
	url = {https://ntrs.nasa.gov/citations/19660042614},
	abstract = {Satellite Telemetry Automatic Reduction System /STARS/ capable of processing data at capacity of 200 million data points per day},
	urldate = {2022-09-27},
	author = {Habib, E. J. and Keipert, F. A. and Lee, R. C.},
	month = feb,
	year = {1966},
	note = {NTRS Author Affiliations: 
NTRS Report/Patent Number: ISA PAPER 7.2-2-65
NTRS Document ID: 19660042614
NTRS Research Center: Legacy CDMS (CDMS)},
	keywords = {COMPUTERS},
	file = {Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/VCNXSAPU/19660042614.html:text/html},
}

@book{belzer_encyclopedia_1979,
	title = {Encyclopedia of {Computer} {Science} and {Technology}: {Volume} 12 - {Pattern} {Recognition}: {Structural} {Description} {Languages} to {Reliability} of {Computer} {Systems}},
	isbn = {978-0-8247-2262-3},
	shorttitle = {Encyclopedia of {Computer} {Science} and {Technology}},
	abstract = {"This comprehensive reference work provides immediate, fingertip access to state-of-the-art technology in nearly 700 self-contained articles written by over 900 international authorities. Each article in the Encyclopedia features current developments and trends in computers, software, vendors, and applications...extensive bibliographies of leading figures in the field, such as Samuel Alexander, John von Neumann, and Norbert Wiener...and in-depth analysis of future directions."},
	language = {en},
	publisher = {CRC Press},
	author = {Belzer, Jack and Holzman, Albert G. and Kent, Allen},
	month = may,
	year = {1979},
	keywords = {Computers / General, Computers / Computer Science},
}

@book{noauthor_mohawk_nodate-2,
	title = {mohawk :: {M}-100-65 {MDS}-1101 {Brochure}},
	shorttitle = {mohawk},
	url = {http://archive.org/details/bitsavers_mohawkM100_5499500},
	abstract = {From the bitsavers.org collection, a scanned-in computer-related document.
mohawk :: M-100-65 MDS-1101 Brochure},
	language = {eng},
	urldate = {2022-09-28},
	keywords = {magnetic},
	file = {mohawk  M-100-65 MDS-1101 Brochure.pdf:/Users/rca2t1/Dropbox/Zotero/storage/PE75T5YH/mohawk  M-100-65 MDS-1101 Brochure.pdf:application/pdf},
}

@article{iivari_dimensions_1986,
	title = {Dimensions of information systems design: {A} framework for a long-range research program},
	volume = {11},
	issn = {0306-4379},
	shorttitle = {Dimensions of information systems design},
	url = {https://www.sciencedirect.com/science/article/pii/0306437986900074},
	doi = {10.1016/0306-4379(86)90007-4},
	abstract = {Even though the two IFIP WG8.1 working conferences on the comparative review and feature analysis of information systems methodologies (ISDMs) have made an important contribution, there is a need for supplementary longer-term comparative research which might gradually produce empirically-based knowledge about what are to be regarded as sound principles of IS design in various circumstances. Due to its scope, this research should take the form of broad international cooperation based on a reasonably common research framework, one close in spirit to that of Ives, Hamilton and Davis. A research framework of this kind should include as one element a profound conceptual model for IS design as a process, an area which is left relatively unanalyzed in the model of Ives et al. For that purpose the paper outlines a framework based on the sociocybernetic metamodel for IS design as a starting point for discussion and hopefully a more elaborate framework.},
	language = {en},
	number = {2},
	urldate = {2022-09-28},
	journal = {Information Systems},
	author = {Iivari, Juhani},
	month = jan,
	year = {1986},
	pages = {185--197},
	file = {ScienceDirect Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/UJZVUBDD/0306437986900074.html:text/html},
}

@article{iivari_pioco_1987-1,
	title = {The {PIOCO} {Model} for {Information} {Systems} {Design}},
	volume = {11},
	issn = {0276-7783},
	url = {https://www.jstor.org/stable/248688},
	doi = {10.2307/248688},
	abstract = {The PIOCO model is a comprehensive methodology for information systems (IS) design consisting of a metamodel for an information system, the corresponding description languages, a process model for information systems design, and a model for choice and quality criteria. The metamodel for an information system consists of three levels of abstraction and forms a profound and articulated conceptual basis for the PIOCO model for the IS design process. The article gives an overview of the PIOCO approach from a management perspective, emphasizing the role of IS design as an inquiry process supporting the decision-making concerning the information system, the quality criteria related to the IS design, and the use of the PIOCO model as a macro-framework which integrates more detailed micro-level methodologies, methods, techniques and tools.},
	number = {3},
	urldate = {2022-09-28},
	journal = {MIS Quarterly},
	author = {Iivari, Juhani and Koskela, Erkki},
	year = {1987},
	note = {Publisher: Management Information Systems Research Center, University of Minnesota},
	pages = {401--419},
	file = {JSTOR Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/TMU5MQ6J/Iivari and Koskela - 1987 - The PIOCO Model for Information Systems Design.pdf:application/pdf},
}

@inproceedings{kerola_comparison_1981,
	address = {San Diego, California, USA},
	series = {{ICSE} '81},
	title = {A comparison of lifecycle models},
	isbn = {978-0-89791-146-7},
	abstract = {Preliminary comparison of world views in systems development is given. The purpose of the paper is to present the Finnish PSC systemeering model to the software engineering (SE) community and to compare it with the ideas of D. Ross and practical approaches in SE.},
	urldate = {2022-09-28},
	booktitle = {Proceedings of the 5th international conference on {Software} engineering},
	publisher = {IEEE Press},
	author = {Kerola, Pentti and Freeman, Peter},
	month = mar,
	year = {1981},
	keywords = {Development strategies, Lifecycle, Systemeering},
	pages = {90--99},
	annote = {Systemeering

},
	file = {Full Text PDF:/Users/rca2t1/Dropbox/Zotero/storage/FGVPUJ3T/Kerola and Freeman - 1981 - A comparison of lifecycle models.pdf:application/pdf},
}

@book{chase_experimental_1970,
	address = {L.G. Hanscom Field, Bedford, Massachusetts},
	series = {Instrumentation {Papers} ;{No}. 164},
	title = {An {Experimental} {Display} {Processor} for the {DX}-1},
	url = {https://catalog.hathitrust.org/Record/102198172},
	abstract = {An experimental two-console, core-buffered CRT display unit has been developed to advance display console design and improve digital hardware line- and curve-generating techniques. Static or dynamic graphical information can be displayed by either a black and white or full-color display processor under the control of a list processor designed for interfacing to a time-shared main computer. (Author).},
	urldate = {2022-09-28},
	publisher = {Air Force Cambridge Research Laboratories, Office of Aerospace Research, United States Air Force},
	author = {Chase, Edward N. and {Air Force Cambridge Research Laboratories (U.S.)}},
	year = {1970},
	keywords = {Cathode ray tubes, (OCoLC)fst00849102, (OCoLC)fst00872390, (OCoLC)fst00972541, Computer programming, fast, Information display systems},
	annote = {AD0702082 (from http://www.dtic.mil).},
	annote = {An experimental two-console, core-buffered CRT display unit has been developed to advance display console design and improve digital hardware line- and curve-generating techniques. Static or dynamic graphical information can be displayed by either a black and white or full-color display processor under the control of a list processor designed for interfacing to a time-shared main computer. (Author).},
	annote = {Data Sciences Laboratory Project 4641},
	annote = {Includes bibliographical references (page 33).},
	annote = {"January 1970."},
	annote = {Research supported by the Air Force Cambridge Research Laboratories, Office of Aerospace Research, United States Air Force, L.G. Hanscom Field, Bedford, Massachusetts.},
}

@book{air_force_cambridge_research_laboratories_us_history_1962,
	address = {Bedford, Massachusetts},
	series = {{AFCRL} 62-714},
	title = {History and progress of {AFCRL}, {Jan}. 1961-{June} 1962; a detailed survey of research at the {Air} {Force} {Cambridge} {Research} {Laboratories}, {Office} of {Aerospace} {Research}, {Bedford}, {Mass}.},
	url = {https://catalog.hathitrust.org/Record/102893702},
	urldate = {2022-09-29},
	publisher = {Air Force Cambridge Research Laboratories, Office of Aerospace Research, United States Air Force},
	author = {{Air Force Cambridge Research Laboratories (U.S.)}},
	year = {1962},
	keywords = {History, fast, (OCoLC)fst00819166, (OCoLC)fst01411628, Associations, institutions, etc},
	annote = {Appendix A: Journal Articles/Books January 1961 - June 1962. (p. 173-184).},
	annote = {Appendix B: Papers Presented at Meetings January 1961 - June 1962. (p. 185-198).},
	annote = {Appendix C: Technical Reports January 1961 - June 1962. (p. 199-207).},
	annote = {Appendix D: Organization (p. 208-212).},
	annote = {"October 1962."},
	file = {Air Force Cambridge Research Laboratories (U.S.) - 1962 - History and progress of AFCRL, Jan. 1961-June 1962.pdf:/Users/rca2t1/Dropbox/Zotero/storage/EPCBTWZ3/Air Force Cambridge Research Laboratories (U.S.) - 1962 - History and progress of AFCRL, Jan. 1961-June 1962.pdf:application/pdf},
}

@misc{noauthor_one_nodate,
	title = {One {Data} {Science} {Job} {Doesn}’t {Fit} {All} {\textbar} {LinkedIn}},
	url = {https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/},
	urldate = {2022-09-29},
	file = {One Data Science Job Doesn’t Fit All | LinkedIn:/Users/rca2t1/Dropbox/Zotero/storage/K5FNPYJY/one-data-science-job-doesnt-fit-all-elena-grewal.html:text/html},
}

@book{pearson_notes_1958,
	title = {Notes on {Space} {Technology}},
	url = {https://ntrs.nasa.gov/citations/19740074640},
	abstract = {These notes are part of a space technology course given at the Flight Research Division of the NACA Langley Aeronautical Laboratory during the early part of 1958. The course was conducted as a self-education program within the Flight Research Division and the various Sections of the notes were prepared for the most part by members of the Division; however, four of the seventeen Sections were prepared by personnel from the Pilotless Aircraft Research Division and the Compressibility Research Division who were very helpful in making the program more complete.

The notes have been compiled on a brief time schedule and it will be apparent to the reader that the present version is incomplete and to some extent may lack uniformity in length, type of presentation, and technical detail in the various Sections. Nevertheless, there has been a demand for the notes from those who have seen them, and it is thought that they might serve a useful purpose if they were made available on a wider basis. It is believed that for the sake of expediency this goal is best achieved by making the material available now in its present unedited form instead of following the usual NACA editing procedures.},
	urldate = {2022-09-29},
	author = {Pearson, Henry A.},
	month = jan,
	year = {1958},
	note = {NTRS Author Affiliations: Langley Aeronautical Laboratory
NTRS Meeting Information: Space Technology Course; 1958-02-01 to 1958-05-01; undefined
NTRS Report/Patent Number: NASA-TM-X-69992
NTRS Document ID: 19740074640
NTRS Research Center: Langley Research Center (LaRC)},
	keywords = {Aeronautics (General)},
	file = {19740074640.pdf:/Users/rca2t1/Dropbox/Zotero/storage/C42VSYBN/Pearson - 1958 - Notes on Space Technology.pdf:application/pdf;Snapshot:/Users/rca2t1/Dropbox/Zotero/storage/6L4B7HHT/19740074640.html:text/html},
}

@misc{noauthor_mansfield_nodate,
	title = {The {Mansfield} {Amendment}},
	url = {https://www.nsf.gov/nsb/documents/2000/nsb00215/nsb50/1970/mansfield.html},
	urldate = {2022-09-30},
	journal = {NSF: NSB 50th Anniversary},
	file = {NSF\: NSB 50th Anniversary:/Users/rca2t1/Dropbox/Zotero/storage/5HN4EBIQ/mansfield.html:text/html},
}
